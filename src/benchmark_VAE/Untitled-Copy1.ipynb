{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd65f3d-c554-44b9-bf8c-f66153166848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n",
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd23c27-3ca4-484f-8d3c-909bf0e8e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/miniforge3/envs/s2s/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from benchmark_VAE.src.pythae.models import VQVAE, VQVAEConfig\n",
    "from benchmark_VAE.src.pythae.models import SVAE, SVAEConfig\n",
    "from benchmark_VAE.src.pythae.models import DisentangledBetaVAE, DisentangledBetaVAEConfig\n",
    "from benchmark_VAE.src.pythae.models import VAE, VAEConfig\n",
    "from benchmark_VAE.src.pythae.models import BetaTCVAE, BetaTCVAEConfig\n",
    "from benchmark_VAE.src.pythae.trainers import BaseTrainerConfig\n",
    "from benchmark_VAE.src.pythae.pipelines.training import TrainingPipeline\n",
    "from benchmark_VAE.src.pythae.models.nn.benchmarks.mnist.resnets import Encoder_ResNet_VQVAE_MNIST, Decoder_ResNet_VQVAE_MNIST\n",
    "\n",
    "from benchmark_VAE.src.pythae.models.nn.benchmarks.mnist.resnets import Encoder_ResNet_VAE_MNIST, Decoder_ResNet_AE_MNIST\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56c4f68-5b92-46f6-b960-db1caf7fcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = DisentangledBetaVAEConfig(\n",
    "    input_dim=(1, 64, 64),\n",
    "    latent_dim=32,\n",
    "    reconstruction_loss= \"mse\",\n",
    "    beta=2.,\n",
    "    C=30.0,\n",
    "    warmup_epoch=100\n",
    "\n",
    ")\n",
    "\n",
    "model = DisentangledBetaVAE(\n",
    "    model_config=model_config,\n",
    "    encoder=Encoder_ResNet_VAE_MNIST(model_config), \n",
    "    decoder=Decoder_ResNet_AE_MNIST(model_config) \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023923a9-1ce9-4b97-896f-494ab4cc484c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DisentangledBetaVAE(\n",
       "  (decoder): Decoder_ResNet_AE_MNIST(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=2048, bias=True)\n",
       "      (1): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (4): ReLU()\n",
       "      )\n",
       "      (2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (3): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Encoder_ResNet_VAE_MNIST(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (embedding): Linear(in_features=2048, out_features=32, bias=True)\n",
       "    (log_var): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0e1a73-528c-4da3-9c96-933481b885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../../data', train=True, download=True, transform=None)\n",
    "\n",
    "train_dataset = mnist_trainset.data[:-50000].reshape(-1, 1, 28, 28) / 255.\n",
    "eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb428cf-6e1a-478e-a251-0eff24f6379e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9795fe-d108-4b2c-b984-562cef9e7a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08ef3f8b-79f0-4427-a3d4-f4fb39c0a2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 4, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = model.encoder(train_dataset[:1]).embedding\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63242cc1-cc77-41d4-b299-d5dc415fd083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 16])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding.permute(0, 2, 3, 1)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c631a867-41c3-4c9e-b5f8-0a7e6ce56890",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.quantizer(embeddings, uses_ddp=False).quantized_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d029f8fe-51d0-4a8f-a6fe-3ebf379d0e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.nn.functional.interpolate(train_dataset[2:5], size=(64,64))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0a8cba-d763-4d55-b8c5-17b8e8096148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95be28a7-0f14-4834-912b-3c251753d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACxklEQVR4AY2WC3LkMAhEPVu5/5W9dEMj0G/GqRhZwKORLCfPc7teOF+7v3aHMcsHGL/+abC1H8x+eDerJHt+Y+55rgBlJNxYH1eRU1cAoyA9qttoYV4BqZMM44iQjnsLUS2jtRgpH4OrAkYi39fvfWycODrvAI+VbEvgJoI2NuGmwDtQHx/PIrSq+KkF1IRiJJbimLopyDohgvHLRp4VtDRuQPTeHDcFUdEMO6h5KW7bQkR6EFpWOC20VNbfqKMePX4sloULsQRvFSxRno677aX9NNyyiG+c2hKVSwDpU/5xEdUmavolG48Xw8gIN8P6Fs5jnSbz5xZUp3QABnXIKIaQGWCJyPUY3LUmuXQNvexCg0smtj6WVlPDzgrCozK0RgV4z5kAlkDdwSljbgee8yvtMR3AgEh2Yy8kVIwOpE1RHSBv2DQN3B76iySXLKrEa0AW56vT/F2BdLl9xxYiyxghqYZVgB/AJS7e5l15I1WAwEWkSsquMipAUbK+pRDvyAJWraZAflkEcZwTg7wFuDujLYafUkzbb7wQIzNGo4WaSWdOqAMd7AYZgJweQg2B2uFxKXpS+ACMPPlgubV7l4clIMk5YHmLYgeYdc5ES4DzpjvqJzAHLSgBE1gFMU0XbjtEAhIrkp0En2OaZjNMgxUgD60le6oPNpgvAMjeZJUiVwDF82YZ29eonQXHjnoY+QetLt/we/xRQRRWByvJ87ffg3D5+qkDTM7VMXdUYD78NcycwxJcASgwCHxabycF3jv+Nf9ynQBLmlZxdlwAeJX5TZpz2vMFYHHZgR1pPxu5qKIcAN76Eq2sYg8ARthCfkccIrT41a3jXcrb8KKgJtfT8AuAG2CByTBFewEnBUg4ZHQBJwBrayEoJcX8BIjoU1JlHBex7eDpKBppCyjaR7GDnC0AWfYWt5Qt9KRg+QvSUEMURv8B6WjCaDVJE3EAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.array(Image.open('../datasets/crop_640/1/00000_614a_d239.png'))\n",
    "img = torch.from_numpy(img).to(device)\n",
    "img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(64,64))\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dda5d6-c1c2-4275-b98f-79dd39b033ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86eea86f-c5cb-4183-b754-a11e83a8c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 ms, sys: 1.29 ms, total: 3.55 ms\n",
      "Wall time: 3.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model(dict(data=img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4370a4b-cf11-49f5-bc01-2423d91c535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c46b72d-90a0-49d2-93f7-3f7dc292dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e89259b-ec4c-479c-8d18-69f8c3ee44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((2,128,64,64)).to(device)\n",
    "\n",
    "b = nn.ConvTranspose2d(128, 128, 4, 2, padding=1).to(device)\n",
    "c = nn.Conv2d(128, 128, 4, 2, padding=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c8dcf69-75ea-4f61-94ff-073dd5f678bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c(a)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf42b83-f9e6-4d00-8b4e-0b7ce7f3ea60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b894a9-c40c-4a6a-81e1-0b2cc8409bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['recon_loss', 'reg_loss', 'loss', 'recon_x', 'z'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c546f6e0-de07-49e3-a1bb-2049c954f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AMqiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiv/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(out.recon_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d89f27-9afe-4370-bdfe-63016c9c4cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0490,  0.2069,  0.1350,  0.0492, -0.1693,  0.0792,  0.0774, -0.0556,\n",
       "          0.0349,  0.0029, -0.2590,  0.0953, -0.1836,  0.1020,  0.3490,  0.0332,\n",
       "          0.2473, -0.1583, -0.1192, -0.1606,  0.2858,  0.0873,  0.0491, -0.2933,\n",
       "         -0.1309, -0.4745,  0.2475,  0.1074, -0.1174, -0.0861,  0.0682, -0.0288]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02276d4c-2114-46c8-8363-bd4cea12f68f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_ResNet_VQVAE_MNIST(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (conv_block): Sequential(\n",
       "          (0): ReLU()\n",
       "          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_qantized): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b5368-4a44-4d82-acab-f2bcb143962c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb7396e-bde4-4699-81f4-99d18fe3a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2e8fb2-9fa0-4544-8566-4ef90687492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_config = BaseTrainerConfig(\n",
    "    output_dir='/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/out',\n",
    "    num_epochs=50000,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    steps_saving=2000,\n",
    "    optimizer_cls=\"AdamW\",\n",
    "    optimizer_params={\"weight_decay\": 0.05, \"betas\": (0.91, 0.99)}\n",
    ")\n",
    "\n",
    "# my_training_config = BaseTrainerConfig(\n",
    "#     output_dir='/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/out',\n",
    "#     num_epochs=50000,\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=64,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     # train_dataloader_num_workers=2,\n",
    "#     # eval_dataloader_num_workers=2,\n",
    "#     steps_saving=5000,\n",
    "#     optimizer_cls=\"AdamW\",\n",
    "#     optimizer_params={\"weight_decay\": 0.05, \"betas\": (0.91, 0.995)},\n",
    "#     scheduler_cls=\"ReduceLROnPlateau\",\n",
    "#     scheduler_params={\"patience\": 5, \"factor\": 0.5}\n",
    "# )\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    training_config=my_training_config,\n",
    "\tmodel=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f19686-f7cf-4ab6-89d7-566683188d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "from torchvision.transforms import GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c998fc53-904c-47ac-897e-b93d26f29b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiitPQdPg1LVUhupDHAFLyMOuB6e9WNR8PvEsdxp0gvbWY/IYxll9Aw7Gp28G6ilhPcSPEJYlDm3DZfB9u1MTwneSRYWe3N1t3/AGbf8+3/AB9qm0Lwv9ru4P7Ul+ywSPsCk4dj7Cnjwi0F3dPqUv2SxgfHmZDFsnAx61HfeEJ47+GHT7mK7gnTzI587Vx7+hpdO8FapeXt3bTRGH7NGXZj0Y9gPXNSaZ4LuNRhkjM6RXyqGW3cgHb3J9KW68O2/hrUM6vPDdRqRsSBsiT159Knn8Ix6zi48NyC48xjugJCmMenvXOavYLpl+1oJfMeMASf7LdxVGilVmU5UkH2NX9I1u/0O7+02E3lyYwcjIP4U611/UrPUJr6G5YXEwIkY87s1R+0TfaDOJGEpO7eDzmn3F7c3U4nnnd5R0YnkUkl5czQiKSeR4wchWbPNWptavp9NgsHlxbw/dUcfnTV1nUlEQF7MBEcp8/SoHvbqS4edriQyv8AefcQTUTO743uzY6ZOcVJb3dxaSB7eeSJgcgoxFRu7yyM7sWdjkknkmm0UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUV/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAACqUlEQVR4Ae3T+0/aUBQH8NOCDwTUcotRirRoC0SqZs4lZg+XPf7k/e6WmWhcfMQ0RtwyLNIJwsWhZaJQWDt0ociW/bLsh53+Qu7puffb86EFwAsFUAAFUAAFUAAFUAAFUAAFUAAFUAAFUAAFUAAFUOCfCDB/J5UIVr7a92ivu0oCJnVX3CvCXZ013KV+K6Ium+t/EjiYXjTe/SaRPJ/epw1g+RhH9a6+znOSyaZhOvlEFYLB9HDbaRnjrulN10O5J5xMyAHrc67zbN5wtJGr2NtFRi87WzzhuSf+rAXALySikN3+GcnK4icKvLpwsVWZtnRQBeNclpT6mh0YSxarvw4URj9+URZ2N+xGIka4merbChHjExDPZitAlFlv/XpkymQeJ+hp4unoGiViqKyfQ/hR7Bz4+cj46LXnZWHtRjC0gfak4ldaTC1OjGbXgOCeMMBkdqyluUuNkgfpYNU3wBM16SmDlNzbBDXNHtzML/l1ZrG5aaZWCbFvxlo77+HZCsvJ0YjRWnwFir+WNTTq2RspzMTnfA0zc9Q9YE8gPaZ0/UQSQl9F6XI/n5yVvaFyTm8/nJeHYLhwrNtjB6Tgt4N8nQ4meFUot6QUCwr1pqdKee1CGCtqTcvOA6sANWt2ZGpi+9jm6rrcn8Xtn6+uJEKHb7Yay69jJ7sf7A2BqByBjH0OEYfqfNg5EV6sMkeGBqLEQ/l0IsVs2CwiVyr5hs46EWyY86WkTM9L6CalP1qpNh6pbR42QNc8xSOnZB6WRHDeEafh9tOpVHxOMNWdO+TEud3ZfjdOq1iE3L3PzD3hXS8nMjn7aIYP10+v7oo9v7zU7tHqaei/7B/Yv9dd9bAty13BFQqgAAqgAAqgAAqgAAqgAAqgAAqgAAqgAAqgAAqgAAr8VwLfAXBWAHBL+puFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "blur = GaussianBlur(3, sigma=1).to(device)\n",
    "br = blur(img_data_x[:10])\n",
    "\n",
    "to_pil_image(br[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75b89062-3b7b-4a37-bde1-5c5ce5da669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAADZklEQVR4Ae1aP28TMRR3WkCVqkiEbp2qzkwd0q1T1S8AU1Yk1C/AWsHH6MCUkQ+AmJhQBUyROkZdYKsuUlVRMfHDd0nOzp2f/fx8ORF0t8R+f36/957ds12fUt3TVaCrQFeB/64CvYSMhkp9LdyPv/FRBITZswX88lepmZbM9visbMsJgC+U9Ugrx5QyVp6DceB2tdXrWPCK/SCnqsi83SmQl1j09DXXqcDzFLiKdtvXZBfRXqXDBTApO+HGELgPWwUszoD9gMlC/RvY5lmGrDijPwYOQjgR+hBlXOVZxJ7BeRoKh0VQM5pRf1XAOt5Omv/6Zy0IpXbWk92c6fOPGuM66TRZ7fVBVbkWmFSwSvBxtSsF9frZFLj1mjajPDeMeNMMZAAF2cIAuwHLptSLFE2mTQGTOAXV1jtS37jifTi5LF/tredhOQ6yYEKEwMsa8GhUbG/GNQVL4GXc827BbjxrAM2Nx7RuxxuN9tPlpr0JzZHHxaNaol3i+7LJ/SVRg/nNGR5IACoCamPFBsIRBe2WE8CE2IWBO5eUlLmRvfOzihU3d5yEmVNaJSr74xjz89LNNLZjAAq3xPNLNJ/eQZhw41t4Fe+TwnglinYaN1ftlER8CUWNm+Qm0oEwUPlgCAmFbnmmTNctU5VNa/2rGbZe0s0lnLY856QvDGmYU+YcVaqZMcSvnjRU20/v8e0u3caI1kVo/kAdshjvWFZh5hyGAzVpcoIyCM8YNuHsCgsMOBk2x6dHkHEcb5CPVYdYPuHBsowllo8zRiW4o4EnDqFXFB3hCprvQLtiaDpJhHhrgLitFEKJb8JLkL8+2MlDvFrI1gd9Hyd6LrnLSBUdfUmGGWY96fJ3Xw1B9wNzYSz6j9CcZ+K+kPIxcq70HEksRAQyDikX4BOl4sj7BCFVVEA6yfwJam09khP2/oZO1XOEvF3NRd/tua5WaGi3pp6GZafXXuuxFPLmCy+hHJfytK4RKJNG5fct5yd9F0qTxrXUU+aHE5mf0Kv1cn4QBipza+Om0I6slZtCQ8g77Rn71Fa7s0V/O5IacIy/XmBizFNtJddSFc7n3ID1pyNI2F4b2kCJDuYfTd2kHv8Mod531L50Kr6WKtbpjH9z+sjG9LZ7alip67F0O+zl6ZRdBboKdBXYvAr8BcTTTU/m3qSTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa095d-314c-4fab-90e3-733d9a579e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cd8d7-cbed-4f4b-9d1f-a2c66a87c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a3ff5d-ca93-43eb-b956-5fe01bb16696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index 0\n",
      "processing index 500\n",
      "processing index 1000\n",
      "processing index 1500\n",
      "processing index 2000\n",
      "collected data (2217, 1, 64, 64)\n",
      "collected label (0,)\n"
     ]
    }
   ],
   "source": [
    "# _Read Images to Array from Folder\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "path = \"/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/datasets/crop_640/1\"\n",
    "path = os.path.join(path,'')\n",
    "\n",
    "size = 64\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "\n",
    "# blur = GaussianBlur(3, sigma=1)\n",
    "\n",
    "for i,f in enumerate(os.listdir(path)):\n",
    "  ext = os.path.splitext(f)[1]\n",
    "  filename = os.path.splitext(f)[0]\n",
    "  if ext.lower() not in valid_images:\n",
    "      continue\n",
    "  img = np.array(Image.open(os.path.join(path,f)))\n",
    "  # print(img.shape)\n",
    "  img = torch.from_numpy(img)\n",
    "  img = torch.nn.functional.interpolate(img.unsqueeze(0).unsqueeze(0), size=(size,size), mode='bilinear',antialias=True)\n",
    "  # img = blur(img)\n",
    "  \n",
    "  imgs.append(img[0].numpy())\n",
    "  # labels.append(int(filename[-2]))\n",
    "\n",
    "  if i%500==0:\n",
    "    print(f'processing index {i}')\n",
    "\n",
    "img_data_x = np.array(imgs)\n",
    "img_data_y = np.array(labels)\n",
    "np.random.shuffle(img_data_x)\n",
    "print(f'collected data {img_data_x.shape}\\ncollected label {img_data_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79165d2f-cf92-47da-9970-706507f7adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2217, 1, 64, 64])\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "img_data_x = torch.from_numpy(img_data_x)\n",
    "\n",
    "img_data_x = 1-img_data_x/255.\n",
    "# img_data_x = img_data_x.unsqueeze(1)\n",
    "# img_data_x = img_data_x.permute(0,3,1,2)\n",
    "\n",
    "# img = torch.nn.functional.interpolate(img_data_x, size=(112,112))\n",
    "\n",
    "print(img_data_x.shape)\n",
    "print(img_data_x.max())\n",
    "print(img_data_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2217c0-915a-49d0-b75c-92cf76a4ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiitFdKQorvqlggIzgyMSPwCmo7mwighMkeoWlxg42xF935MoqtNF5ThRIkmVByhyOe31q7HpEkkauLywAYA4a6QEfUE1QdDHIyEqSpIypyD9DV46PcCHzfPssbd2PtkWfy3Zz7VThhaeZYkKBmOAXcKPxJOBUdFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAAuklEQVR4Ae2QsQrCMBRF72trsaW4Oao/oJsObm5+sz/g4OToJlgQHEUTUWJiXqfSoT/gvYQkN+/mkRyAIgESIAESIAESaBOQton7VOB956zXiggC4pjNpSqKQZXi/bofTmG63teQgHIBqx3MOcaiilJnZ5wuyLOsuR7fERBuxpqnR1qNHwG2tpDYIZ+Mhhq9Xpz2k9VG3Wd3ROIRtsvuF7TaqyTRsvhvk8qz3jCLJEACJEACJEACf0ngB6/9LyoKtvQYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f708b662-5453-44fa-9ce5-cc104d9e4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_data_x):\n",
    "        self.img_data_x = img_data_x\n",
    "\n",
    "        self.rf = v2.RandomHorizontalFlip()\n",
    "        self.rv = v2.RandomVerticalFlip()\n",
    "        self.rr = v2.RandomRotation(degrees=(0, 180),interpolation=InterpolationMode.BILINEAR)\n",
    "        self.ra = v2.RandomAffine(degrees=0, translate=(0.4, 0.4))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.img_data_x[idx]\n",
    "        x = self.rf(x)\n",
    "        x = self.rv(x)\n",
    "        x = self.rr(x)\n",
    "        x = self.ra(x)\n",
    "        return dict(data=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768f151b-3807-4f1e-9dce-0f08beaa3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(img_data_x[:2000])\n",
    "eval_data = CustomImageDataset(img_data_x[2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c26cf6-5a6a-4e6e-a89f-f2d11a240264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiilCljhQSfQVI1tcKu5oJQvqUOKirS87T1jMkelSugON0twSM/8BValtpprrf9h0O3fy1LMUieTaB3OWNRw6jdzzLFb2Vo0jHCqlnGxP5g1YvLrWbBUdpYo0fID2ojABHVcp0I9Kh/tbXTbed9tvjAG2797bc+memaf9q8QvYG8+0X/wBmzgyeYwB/XkVTXVdSDDZf3e7PGJm/xq3cX+rWrqmowbywyFvLcEkfUjP5Gro/4SSWbc9lK8ONptTHth2+mwYA/Dnv1pk9t4hZo2SzltooWDRRQjaiH1Azyfc5NLLHrU0ciQ6fBa+Z/rmhCoz+uSTwPYYHtVa0tNXst4iWEI/3kleJlb6qxx+NWQviBpfN+0wcrs2G6h2bfTYW249sVCU1j7at3Je23nqNoL3kRG3+7jdjb7dKtJ9qizJaLolpM3WaK6TePpuchfwxVCZdQsrCVGvrWWBz80S3McvJ7hckg+45rIooooooooooooooooooooooor//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACVElEQVR4Ae2SW2sTURDH5+w5m80mm7tWWhIvqYpKQUuLFFHEYKtPttiq+AV89gP4dQTBUltF0QcRakQfGkvFS4K2AS+1tJBmu5ts9nJ2PZsrtRIVfJIdFnbPnJk/8//NAnjhEfAIeAQ8Av8RAfRbLxwHQJ16GecTJQlLpKpo5UojBb8WQBgJohSKRhOiI0pglykg1kCwpSmWwBk4HNZLm6vfZKMjgHyBQIgFFnzEx2EEelWVS2XVboyIgAlQzWweQYjEdqd6iPwRCUJQioRiIYmnmqooimnWaM3WHaM5djeLnNR3DN20axVZKZeVqtFS79az886Pd+b+SYak0n+ks30L0p5i00fyEh+fXWxKuBsAQP1DLz+3RbFft9wDYU86UVxzv2Mjw9HZ5+4Xf3bwydvea8Y795A8H5v+AhAZP/pqYnrVzbDYNy6ajwuUyfLDp+2VA3PLgEcy+Xnnxu0iwK5Jc6YM0HOlsCT3ntmftc7Nr/SPvn+wdeTywyW3XRw7eTd/8KL6dF1Gt+jMJ5qafKSNkXvrAAMT9+XB489eMG020mgaa7mcCn2Z+PfFZWZk7/UPC5vBwxfWpjfYnEMnKnfQqQWDlR6aItms6TYNZMQ3OabUCD60VXfaOkM4kwyir6/zTVRce/W4vU3E/v1ugUS+2/Vf321fY9d2zBFEeCD+TlV1A1DC50OB9vwOoADiwhhsC4jIOPmBxOueTI25dMAEEugIFOYccpXqyN+yTUvU0ahLwVIdW3OAVlvVlm5Ylu3Ut9PKeW+PgEfAI+AR8Aj8TOAHMIzNbgwsv7AAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5f455c-ad48-4cc2-b888-497cc03d6613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train dataset...\n",
      "Checking eval dataset...\n",
      "Using Base Trainer\n",
      "\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/out/DisentangledBetaVAE_training_2023-11-25_14-05-24. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 50000\n",
      " - per_device_train_batch_size: 64\n",
      " - per_device_eval_batch_size: 64\n",
      " - checkpoint saving every: 2000\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.91, 0.99)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n",
      "Scheduler: None\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.54batch/s]\n",
      "Training of epoch 1/50000: 100%|█████████████| 32/32 [00:00<00:00, 38.55batch/s]\u001b[A\n",
      "Eval of epoch 1/50000: 100%|███████████████████| 4/4 [00:00<00:00, 51.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 520.308\n",
      "Eval loss: 517.7737\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/50000:  94%|████████████▏| 30/32 [00:00<00:00, 49.50batch/s]\n",
      "Training of epoch 2/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 2/50000: 100%|███████████████████| 4/4 [00:00<00:00, 62.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 513.667\n",
      "Eval loss: 509.0549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/50000:  88%|███████████▍ | 28/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 3/50000: 100%|█████████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 3/50000: 100%|███████████████████| 4/4 [00:00<00:00, 63.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 496.7035\n",
      "Eval loss: 481.8747\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/50000:  97%|████████████▌| 31/32 [00:00<00:00, 48.91batch/s]\n",
      "Training of epoch 4/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.37batch/s]\u001b[A\n",
      "Eval of epoch 4/50000: 100%|███████████████████| 4/4 [00:00<00:00, 62.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 449.8244\n",
      "Eval loss: 404.7849\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/50000:  88%|███████████▍ | 28/32 [00:00<00:00, 50.01batch/s]\n",
      "Training of epoch 5/50000: 100%|█████████████| 32/32 [00:00<00:00, 46.04batch/s]\u001b[A\n",
      "Eval of epoch 5/50000: 100%|███████████████████| 4/4 [00:00<00:00, 63.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 337.5375\n",
      "Eval loss: 264.8479\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/50000:  94%|████████████▏| 30/32 [00:00<00:00, 49.02batch/s]\n",
      "Training of epoch 6/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.51batch/s]\u001b[A\n",
      "Eval of epoch 6/50000: 100%|███████████████████| 4/4 [00:00<00:00, 63.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 203.7628\n",
      "Eval loss: 151.8711\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/50000:  94%|████████████▏| 30/32 [00:00<00:00, 48.87batch/s]\n",
      "Training of epoch 7/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.22batch/s]\u001b[A\n",
      "Eval of epoch 7/50000: 100%|███████████████████| 4/4 [00:00<00:00, 61.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 125.1113\n",
      "Eval loss: 101.7372\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/50000:  94%|████████████▏| 30/32 [00:00<00:00, 48.90batch/s]\n",
      "Training of epoch 8/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.22batch/s]\u001b[A\n",
      "Eval of epoch 8/50000: 100%|███████████████████| 4/4 [00:00<00:00, 61.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 89.4869\n",
      "Eval loss: 77.0911\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/50000:  88%|███████████▍ | 28/32 [00:00<00:00, 49.83batch/s]\n",
      "Training of epoch 9/50000: 100%|█████████████| 32/32 [00:00<00:00, 45.97batch/s]\u001b[A\n",
      "Eval of epoch 9/50000: 100%|███████████████████| 4/4 [00:00<00:00, 60.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 71.1194\n",
      "Eval loss: 62.9211\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.42batch/s]\n",
      "Training of epoch 10/50000: 100%|████████████| 32/32 [00:00<00:00, 45.66batch/s]\u001b[A\n",
      "Eval of epoch 10/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 58.2285\n",
      "Eval loss: 50.5679\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.97batch/s]\n",
      "Training of epoch 11/50000: 100%|████████████| 32/32 [00:00<00:00, 45.35batch/s]\u001b[A\n",
      "Eval of epoch 11/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 49.4254\n",
      "Eval loss: 45.9058\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.66batch/s]\n",
      "Training of epoch 12/50000: 100%|████████████| 32/32 [00:00<00:00, 45.25batch/s]\u001b[A\n",
      "Eval of epoch 12/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 43.2674\n",
      "Eval loss: 39.1989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.27batch/s]\n",
      "Training of epoch 13/50000: 100%|████████████| 32/32 [00:00<00:00, 45.57batch/s]\u001b[A\n",
      "Eval of epoch 13/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 37.3519\n",
      "Eval loss: 33.9838\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.28batch/s]\n",
      "Training of epoch 14/50000: 100%|████████████| 32/32 [00:00<00:00, 44.51batch/s]\u001b[A\n",
      "Eval of epoch 14/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 32.878\n",
      "Eval loss: 28.4576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.45batch/s]\n",
      "Training of epoch 15/50000: 100%|████████████| 32/32 [00:00<00:00, 44.71batch/s]\u001b[A\n",
      "Eval of epoch 15/50000: 100%|██████████████████| 4/4 [00:00<00:00, 62.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 28.7966\n",
      "Eval loss: 25.5709\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.40batch/s]\n",
      "Training of epoch 16/50000: 100%|████████████| 32/32 [00:00<00:00, 45.33batch/s]\u001b[A\n",
      "Eval of epoch 16/50000: 100%|██████████████████| 4/4 [00:00<00:00, 62.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 26.0965\n",
      "Eval loss: 22.8278\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.64batch/s]\n",
      "Training of epoch 17/50000: 100%|████████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 17/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 23.9401\n",
      "Eval loss: 22.0892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.71batch/s]\n",
      "Training of epoch 18/50000: 100%|████████████| 32/32 [00:00<00:00, 44.85batch/s]\u001b[A\n",
      "Eval of epoch 18/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 22.3303\n",
      "Eval loss: 21.6981\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.03batch/s]\n",
      "Training of epoch 19/50000: 100%|████████████| 32/32 [00:00<00:00, 45.24batch/s]\u001b[A\n",
      "Eval of epoch 19/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 21.7397\n",
      "Eval loss: 19.9235\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.53batch/s]\n",
      "Training of epoch 20/50000: 100%|████████████| 32/32 [00:00<00:00, 45.93batch/s]\u001b[A\n",
      "Eval of epoch 20/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 20.8663\n",
      "Eval loss: 19.0932\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/50000:  94%|███████████▎| 30/32 [00:00<00:00, 47.63batch/s]\n",
      "Training of epoch 21/50000: 100%|████████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 21/50000: 100%|██████████████████| 4/4 [00:00<00:00, 60.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 20.6753\n",
      "Eval loss: 18.5839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.46batch/s]\n",
      "Training of epoch 22/50000: 100%|████████████| 32/32 [00:00<00:00, 45.13batch/s]\u001b[A\n",
      "Eval of epoch 22/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 20.2407\n",
      "Eval loss: 18.8022\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.50batch/s]\n",
      "Training of epoch 23/50000: 100%|████████████| 32/32 [00:00<00:00, 45.90batch/s]\u001b[A\n",
      "Eval of epoch 23/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.6648\n",
      "Eval loss: 18.3507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.23batch/s]\n",
      "Training of epoch 24/50000: 100%|████████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 24/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 20.0808\n",
      "Eval loss: 18.2641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.79batch/s]\n",
      "Training of epoch 25/50000: 100%|████████████| 32/32 [00:00<00:00, 45.57batch/s]\u001b[A\n",
      "Eval of epoch 25/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.7718\n",
      "Eval loss: 19.9385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.60batch/s]\n",
      "Training of epoch 26/50000: 100%|████████████| 32/32 [00:00<00:00, 44.95batch/s]\u001b[A\n",
      "Eval of epoch 26/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5665\n",
      "Eval loss: 18.0637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.63batch/s]\n",
      "Training of epoch 27/50000: 100%|████████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 27/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4141\n",
      "Eval loss: 18.6325\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 50.05batch/s]\n",
      "Training of epoch 28/50000: 100%|████████████| 32/32 [00:00<00:00, 46.32batch/s]\u001b[A\n",
      "Eval of epoch 28/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4427\n",
      "Eval loss: 17.3283\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 50.08batch/s]\n",
      "Training of epoch 29/50000: 100%|████████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 29/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2384\n",
      "Eval loss: 18.6304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/50000:  97%|███████████▋| 31/32 [00:00<00:00, 48.46batch/s]\n",
      "Training of epoch 30/50000: 100%|████████████| 32/32 [00:00<00:00, 45.24batch/s]\u001b[A\n",
      "Eval of epoch 30/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2913\n",
      "Eval loss: 16.9036\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 31/50000: 100%|████████████| 32/32 [00:00<00:00, 45.70batch/s]\u001b[A\n",
      "Eval of epoch 31/50000: 100%|██████████████████| 4/4 [00:00<00:00, 62.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1415\n",
      "Eval loss: 16.7744\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 32/50000: 100%|████████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 32/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2922\n",
      "Eval loss: 17.6494\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.31batch/s]\n",
      "Training of epoch 33/50000: 100%|████████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 33/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0382\n",
      "Eval loss: 17.4131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.28batch/s]\n",
      "Training of epoch 34/50000: 100%|████████████| 32/32 [00:00<00:00, 45.54batch/s]\u001b[A\n",
      "Eval of epoch 34/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0011\n",
      "Eval loss: 18.2104\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.13batch/s]\n",
      "Training of epoch 35/50000: 100%|████████████| 32/32 [00:00<00:00, 45.32batch/s]\u001b[A\n",
      "Eval of epoch 35/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1458\n",
      "Eval loss: 17.2231\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 36/50000: 100%|████████████| 32/32 [00:00<00:00, 46.13batch/s]\u001b[A\n",
      "Eval of epoch 36/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.192\n",
      "Eval loss: 18.3185\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.18batch/s]\n",
      "Training of epoch 37/50000: 100%|████████████| 32/32 [00:00<00:00, 45.72batch/s]\u001b[A\n",
      "Eval of epoch 37/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2538\n",
      "Eval loss: 18.3172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.15batch/s]\n",
      "Training of epoch 38/50000: 100%|████████████| 32/32 [00:00<00:00, 45.63batch/s]\u001b[A\n",
      "Eval of epoch 38/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5599\n",
      "Eval loss: 17.7769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.41batch/s]\n",
      "Training of epoch 39/50000: 100%|████████████| 32/32 [00:00<00:00, 45.65batch/s]\u001b[A\n",
      "Eval of epoch 39/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.459\n",
      "Eval loss: 16.9417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.32batch/s]\n",
      "Training of epoch 40/50000: 100%|████████████| 32/32 [00:00<00:00, 45.75batch/s]\u001b[A\n",
      "Eval of epoch 40/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.987\n",
      "Eval loss: 17.5561\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.27batch/s]\n",
      "Training of epoch 41/50000: 100%|████████████| 32/32 [00:00<00:00, 45.36batch/s]\u001b[A\n",
      "Eval of epoch 41/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1597\n",
      "Eval loss: 17.5226\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.49batch/s]\n",
      "Training of epoch 42/50000: 100%|████████████| 32/32 [00:00<00:00, 45.96batch/s]\u001b[A\n",
      "Eval of epoch 42/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1649\n",
      "Eval loss: 18.142\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.91batch/s]\n",
      "Training of epoch 43/50000: 100%|████████████| 32/32 [00:00<00:00, 45.17batch/s]\u001b[A\n",
      "Eval of epoch 43/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0251\n",
      "Eval loss: 17.3436\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.24batch/s]\n",
      "Training of epoch 44/50000: 100%|████████████| 32/32 [00:00<00:00, 45.74batch/s]\u001b[A\n",
      "Eval of epoch 44/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9315\n",
      "Eval loss: 17.3355\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.23batch/s]\n",
      "Training of epoch 45/50000: 100%|████████████| 32/32 [00:00<00:00, 45.79batch/s]\u001b[A\n",
      "Eval of epoch 45/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8705\n",
      "Eval loss: 18.9624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.66batch/s]\n",
      "Training of epoch 46/50000: 100%|████████████| 32/32 [00:00<00:00, 45.80batch/s]\u001b[A\n",
      "Eval of epoch 46/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2851\n",
      "Eval loss: 17.067\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/50000: 100%|████████████| 32/32 [00:00<00:00, 52.09batch/s]\n",
      "Training of epoch 47/50000: 100%|████████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 47/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.628\n",
      "Eval loss: 18.2777\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.71batch/s]\n",
      "Training of epoch 48/50000: 100%|████████████| 32/32 [00:00<00:00, 45.12batch/s]\u001b[A\n",
      "Eval of epoch 48/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0904\n",
      "Eval loss: 17.9384\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.25batch/s]\n",
      "Training of epoch 49/50000: 100%|████████████| 32/32 [00:00<00:00, 45.87batch/s]\u001b[A\n",
      "Eval of epoch 49/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9362\n",
      "Eval loss: 17.5351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.55batch/s]\n",
      "Training of epoch 50/50000: 100%|████████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 50/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1235\n",
      "Eval loss: 19.067\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.77batch/s]\n",
      "Training of epoch 51/50000: 100%|████████████| 32/32 [00:00<00:00, 45.96batch/s]\u001b[A\n",
      "Eval of epoch 51/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2546\n",
      "Eval loss: 17.1631\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 52/50000: 100%|████████████| 32/32 [00:00<00:00, 46.04batch/s]\u001b[A\n",
      "Eval of epoch 52/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3046\n",
      "Eval loss: 18.3016\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 53/50000: 100%|████████████| 32/32 [00:00<00:00, 46.17batch/s]\u001b[A\n",
      "Eval of epoch 53/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.8304\n",
      "Eval loss: 18.4305\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 48.70batch/s]\n",
      "Training of epoch 54/50000: 100%|████████████| 32/32 [00:00<00:00, 45.51batch/s]\u001b[A\n",
      "Eval of epoch 54/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3797\n",
      "Eval loss: 17.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.88batch/s]\n",
      "Training of epoch 55/50000: 100%|████████████| 32/32 [00:00<00:00, 45.38batch/s]\u001b[A\n",
      "Eval of epoch 55/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1602\n",
      "Eval loss: 18.3961\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.04batch/s]\n",
      "Training of epoch 56/50000: 100%|████████████| 32/32 [00:00<00:00, 45.45batch/s]\u001b[A\n",
      "Eval of epoch 56/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0578\n",
      "Eval loss: 17.3431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 57/50000: 100%|████████████| 32/32 [00:00<00:00, 46.17batch/s]\u001b[A\n",
      "Eval of epoch 57/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0643\n",
      "Eval loss: 17.5176\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.65batch/s]\n",
      "Training of epoch 58/50000: 100%|████████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 58/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0285\n",
      "Eval loss: 18.7177\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.05batch/s]\n",
      "Training of epoch 59/50000: 100%|████████████| 32/32 [00:00<00:00, 45.44batch/s]\u001b[A\n",
      "Eval of epoch 59/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0436\n",
      "Eval loss: 16.9918\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.82batch/s]\n",
      "Training of epoch 60/50000: 100%|████████████| 32/32 [00:00<00:00, 45.32batch/s]\u001b[A\n",
      "Eval of epoch 60/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4728\n",
      "Eval loss: 18.2311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.96batch/s]\n",
      "Training of epoch 61/50000: 100%|████████████| 32/32 [00:00<00:00, 45.53batch/s]\u001b[A\n",
      "Eval of epoch 61/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3032\n",
      "Eval loss: 18.6407\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.87batch/s]\n",
      "Training of epoch 62/50000: 100%|████████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 62/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0637\n",
      "Eval loss: 17.2561\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 63/50000: 100%|████████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 63/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0733\n",
      "Eval loss: 17.4161\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.19batch/s]\n",
      "Training of epoch 64/50000: 100%|████████████| 32/32 [00:00<00:00, 45.77batch/s]\u001b[A\n",
      "Eval of epoch 64/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3477\n",
      "Eval loss: 17.8706\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 49.89batch/s]\n",
      "Training of epoch 65/50000: 100%|████████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 65/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4288\n",
      "Eval loss: 16.8379\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 66/50000: 100%|████████████| 32/32 [00:00<00:00, 45.84batch/s]\u001b[A\n",
      "Eval of epoch 66/50000: 100%|██████████████████| 4/4 [00:00<00:00, 61.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.207\n",
      "Eval loss: 16.5574\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.46batch/s]\n",
      "Training of epoch 67/50000: 100%|████████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 67/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1811\n",
      "Eval loss: 16.8173\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 68/50000: 100%|████████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 68/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2583\n",
      "Eval loss: 17.746\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.24batch/s]\n",
      "Training of epoch 69/50000: 100%|████████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 69/50000: 100%|██████████████████| 4/4 [00:00<00:00, 68.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2967\n",
      "Eval loss: 17.4203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/50000: 100%|████████████| 32/32 [00:00<00:00, 51.99batch/s]\n",
      "Training of epoch 70/50000: 100%|████████████| 32/32 [00:00<00:00, 46.28batch/s]\u001b[A\n",
      "Eval of epoch 70/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.35\n",
      "Eval loss: 17.393\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 71/50000: 100%|████████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 71/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1495\n",
      "Eval loss: 18.6026\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.46batch/s]\n",
      "Training of epoch 72/50000: 100%|████████████| 32/32 [00:00<00:00, 46.01batch/s]\u001b[A\n",
      "Eval of epoch 72/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9726\n",
      "Eval loss: 18.6126\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/50000:  94%|███████████▎| 30/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 73/50000: 100%|████████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 73/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1344\n",
      "Eval loss: 17.4197\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.97batch/s]\n",
      "Training of epoch 74/50000: 100%|████████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 74/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4929\n",
      "Eval loss: 18.4824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.12batch/s]\n",
      "Training of epoch 75/50000: 100%|████████████| 32/32 [00:00<00:00, 45.70batch/s]\u001b[A\n",
      "Eval of epoch 75/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0513\n",
      "Eval loss: 18.7747\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/50000:  97%|███████████▋| 31/32 [00:00<00:00, 49.80batch/s]\n",
      "Training of epoch 76/50000: 100%|████████████| 32/32 [00:00<00:00, 46.28batch/s]\u001b[A\n",
      "Eval of epoch 76/50000: 100%|██████████████████| 4/4 [00:00<00:00, 68.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1497\n",
      "Eval loss: 17.7072\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 77/50000: 100%|████████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 77/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0874\n",
      "Eval loss: 18.0854\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 78/50000: 100%|████████████| 32/32 [00:00<00:00, 46.78batch/s]\u001b[A\n",
      "Eval of epoch 78/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3364\n",
      "Eval loss: 18.0027\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/50000:  94%|███████████▎| 30/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 79/50000: 100%|████████████| 32/32 [00:00<00:00, 46.89batch/s]\u001b[A\n",
      "Eval of epoch 79/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4688\n",
      "Eval loss: 17.8253\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.54batch/s]\n",
      "Training of epoch 80/50000: 100%|████████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 80/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9638\n",
      "Eval loss: 18.6287\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.50batch/s]\n",
      "Training of epoch 81/50000: 100%|████████████| 32/32 [00:00<00:00, 45.89batch/s]\u001b[A\n",
      "Eval of epoch 81/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8517\n",
      "Eval loss: 17.1409\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.32batch/s]\n",
      "Training of epoch 82/50000: 100%|████████████| 32/32 [00:00<00:00, 45.76batch/s]\u001b[A\n",
      "Eval of epoch 82/50000: 100%|██████████████████| 4/4 [00:00<00:00, 64.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0871\n",
      "Eval loss: 17.6315\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/50000:  94%|███████████▎| 30/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 83/50000: 100%|████████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 83/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2757\n",
      "Eval loss: 17.6892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 84/50000: 100%|████████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 84/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1381\n",
      "Eval loss: 16.6833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 85/50000: 100%|████████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 85/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3385\n",
      "Eval loss: 17.6745\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 86/50000: 100%|████████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 86/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2794\n",
      "Eval loss: 17.0196\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 87/50000: 100%|████████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 87/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1143\n",
      "Eval loss: 17.4385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/50000:  84%|██████████▏ | 27/32 [00:00<00:00, 49.92batch/s]\n",
      "Training of epoch 88/50000: 100%|████████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 88/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2929\n",
      "Eval loss: 18.0432\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 89/50000: 100%|████████████| 32/32 [00:00<00:00, 46.72batch/s]\u001b[A\n",
      "Eval of epoch 89/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9919\n",
      "Eval loss: 18.2109\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/50000: 100%|████████████| 32/32 [00:00<00:00, 52.17batch/s]\n",
      "Training of epoch 90/50000: 100%|████████████| 32/32 [00:00<00:00, 46.21batch/s]\u001b[A\n",
      "Eval of epoch 90/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5437\n",
      "Eval loss: 16.8211\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 91/50000: 100%|████████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 91/50000: 100%|██████████████████| 4/4 [00:00<00:00, 68.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1172\n",
      "Eval loss: 16.7299\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.66batch/s]\n",
      "Training of epoch 92/50000: 100%|████████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 92/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1488\n",
      "Eval loss: 17.4408\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/50000: 100%|████████████| 32/32 [00:00<00:00, 52.25batch/s]\n",
      "Training of epoch 93/50000: 100%|████████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 93/50000: 100%|██████████████████| 4/4 [00:00<00:00, 67.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1077\n",
      "Eval loss: 18.2217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/50000:  94%|███████████▎| 30/32 [00:00<00:00, 49.98batch/s]\n",
      "Training of epoch 94/50000: 100%|████████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 94/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3844\n",
      "Eval loss: 18.575\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 95/50000: 100%|████████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 95/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2736\n",
      "Eval loss: 18.1329\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/50000:  88%|██████████▌ | 28/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 96/50000: 100%|████████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 96/50000: 100%|██████████████████| 4/4 [00:00<00:00, 65.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4276\n",
      "Eval loss: 18.9947\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/50000:  91%|██████████▉ | 29/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 97/50000: 100%|████████████| 32/32 [00:00<00:00, 45.87batch/s]\u001b[A\n",
      "Eval of epoch 97/50000: 100%|██████████████████| 4/4 [00:00<00:00, 63.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1428\n",
      "Eval loss: 16.4498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/50000:  94%|███████████▎| 30/32 [00:00<00:00, 48.93batch/s]\n",
      "Training of epoch 98/50000: 100%|████████████| 32/32 [00:00<00:00, 45.77batch/s]\u001b[A\n",
      "Eval of epoch 98/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5188\n",
      "Eval loss: 17.6139\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/50000:  94%|███████████▎| 30/32 [00:00<00:00, 50.14batch/s]\n",
      "Training of epoch 99/50000: 100%|████████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 99/50000: 100%|██████████████████| 4/4 [00:00<00:00, 66.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5345\n",
      "Eval loss: 19.1806\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 100/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 100/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8625\n",
      "Eval loss: 18.05\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 101/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 101/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 101/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4108\n",
      "Eval loss: 17.8932\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 102/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 102/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 102/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0329\n",
      "Eval loss: 16.928\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 103/50000: 100%|███████████| 32/32 [00:00<00:00, 52.08batch/s]\n",
      "Training of epoch 103/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 103/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8576\n",
      "Eval loss: 18.0614\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 104/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.66batch/s]\n",
      "Training of epoch 104/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 104/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1041\n",
      "Eval loss: 18.1785\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 105/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.92batch/s]\n",
      "Training of epoch 105/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 105/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0299\n",
      "Eval loss: 17.9966\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 106/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.01batch/s]\n",
      "Training of epoch 106/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 106/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1365\n",
      "Eval loss: 18.6147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 107/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 107/50000: 100%|███████████| 32/32 [00:00<00:00, 45.94batch/s]\u001b[A\n",
      "Eval of epoch 107/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1621\n",
      "Eval loss: 18.0673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 108/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.01batch/s]\n",
      "Training of epoch 108/50000: 100%|███████████| 32/32 [00:00<00:00, 46.09batch/s]\u001b[A\n",
      "Eval of epoch 108/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1106\n",
      "Eval loss: 18.1361\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 109/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 109/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 109/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8966\n",
      "Eval loss: 18.8955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 110/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 110/50000: 100%|███████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 110/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0629\n",
      "Eval loss: 17.7229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 111/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.16batch/s]\n",
      "Training of epoch 111/50000: 100%|███████████| 32/32 [00:00<00:00, 45.93batch/s]\u001b[A\n",
      "Eval of epoch 111/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9685\n",
      "Eval loss: 18.5031\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 112/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 112/50000: 100%|███████████| 32/32 [00:00<00:00, 46.19batch/s]\u001b[A\n",
      "Eval of epoch 112/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1414\n",
      "Eval loss: 17.5532\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 113/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.87batch/s]\n",
      "Training of epoch 113/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 113/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0663\n",
      "Eval loss: 18.1502\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 114/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.13batch/s]\n",
      "Training of epoch 114/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 114/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8777\n",
      "Eval loss: 16.6806\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 115/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 115/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 115/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0071\n",
      "Eval loss: 16.8845\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 116/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 116/50000: 100%|███████████| 32/32 [00:00<00:00, 46.50batch/s]\u001b[A\n",
      "Eval of epoch 116/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9912\n",
      "Eval loss: 17.2964\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 117/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.51batch/s]\n",
      "Training of epoch 117/50000: 100%|███████████| 32/32 [00:00<00:00, 46.75batch/s]\u001b[A\n",
      "Eval of epoch 117/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1133\n",
      "Eval loss: 17.3949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 118/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.60batch/s]\n",
      "Training of epoch 118/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 118/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5839\n",
      "Eval loss: 17.2697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 119/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.43batch/s]\n",
      "Training of epoch 119/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 119/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1216\n",
      "Eval loss: 17.1574\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 120/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.79batch/s]\n",
      "Training of epoch 120/50000: 100%|███████████| 32/32 [00:00<00:00, 46.33batch/s]\u001b[A\n",
      "Eval of epoch 120/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9801\n",
      "Eval loss: 17.5978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 121/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.75batch/s]\n",
      "Training of epoch 121/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 121/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2978\n",
      "Eval loss: 18.3754\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 122/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.17batch/s]\n",
      "Training of epoch 122/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 122/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2126\n",
      "Eval loss: 17.1326\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 123/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 123/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 123/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1683\n",
      "Eval loss: 18.3501\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 124/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.34batch/s]\n",
      "Training of epoch 124/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 124/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9133\n",
      "Eval loss: 17.3731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 125/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.82batch/s]\n",
      "Training of epoch 125/50000: 100%|███████████| 32/32 [00:00<00:00, 46.20batch/s]\u001b[A\n",
      "Eval of epoch 125/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0305\n",
      "Eval loss: 18.3719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 126/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 126/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 126/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1699\n",
      "Eval loss: 19.3477\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 127/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.16batch/s]\n",
      "Training of epoch 127/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 127/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0337\n",
      "Eval loss: 17.7951\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 128/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.73batch/s]\n",
      "Training of epoch 128/50000: 100%|███████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 128/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.835\n",
      "Eval loss: 18.0579\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 129/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 129/50000: 100%|███████████| 32/32 [00:00<00:00, 46.10batch/s]\u001b[A\n",
      "Eval of epoch 129/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0669\n",
      "Eval loss: 17.3405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 130/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.58batch/s]\n",
      "Training of epoch 130/50000: 100%|███████████| 32/32 [00:00<00:00, 45.91batch/s]\u001b[A\n",
      "Eval of epoch 130/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2316\n",
      "Eval loss: 17.2311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 131/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 131/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 131/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9605\n",
      "Eval loss: 17.1531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 132/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.65batch/s]\n",
      "Training of epoch 132/50000: 100%|███████████| 32/32 [00:00<00:00, 46.36batch/s]\u001b[A\n",
      "Eval of epoch 132/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2912\n",
      "Eval loss: 18.8698\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 133/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 133/50000: 100%|███████████| 32/32 [00:00<00:00, 46.29batch/s]\u001b[A\n",
      "Eval of epoch 133/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8464\n",
      "Eval loss: 17.6405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 134/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.60batch/s]\n",
      "Training of epoch 134/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 134/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7196\n",
      "Eval loss: 17.6951\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 135/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.10batch/s]\n",
      "Training of epoch 135/50000: 100%|███████████| 32/32 [00:00<00:00, 45.98batch/s]\u001b[A\n",
      "Eval of epoch 135/50000: 100%|█████████████████| 4/4 [00:00<00:00, 58.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.279\n",
      "Eval loss: 18.2572\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 136/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 136/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 136/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1476\n",
      "Eval loss: 17.2742\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 137/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 137/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 137/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1843\n",
      "Eval loss: 17.3658\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 138/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 138/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 138/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8963\n",
      "Eval loss: 17.385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 139/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 139/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 139/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9201\n",
      "Eval loss: 18.1892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 140/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 140/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 140/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1506\n",
      "Eval loss: 17.5908\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 141/50000: 100%|███████████| 32/32 [00:00<00:00, 51.90batch/s]\n",
      "Training of epoch 141/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 141/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9285\n",
      "Eval loss: 18.1558\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 142/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.12batch/s]\n",
      "Training of epoch 142/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 142/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0245\n",
      "Eval loss: 17.935\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 143/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 143/50000: 100%|███████████| 32/32 [00:00<00:00, 46.25batch/s]\u001b[A\n",
      "Eval of epoch 143/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1076\n",
      "Eval loss: 18.1164\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 144/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 144/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 144/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9907\n",
      "Eval loss: 17.7055\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 145/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.65batch/s]\n",
      "Training of epoch 145/50000: 100%|███████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 145/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1075\n",
      "Eval loss: 17.8741\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 146/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.43batch/s]\n",
      "Training of epoch 146/50000: 100%|███████████| 32/32 [00:00<00:00, 46.23batch/s]\u001b[A\n",
      "Eval of epoch 146/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1073\n",
      "Eval loss: 17.4035\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 147/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.85batch/s]\n",
      "Training of epoch 147/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 147/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0793\n",
      "Eval loss: 17.7479\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 148/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 148/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 148/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9193\n",
      "Eval loss: 17.0328\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 149/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 149/50000: 100%|███████████| 32/32 [00:00<00:00, 45.77batch/s]\u001b[A\n",
      "Eval of epoch 149/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1456\n",
      "Eval loss: 16.8736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 150/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 150/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 150/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.6011\n",
      "Eval loss: 18.8647\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 151/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.58batch/s]\n",
      "Training of epoch 151/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 151/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9942\n",
      "Eval loss: 18.109\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 152/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.60batch/s]\n",
      "Training of epoch 152/50000: 100%|███████████| 32/32 [00:00<00:00, 45.97batch/s]\u001b[A\n",
      "Eval of epoch 152/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9577\n",
      "Eval loss: 17.1999\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 153/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.73batch/s]\n",
      "Training of epoch 153/50000: 100%|███████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 153/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2\n",
      "Eval loss: 18.2808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 154/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.10batch/s]\n",
      "Training of epoch 154/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 154/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0733\n",
      "Eval loss: 17.851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 155/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 155/50000: 100%|███████████| 32/32 [00:00<00:00, 46.09batch/s]\u001b[A\n",
      "Eval of epoch 155/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1521\n",
      "Eval loss: 18.0997\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 156/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.72batch/s]\n",
      "Training of epoch 156/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 156/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9753\n",
      "Eval loss: 18.4659\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 157/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.49batch/s]\n",
      "Training of epoch 157/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 157/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4435\n",
      "Eval loss: 17.4589\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 158/50000: 100%|███████████| 32/32 [00:00<00:00, 52.06batch/s]\n",
      "Training of epoch 158/50000: 100%|███████████| 32/32 [00:00<00:00, 45.90batch/s]\u001b[A\n",
      "Eval of epoch 158/50000: 100%|█████████████████| 4/4 [00:00<00:00, 59.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2026\n",
      "Eval loss: 16.9046\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 159/50000: 100%|███████████| 32/32 [00:00<00:00, 51.64batch/s]\n",
      "Training of epoch 159/50000: 100%|███████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 159/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9205\n",
      "Eval loss: 17.1653\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 160/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 160/50000: 100%|███████████| 32/32 [00:00<00:00, 46.99batch/s]\u001b[A\n",
      "Eval of epoch 160/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.087\n",
      "Eval loss: 19.6663\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 161/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.95batch/s]\n",
      "Training of epoch 161/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 161/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0753\n",
      "Eval loss: 16.7944\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 162/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 162/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 162/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1316\n",
      "Eval loss: 17.4474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 163/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.38batch/s]\n",
      "Training of epoch 163/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 163/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1466\n",
      "Eval loss: 18.3032\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 164/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.01batch/s]\n",
      "Training of epoch 164/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 164/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1147\n",
      "Eval loss: 18.2195\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 165/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.82batch/s]\n",
      "Training of epoch 165/50000: 100%|███████████| 32/32 [00:00<00:00, 45.98batch/s]\u001b[A\n",
      "Eval of epoch 165/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5365\n",
      "Eval loss: 18.3875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 166/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.89batch/s]\n",
      "Training of epoch 166/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 166/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9013\n",
      "Eval loss: 17.772\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 167/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.62batch/s]\n",
      "Training of epoch 167/50000: 100%|███████████| 32/32 [00:00<00:00, 46.26batch/s]\u001b[A\n",
      "Eval of epoch 167/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9194\n",
      "Eval loss: 18.0195\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 168/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.27batch/s]\n",
      "Training of epoch 168/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 168/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2766\n",
      "Eval loss: 17.8136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 169/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 169/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 169/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1011\n",
      "Eval loss: 17.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 170/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.11batch/s]\n",
      "Training of epoch 170/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 170/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8936\n",
      "Eval loss: 17.2918\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 171/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 171/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 171/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2727\n",
      "Eval loss: 16.0571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 172/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 172/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 172/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0064\n",
      "Eval loss: 17.1271\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 173/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.79batch/s]\n",
      "Training of epoch 173/50000: 100%|███████████| 32/32 [00:00<00:00, 45.84batch/s]\u001b[A\n",
      "Eval of epoch 173/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.977\n",
      "Eval loss: 17.1237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 174/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 174/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 174/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0741\n",
      "Eval loss: 17.1838\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 175/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 175/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 175/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2934\n",
      "Eval loss: 17.4341\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 176/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 176/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 176/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9947\n",
      "Eval loss: 17.2355\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 177/50000: 100%|███████████| 32/32 [00:00<00:00, 51.92batch/s]\n",
      "Training of epoch 177/50000: 100%|███████████| 32/32 [00:00<00:00, 45.79batch/s]\u001b[A\n",
      "Eval of epoch 177/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0916\n",
      "Eval loss: 17.2928\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 178/50000: 100%|███████████| 32/32 [00:00<00:00, 52.17batch/s]\n",
      "Training of epoch 178/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 178/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0948\n",
      "Eval loss: 18.0499\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 179/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.89batch/s]\n",
      "Training of epoch 179/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 179/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9933\n",
      "Eval loss: 18.0349\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 180/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.56batch/s]\n",
      "Training of epoch 180/50000: 100%|███████████| 32/32 [00:00<00:00, 46.06batch/s]\u001b[A\n",
      "Eval of epoch 180/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1848\n",
      "Eval loss: 17.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 181/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 181/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 181/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7684\n",
      "Eval loss: 18.105\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 182/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.63batch/s]\n",
      "Training of epoch 182/50000: 100%|███████████| 32/32 [00:00<00:00, 45.94batch/s]\u001b[A\n",
      "Eval of epoch 182/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2087\n",
      "Eval loss: 17.88\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 183/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.27batch/s]\n",
      "Training of epoch 183/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 183/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0458\n",
      "Eval loss: 16.6765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 184/50000: 100%|███████████| 32/32 [00:00<00:00, 52.34batch/s]\n",
      "Training of epoch 184/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 184/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.977\n",
      "Eval loss: 17.5245\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 185/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 185/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 185/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4277\n",
      "Eval loss: 17.6083\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 186/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 186/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 186/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8833\n",
      "Eval loss: 17.4415\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 187/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.98batch/s]\n",
      "Training of epoch 187/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 187/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0185\n",
      "Eval loss: 18.1805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 188/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 48.90batch/s]\n",
      "Training of epoch 188/50000: 100%|███████████| 32/32 [00:00<00:00, 44.93batch/s]\u001b[A\n",
      "Eval of epoch 188/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8439\n",
      "Eval loss: 17.4544\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 189/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 189/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 189/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7565\n",
      "Eval loss: 17.4315\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 190/50000: 100%|███████████| 32/32 [00:00<00:00, 52.08batch/s]\n",
      "Training of epoch 190/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 190/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1023\n",
      "Eval loss: 18.4179\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 191/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 191/50000: 100%|███████████| 32/32 [00:00<00:00, 46.28batch/s]\u001b[A\n",
      "Eval of epoch 191/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0285\n",
      "Eval loss: 16.992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 192/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.14batch/s]\n",
      "Training of epoch 192/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 192/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1133\n",
      "Eval loss: 18.5288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 193/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.96batch/s]\n",
      "Training of epoch 193/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 193/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0785\n",
      "Eval loss: 17.0494\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 194/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 194/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 194/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0416\n",
      "Eval loss: 17.756\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 195/50000: 100%|███████████| 32/32 [00:00<00:00, 52.11batch/s]\n",
      "Training of epoch 195/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 195/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2168\n",
      "Eval loss: 16.9966\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 196/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 196/50000: 100%|███████████| 32/32 [00:00<00:00, 46.26batch/s]\u001b[A\n",
      "Eval of epoch 196/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3547\n",
      "Eval loss: 17.4022\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 197/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.68batch/s]\n",
      "Training of epoch 197/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 197/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1862\n",
      "Eval loss: 18.2976\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 198/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.86batch/s]\n",
      "Training of epoch 198/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 198/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4035\n",
      "Eval loss: 18.3876\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 199/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 199/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 199/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3144\n",
      "Eval loss: 17.8373\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 200/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 200/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 200/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.165\n",
      "Eval loss: 17.172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 201/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.67batch/s]\n",
      "Training of epoch 201/50000: 100%|███████████| 32/32 [00:00<00:00, 47.01batch/s]\u001b[A\n",
      "Eval of epoch 201/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9132\n",
      "Eval loss: 18.6427\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 202/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.86batch/s]\n",
      "Training of epoch 202/50000: 100%|███████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 202/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9097\n",
      "Eval loss: 16.5639\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 203/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 203/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 203/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9211\n",
      "Eval loss: 18.0304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 204/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 204/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 204/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9956\n",
      "Eval loss: 17.8287\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 205/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 205/50000: 100%|███████████| 32/32 [00:00<00:00, 46.73batch/s]\u001b[A\n",
      "Eval of epoch 205/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1572\n",
      "Eval loss: 17.1249\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 206/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.51batch/s]\n",
      "Training of epoch 206/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 206/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0899\n",
      "Eval loss: 16.9641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 207/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 207/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 207/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0702\n",
      "Eval loss: 16.2434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 208/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 208/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 208/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.994\n",
      "Eval loss: 17.9438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 209/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 209/50000: 100%|███████████| 32/32 [00:00<00:00, 46.93batch/s]\u001b[A\n",
      "Eval of epoch 209/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8806\n",
      "Eval loss: 16.667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 210/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 210/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 210/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.914\n",
      "Eval loss: 18.1221\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 211/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 211/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 211/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8407\n",
      "Eval loss: 17.3605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 212/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.80batch/s]\n",
      "Training of epoch 212/50000: 100%|███████████| 32/32 [00:00<00:00, 46.10batch/s]\u001b[A\n",
      "Eval of epoch 212/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.979\n",
      "Eval loss: 17.5808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 213/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.18batch/s]\n",
      "Training of epoch 213/50000: 100%|███████████| 32/32 [00:00<00:00, 45.64batch/s]\u001b[A\n",
      "Eval of epoch 213/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0604\n",
      "Eval loss: 17.1124\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 214/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.56batch/s]\n",
      "Training of epoch 214/50000: 100%|███████████| 32/32 [00:00<00:00, 45.87batch/s]\u001b[A\n",
      "Eval of epoch 214/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0806\n",
      "Eval loss: 16.8567\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 215/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 215/50000: 100%|███████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 215/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.959\n",
      "Eval loss: 17.5875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 216/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.14batch/s]\n",
      "Training of epoch 216/50000: 100%|███████████| 32/32 [00:00<00:00, 45.55batch/s]\u001b[A\n",
      "Eval of epoch 216/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0427\n",
      "Eval loss: 18.5085\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 217/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.64batch/s]\n",
      "Training of epoch 217/50000: 100%|███████████| 32/32 [00:00<00:00, 46.25batch/s]\u001b[A\n",
      "Eval of epoch 217/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1353\n",
      "Eval loss: 17.8413\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 218/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 218/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 218/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.077\n",
      "Eval loss: 18.0318\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 219/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.82batch/s]\n",
      "Training of epoch 219/50000: 100%|███████████| 32/32 [00:00<00:00, 46.23batch/s]\u001b[A\n",
      "Eval of epoch 219/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.986\n",
      "Eval loss: 17.0234\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 220/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.87batch/s]\n",
      "Training of epoch 220/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 220/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2623\n",
      "Eval loss: 17.7354\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 221/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 221/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 221/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0112\n",
      "Eval loss: 17.3005\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 222/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 222/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 222/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9671\n",
      "Eval loss: 17.9373\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 223/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.83batch/s]\n",
      "Training of epoch 223/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 223/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9354\n",
      "Eval loss: 16.6931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 224/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 224/50000: 100%|███████████| 32/32 [00:00<00:00, 46.33batch/s]\u001b[A\n",
      "Eval of epoch 224/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1759\n",
      "Eval loss: 18.5021\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 225/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 225/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 225/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.075\n",
      "Eval loss: 17.5409\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 226/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 226/50000: 100%|███████████| 32/32 [00:00<00:00, 46.55batch/s]\u001b[A\n",
      "Eval of epoch 226/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2511\n",
      "Eval loss: 17.3812\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 227/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 227/50000: 100%|███████████| 32/32 [00:00<00:00, 46.93batch/s]\u001b[A\n",
      "Eval of epoch 227/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9349\n",
      "Eval loss: 18.1417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 228/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 228/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 228/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3273\n",
      "Eval loss: 17.7282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 229/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 229/50000: 100%|███████████| 32/32 [00:00<00:00, 46.73batch/s]\u001b[A\n",
      "Eval of epoch 229/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.113\n",
      "Eval loss: 17.6965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 230/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 230/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 230/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3125\n",
      "Eval loss: 17.4962\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 231/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.11batch/s]\n",
      "Training of epoch 231/50000: 100%|███████████| 32/32 [00:00<00:00, 46.54batch/s]\u001b[A\n",
      "Eval of epoch 231/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9239\n",
      "Eval loss: 17.9415\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 232/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.02batch/s]\n",
      "Training of epoch 232/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 232/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0428\n",
      "Eval loss: 17.4701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 233/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.72batch/s]\n",
      "Training of epoch 233/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 233/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9406\n",
      "Eval loss: 17.6099\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 234/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.58batch/s]\n",
      "Training of epoch 234/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 234/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2104\n",
      "Eval loss: 17.5317\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 235/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 235/50000: 100%|███████████| 32/32 [00:00<00:00, 46.20batch/s]\u001b[A\n",
      "Eval of epoch 235/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1172\n",
      "Eval loss: 17.8366\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 236/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.91batch/s]\n",
      "Training of epoch 236/50000: 100%|███████████| 32/32 [00:00<00:00, 46.05batch/s]\u001b[A\n",
      "Eval of epoch 236/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9991\n",
      "Eval loss: 17.1437\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 237/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 237/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 237/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8806\n",
      "Eval loss: 17.8776\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 238/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 238/50000: 100%|███████████| 32/32 [00:00<00:00, 46.32batch/s]\u001b[A\n",
      "Eval of epoch 238/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0902\n",
      "Eval loss: 15.8747\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 239/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.79batch/s]\n",
      "Training of epoch 239/50000: 100%|███████████| 32/32 [00:00<00:00, 46.97batch/s]\u001b[A\n",
      "Eval of epoch 239/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7381\n",
      "Eval loss: 16.6209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 240/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 240/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 240/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2067\n",
      "Eval loss: 17.6265\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 241/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 241/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 241/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0738\n",
      "Eval loss: 18.3441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 242/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 242/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 242/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0691\n",
      "Eval loss: 19.232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 243/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 243/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 243/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9315\n",
      "Eval loss: 17.149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 244/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 244/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 244/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8748\n",
      "Eval loss: 16.8881\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 245/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.02batch/s]\n",
      "Training of epoch 245/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 245/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9755\n",
      "Eval loss: 17.578\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 246/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 246/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 246/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1138\n",
      "Eval loss: 17.8032\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 247/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 247/50000: 100%|███████████| 32/32 [00:00<00:00, 46.55batch/s]\u001b[A\n",
      "Eval of epoch 247/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3689\n",
      "Eval loss: 18.3207\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 248/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.27batch/s]\n",
      "Training of epoch 248/50000: 100%|███████████| 32/32 [00:00<00:00, 46.73batch/s]\u001b[A\n",
      "Eval of epoch 248/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5663\n",
      "Eval loss: 18.1062\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 249/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.02batch/s]\n",
      "Training of epoch 249/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 249/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2935\n",
      "Eval loss: 18.0664\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 250/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.43batch/s]\n",
      "Training of epoch 250/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 250/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3584\n",
      "Eval loss: 17.0692\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 251/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 251/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 251/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.237\n",
      "Eval loss: 17.4226\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 252/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 252/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 252/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7857\n",
      "Eval loss: 17.1767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 253/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.07batch/s]\n",
      "Training of epoch 253/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 253/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8042\n",
      "Eval loss: 18.1731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 254/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 254/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 254/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0734\n",
      "Eval loss: 17.7458\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 255/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 255/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 255/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8992\n",
      "Eval loss: 17.5139\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 256/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 256/50000: 100%|███████████| 32/32 [00:00<00:00, 46.72batch/s]\u001b[A\n",
      "Eval of epoch 256/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4831\n",
      "Eval loss: 16.9817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 257/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 257/50000: 100%|███████████| 32/32 [00:00<00:00, 46.87batch/s]\u001b[A\n",
      "Eval of epoch 257/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2367\n",
      "Eval loss: 17.1898\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 258/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 258/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 258/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1288\n",
      "Eval loss: 17.6627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 259/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 259/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 259/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0406\n",
      "Eval loss: 18.6391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 260/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 260/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 260/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3534\n",
      "Eval loss: 18.1199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 261/50000:  94%|██████████▎| 30/32 [00:00<00:00, 51.02batch/s]\n",
      "Training of epoch 261/50000: 100%|███████████| 32/32 [00:00<00:00, 47.39batch/s]\u001b[A\n",
      "Eval of epoch 261/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1462\n",
      "Eval loss: 18.4818\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 262/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.36batch/s]\n",
      "Training of epoch 262/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 262/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8981\n",
      "Eval loss: 17.4558\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 263/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 263/50000: 100%|███████████| 32/32 [00:00<00:00, 46.71batch/s]\u001b[A\n",
      "Eval of epoch 263/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8136\n",
      "Eval loss: 18.5088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 264/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.48batch/s]\n",
      "Training of epoch 264/50000: 100%|███████████| 32/32 [00:00<00:00, 46.97batch/s]\u001b[A\n",
      "Eval of epoch 264/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0464\n",
      "Eval loss: 18.3989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 265/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 265/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 265/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9174\n",
      "Eval loss: 17.5557\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 266/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 266/50000: 100%|███████████| 32/32 [00:00<00:00, 46.46batch/s]\u001b[A\n",
      "Eval of epoch 266/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0509\n",
      "Eval loss: 18.0291\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 267/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.19batch/s]\n",
      "Training of epoch 267/50000: 100%|███████████| 32/32 [00:00<00:00, 45.66batch/s]\u001b[A\n",
      "Eval of epoch 267/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0713\n",
      "Eval loss: 16.8785\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 268/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.50batch/s]\n",
      "Training of epoch 268/50000: 100%|███████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 268/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9746\n",
      "Eval loss: 17.7291\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 269/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.71batch/s]\n",
      "Training of epoch 269/50000: 100%|███████████| 32/32 [00:00<00:00, 45.94batch/s]\u001b[A\n",
      "Eval of epoch 269/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.26\n",
      "Eval loss: 17.438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 270/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 270/50000: 100%|███████████| 32/32 [00:00<00:00, 45.08batch/s]\u001b[A\n",
      "Eval of epoch 270/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9676\n",
      "Eval loss: 17.3637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 271/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 271/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 271/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2296\n",
      "Eval loss: 18.1729\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 272/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 272/50000: 100%|███████████| 32/32 [00:00<00:00, 46.57batch/s]\u001b[A\n",
      "Eval of epoch 272/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1882\n",
      "Eval loss: 17.2978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 273/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 273/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 273/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1697\n",
      "Eval loss: 18.2504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 274/50000: 100%|███████████| 32/32 [00:00<00:00, 51.70batch/s]\n",
      "Training of epoch 274/50000: 100%|███████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 274/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2198\n",
      "Eval loss: 17.1165\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 275/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.97batch/s]\n",
      "Training of epoch 275/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 275/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8359\n",
      "Eval loss: 18.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 276/50000: 100%|███████████| 32/32 [00:00<00:00, 52.03batch/s]\n",
      "Training of epoch 276/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 276/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0752\n",
      "Eval loss: 18.0415\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 277/50000: 100%|███████████| 32/32 [00:00<00:00, 51.79batch/s]\n",
      "Training of epoch 277/50000: 100%|███████████| 32/32 [00:00<00:00, 45.89batch/s]\u001b[A\n",
      "Eval of epoch 277/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0805\n",
      "Eval loss: 16.5933\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 278/50000: 100%|███████████| 32/32 [00:00<00:00, 52.06batch/s]\n",
      "Training of epoch 278/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 278/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1563\n",
      "Eval loss: 17.5892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 279/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 279/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 279/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7443\n",
      "Eval loss: 17.7826\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 280/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.99batch/s]\n",
      "Training of epoch 280/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 280/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3266\n",
      "Eval loss: 17.6023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 281/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.48batch/s]\n",
      "Training of epoch 281/50000: 100%|███████████| 32/32 [00:00<00:00, 45.66batch/s]\u001b[A\n",
      "Eval of epoch 281/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6987\n",
      "Eval loss: 16.8909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 282/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.67batch/s]\n",
      "Training of epoch 282/50000: 100%|███████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 282/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9509\n",
      "Eval loss: 19.0974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 283/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.35batch/s]\n",
      "Training of epoch 283/50000: 100%|███████████| 32/32 [00:00<00:00, 46.05batch/s]\u001b[A\n",
      "Eval of epoch 283/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2551\n",
      "Eval loss: 18.822\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 284/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 284/50000: 100%|███████████| 32/32 [00:00<00:00, 45.96batch/s]\u001b[A\n",
      "Eval of epoch 284/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0337\n",
      "Eval loss: 17.8235\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 285/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.46batch/s]\n",
      "Training of epoch 285/50000: 100%|███████████| 32/32 [00:00<00:00, 45.89batch/s]\u001b[A\n",
      "Eval of epoch 285/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2526\n",
      "Eval loss: 17.7108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 286/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.74batch/s]\n",
      "Training of epoch 286/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 286/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8441\n",
      "Eval loss: 17.3025\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 287/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.97batch/s]\n",
      "Training of epoch 287/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 287/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.978\n",
      "Eval loss: 17.5178\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 288/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 288/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 288/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.93\n",
      "Eval loss: 17.6788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 289/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.61batch/s]\n",
      "Training of epoch 289/50000: 100%|███████████| 32/32 [00:00<00:00, 46.20batch/s]\u001b[A\n",
      "Eval of epoch 289/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1457\n",
      "Eval loss: 19.7733\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 290/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.68batch/s]\n",
      "Training of epoch 290/50000: 100%|███████████| 32/32 [00:00<00:00, 45.97batch/s]\u001b[A\n",
      "Eval of epoch 290/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1802\n",
      "Eval loss: 16.8171\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 291/50000: 100%|███████████| 32/32 [00:00<00:00, 52.06batch/s]\n",
      "Training of epoch 291/50000: 100%|███████████| 32/32 [00:00<00:00, 46.33batch/s]\u001b[A\n",
      "Eval of epoch 291/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4049\n",
      "Eval loss: 16.9185\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 292/50000: 100%|███████████| 32/32 [00:00<00:00, 51.74batch/s]\n",
      "Training of epoch 292/50000: 100%|███████████| 32/32 [00:00<00:00, 45.61batch/s]\u001b[A\n",
      "Eval of epoch 292/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1391\n",
      "Eval loss: 17.3886\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 293/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 293/50000: 100%|███████████| 32/32 [00:00<00:00, 46.36batch/s]\u001b[A\n",
      "Eval of epoch 293/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.108\n",
      "Eval loss: 17.1162\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 294/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.96batch/s]\n",
      "Training of epoch 294/50000: 100%|███████████| 32/32 [00:00<00:00, 45.99batch/s]\u001b[A\n",
      "Eval of epoch 294/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.718\n",
      "Eval loss: 18.0877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 295/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.90batch/s]\n",
      "Training of epoch 295/50000: 100%|███████████| 32/32 [00:00<00:00, 45.99batch/s]\u001b[A\n",
      "Eval of epoch 295/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0791\n",
      "Eval loss: 17.3426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 296/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.39batch/s]\n",
      "Training of epoch 296/50000: 100%|███████████| 32/32 [00:00<00:00, 45.95batch/s]\u001b[A\n",
      "Eval of epoch 296/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0379\n",
      "Eval loss: 18.4994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 297/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.75batch/s]\n",
      "Training of epoch 297/50000: 100%|███████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 297/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9104\n",
      "Eval loss: 17.6018\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 298/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 298/50000: 100%|███████████| 32/32 [00:00<00:00, 45.76batch/s]\u001b[A\n",
      "Eval of epoch 298/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7559\n",
      "Eval loss: 17.4481\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 299/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.58batch/s]\n",
      "Training of epoch 299/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 299/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1177\n",
      "Eval loss: 18.2385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 300/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 300/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 300/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.943\n",
      "Eval loss: 16.8377\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 301/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 301/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 301/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9646\n",
      "Eval loss: 18.313\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 302/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.77batch/s]\n",
      "Training of epoch 302/50000: 100%|███████████| 32/32 [00:00<00:00, 46.25batch/s]\u001b[A\n",
      "Eval of epoch 302/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4941\n",
      "Eval loss: 18.3356\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 303/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 303/50000: 100%|███████████| 32/32 [00:00<00:00, 45.29batch/s]\u001b[A\n",
      "Eval of epoch 303/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2421\n",
      "Eval loss: 18.6508\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 304/50000: 100%|███████████| 32/32 [00:00<00:00, 52.16batch/s]\n",
      "Training of epoch 304/50000: 100%|███████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 304/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1387\n",
      "Eval loss: 17.3352\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 305/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 305/50000: 100%|███████████| 32/32 [00:00<00:00, 46.78batch/s]\u001b[A\n",
      "Eval of epoch 305/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0219\n",
      "Eval loss: 18.1246\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 306/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.83batch/s]\n",
      "Training of epoch 306/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 306/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1024\n",
      "Eval loss: 18.2659\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 307/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 307/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 307/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9923\n",
      "Eval loss: 16.5283\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 308/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 308/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 308/50000: 100%|█████████████████| 4/4 [00:00<00:00, 60.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0533\n",
      "Eval loss: 18.8366\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 309/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 309/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 309/50000: 100%|█████████████████| 4/4 [00:00<00:00, 61.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2909\n",
      "Eval loss: 17.2017\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 310/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 310/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 310/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1202\n",
      "Eval loss: 17.7828\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 311/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.27batch/s]\n",
      "Training of epoch 311/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 311/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0544\n",
      "Eval loss: 17.6975\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 312/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 312/50000: 100%|███████████| 32/32 [00:00<00:00, 46.57batch/s]\u001b[A\n",
      "Eval of epoch 312/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1186\n",
      "Eval loss: 18.2561\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 313/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.57batch/s]\n",
      "Training of epoch 313/50000: 100%|███████████| 32/32 [00:00<00:00, 46.73batch/s]\u001b[A\n",
      "Eval of epoch 313/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1556\n",
      "Eval loss: 17.3634\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 314/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.71batch/s]\n",
      "Training of epoch 314/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 314/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7456\n",
      "Eval loss: 17.2767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 315/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 315/50000: 100%|███████████| 32/32 [00:00<00:00, 46.32batch/s]\u001b[A\n",
      "Eval of epoch 315/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9709\n",
      "Eval loss: 18.3163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 316/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.15batch/s]\n",
      "Training of epoch 316/50000: 100%|███████████| 32/32 [00:00<00:00, 45.91batch/s]\u001b[A\n",
      "Eval of epoch 316/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9076\n",
      "Eval loss: 16.592\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 317/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.34batch/s]\n",
      "Training of epoch 317/50000: 100%|███████████| 32/32 [00:00<00:00, 46.23batch/s]\u001b[A\n",
      "Eval of epoch 317/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0746\n",
      "Eval loss: 17.3006\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 318/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.64batch/s]\n",
      "Training of epoch 318/50000: 100%|███████████| 32/32 [00:00<00:00, 46.20batch/s]\u001b[A\n",
      "Eval of epoch 318/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3274\n",
      "Eval loss: 17.7704\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 319/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.04batch/s]\n",
      "Training of epoch 319/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 319/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2474\n",
      "Eval loss: 17.0409\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 320/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 320/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 320/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0484\n",
      "Eval loss: 17.0151\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 321/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.82batch/s]\n",
      "Training of epoch 321/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 321/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2461\n",
      "Eval loss: 17.7895\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 322/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.43batch/s]\n",
      "Training of epoch 322/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 322/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7091\n",
      "Eval loss: 18.7808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 323/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.27batch/s]\n",
      "Training of epoch 323/50000: 100%|███████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 323/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7283\n",
      "Eval loss: 18.5894\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 324/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 324/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 324/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0801\n",
      "Eval loss: 16.4606\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 325/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 325/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 325/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1432\n",
      "Eval loss: 16.7491\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 326/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.48batch/s]\n",
      "Training of epoch 326/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 326/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.7271\n",
      "Eval loss: 17.5547\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 327/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 327/50000: 100%|███████████| 32/32 [00:00<00:00, 46.31batch/s]\u001b[A\n",
      "Eval of epoch 327/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0979\n",
      "Eval loss: 17.2754\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 328/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 328/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 328/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0787\n",
      "Eval loss: 17.4701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 329/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.95batch/s]\n",
      "Training of epoch 329/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 329/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2857\n",
      "Eval loss: 17.5309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 330/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 330/50000: 100%|███████████| 32/32 [00:00<00:00, 46.29batch/s]\u001b[A\n",
      "Eval of epoch 330/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8873\n",
      "Eval loss: 18.5009\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 331/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 331/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 331/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9045\n",
      "Eval loss: 17.2281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 332/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.38batch/s]\n",
      "Training of epoch 332/50000: 100%|███████████| 32/32 [00:00<00:00, 45.92batch/s]\u001b[A\n",
      "Eval of epoch 332/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1223\n",
      "Eval loss: 16.8086\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 333/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 333/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 333/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3655\n",
      "Eval loss: 18.4708\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 334/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.70batch/s]\n",
      "Training of epoch 334/50000: 100%|███████████| 32/32 [00:00<00:00, 46.97batch/s]\u001b[A\n",
      "Eval of epoch 334/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2185\n",
      "Eval loss: 17.2535\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 335/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.69batch/s]\n",
      "Training of epoch 335/50000: 100%|███████████| 32/32 [00:00<00:00, 47.02batch/s]\u001b[A\n",
      "Eval of epoch 335/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9409\n",
      "Eval loss: 16.6438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 336/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.46batch/s]\n",
      "Training of epoch 336/50000: 100%|███████████| 32/32 [00:00<00:00, 46.85batch/s]\u001b[A\n",
      "Eval of epoch 336/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0332\n",
      "Eval loss: 16.8594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 337/50000: 100%|███████████| 32/32 [00:00<00:00, 52.11batch/s]\n",
      "Training of epoch 337/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 337/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0916\n",
      "Eval loss: 17.3164\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 338/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.28batch/s]\n",
      "Training of epoch 338/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 338/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.832\n",
      "Eval loss: 16.5094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 339/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.55batch/s]\n",
      "Training of epoch 339/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 339/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6975\n",
      "Eval loss: 17.5184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 340/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.51batch/s]\n",
      "Training of epoch 340/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 340/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9295\n",
      "Eval loss: 17.5023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 341/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 341/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 341/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9408\n",
      "Eval loss: 17.9936\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 342/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.46batch/s]\n",
      "Training of epoch 342/50000: 100%|███████████| 32/32 [00:00<00:00, 46.84batch/s]\u001b[A\n",
      "Eval of epoch 342/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.628\n",
      "Eval loss: 16.7314\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 343/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.51batch/s]\n",
      "Training of epoch 343/50000: 100%|███████████| 32/32 [00:00<00:00, 46.04batch/s]\u001b[A\n",
      "Eval of epoch 343/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7987\n",
      "Eval loss: 17.9984\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 344/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.85batch/s]\n",
      "Training of epoch 344/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 344/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2541\n",
      "Eval loss: 19.7533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 345/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.36batch/s]\n",
      "Training of epoch 345/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 345/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1575\n",
      "Eval loss: 17.9317\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 346/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.77batch/s]\n",
      "Training of epoch 346/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 346/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0242\n",
      "Eval loss: 17.9974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 347/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 347/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 347/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2536\n",
      "Eval loss: 17.4904\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 348/50000: 100%|███████████| 32/32 [00:00<00:00, 51.94batch/s]\n",
      "Training of epoch 348/50000: 100%|███████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 348/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8618\n",
      "Eval loss: 17.5218\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 349/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.10batch/s]\n",
      "Training of epoch 349/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 349/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.046\n",
      "Eval loss: 18.4223\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 350/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 350/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 350/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1566\n",
      "Eval loss: 17.3333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 351/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 351/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 351/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9531\n",
      "Eval loss: 17.9816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 352/50000: 100%|███████████| 32/32 [00:00<00:00, 51.76batch/s]\n",
      "Training of epoch 352/50000: 100%|███████████| 32/32 [00:00<00:00, 45.74batch/s]\u001b[A\n",
      "Eval of epoch 352/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3615\n",
      "Eval loss: 18.5709\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 353/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.76batch/s]\n",
      "Training of epoch 353/50000: 100%|███████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 353/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.797\n",
      "Eval loss: 17.9569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 354/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 354/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 354/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1984\n",
      "Eval loss: 19.2057\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 355/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.65batch/s]\n",
      "Training of epoch 355/50000: 100%|███████████| 32/32 [00:00<00:00, 47.02batch/s]\u001b[A\n",
      "Eval of epoch 355/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0675\n",
      "Eval loss: 17.5816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 356/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.87batch/s]\n",
      "Training of epoch 356/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 356/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0325\n",
      "Eval loss: 17.4922\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 357/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 357/50000: 100%|███████████| 32/32 [00:00<00:00, 46.06batch/s]\u001b[A\n",
      "Eval of epoch 357/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2158\n",
      "Eval loss: 16.4874\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 358/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.76batch/s]\n",
      "Training of epoch 358/50000: 100%|███████████| 32/32 [00:00<00:00, 46.05batch/s]\u001b[A\n",
      "Eval of epoch 358/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1287\n",
      "Eval loss: 18.3849\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 359/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 359/50000: 100%|███████████| 32/32 [00:00<00:00, 46.71batch/s]\u001b[A\n",
      "Eval of epoch 359/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0116\n",
      "Eval loss: 19.3131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 360/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.58batch/s]\n",
      "Training of epoch 360/50000: 100%|███████████| 32/32 [00:00<00:00, 46.90batch/s]\u001b[A\n",
      "Eval of epoch 360/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4029\n",
      "Eval loss: 16.7223\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 361/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 361/50000: 100%|███████████| 32/32 [00:00<00:00, 45.83batch/s]\u001b[A\n",
      "Eval of epoch 361/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0769\n",
      "Eval loss: 17.4949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 362/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 362/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 362/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9297\n",
      "Eval loss: 17.9769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 363/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 363/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 363/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7645\n",
      "Eval loss: 17.4031\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 364/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 364/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 364/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8209\n",
      "Eval loss: 17.5152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 365/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 365/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 365/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4244\n",
      "Eval loss: 18.4544\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 366/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 366/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 366/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8197\n",
      "Eval loss: 17.2639\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 367/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 367/50000: 100%|███████████| 32/32 [00:00<00:00, 46.72batch/s]\u001b[A\n",
      "Eval of epoch 367/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3377\n",
      "Eval loss: 18.531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 368/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.28batch/s]\n",
      "Training of epoch 368/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 368/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1315\n",
      "Eval loss: 17.3963\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 369/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 369/50000: 100%|███████████| 32/32 [00:00<00:00, 46.43batch/s]\u001b[A\n",
      "Eval of epoch 369/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0471\n",
      "Eval loss: 18.5266\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 370/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 370/50000: 100%|███████████| 32/32 [00:00<00:00, 46.83batch/s]\u001b[A\n",
      "Eval of epoch 370/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1641\n",
      "Eval loss: 17.0493\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 371/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.34batch/s]\n",
      "Training of epoch 371/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 371/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0098\n",
      "Eval loss: 17.4836\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 372/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 372/50000: 100%|███████████| 32/32 [00:00<00:00, 45.70batch/s]\u001b[A\n",
      "Eval of epoch 372/50000: 100%|█████████████████| 4/4 [00:00<00:00, 60.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1617\n",
      "Eval loss: 17.2363\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 373/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.08batch/s]\n",
      "Training of epoch 373/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 373/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.017\n",
      "Eval loss: 18.1847\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 374/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 374/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 374/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8648\n",
      "Eval loss: 17.0772\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 375/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 375/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 375/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7609\n",
      "Eval loss: 17.6129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 376/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.86batch/s]\n",
      "Training of epoch 376/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 376/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.897\n",
      "Eval loss: 18.5545\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 377/50000: 100%|███████████| 32/32 [00:00<00:00, 51.85batch/s]\n",
      "Training of epoch 377/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 377/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9344\n",
      "Eval loss: 17.9006\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 378/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.42batch/s]\n",
      "Training of epoch 378/50000: 100%|███████████| 32/32 [00:00<00:00, 45.90batch/s]\u001b[A\n",
      "Eval of epoch 378/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9483\n",
      "Eval loss: 17.6949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 379/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 379/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 379/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.977\n",
      "Eval loss: 17.7784\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 380/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 380/50000: 100%|███████████| 32/32 [00:00<00:00, 46.54batch/s]\u001b[A\n",
      "Eval of epoch 380/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1956\n",
      "Eval loss: 18.1841\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 381/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.76batch/s]\n",
      "Training of epoch 381/50000: 100%|███████████| 32/32 [00:00<00:00, 47.07batch/s]\u001b[A\n",
      "Eval of epoch 381/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2211\n",
      "Eval loss: 16.9831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 382/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 382/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 382/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4951\n",
      "Eval loss: 18.9669\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 383/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.10batch/s]\n",
      "Training of epoch 383/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 383/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0397\n",
      "Eval loss: 17.0146\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 384/50000: 100%|███████████| 32/32 [00:00<00:00, 52.05batch/s]\n",
      "Training of epoch 384/50000: 100%|███████████| 32/32 [00:00<00:00, 46.25batch/s]\u001b[A\n",
      "Eval of epoch 384/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2935\n",
      "Eval loss: 17.6875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 385/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 385/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 385/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9725\n",
      "Eval loss: 17.2021\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 386/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.34batch/s]\n",
      "Training of epoch 386/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 386/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0441\n",
      "Eval loss: 16.4039\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 387/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 387/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 387/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8349\n",
      "Eval loss: 17.6051\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 388/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 388/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 388/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6672\n",
      "Eval loss: 17.5159\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 389/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 389/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 389/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9514\n",
      "Eval loss: 17.2127\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 390/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 390/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 390/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0491\n",
      "Eval loss: 17.365\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 391/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.55batch/s]\n",
      "Training of epoch 391/50000: 100%|███████████| 32/32 [00:00<00:00, 46.94batch/s]\u001b[A\n",
      "Eval of epoch 391/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2739\n",
      "Eval loss: 17.706\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 392/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.12batch/s]\n",
      "Training of epoch 392/50000: 100%|███████████| 32/32 [00:00<00:00, 46.46batch/s]\u001b[A\n",
      "Eval of epoch 392/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.057\n",
      "Eval loss: 18.5331\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 393/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.55batch/s]\n",
      "Training of epoch 393/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 393/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1795\n",
      "Eval loss: 17.1955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 394/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 394/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 394/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2353\n",
      "Eval loss: 17.6752\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 395/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 395/50000: 100%|███████████| 32/32 [00:00<00:00, 46.89batch/s]\u001b[A\n",
      "Eval of epoch 395/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8947\n",
      "Eval loss: 17.6354\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 396/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 396/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 396/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8535\n",
      "Eval loss: 17.1963\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 397/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 397/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 397/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9078\n",
      "Eval loss: 18.6276\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 398/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.05batch/s]\n",
      "Training of epoch 398/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 398/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0162\n",
      "Eval loss: 16.6228\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 399/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.47batch/s]\n",
      "Training of epoch 399/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 399/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0351\n",
      "Eval loss: 16.8689\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 400/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 400/50000: 100%|███████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 400/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3917\n",
      "Eval loss: 17.6771\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 401/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.56batch/s]\n",
      "Training of epoch 401/50000: 100%|███████████| 32/32 [00:00<00:00, 47.04batch/s]\u001b[A\n",
      "Eval of epoch 401/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.7211\n",
      "Eval loss: 17.3659\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 402/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.55batch/s]\n",
      "Training of epoch 402/50000: 100%|███████████| 32/32 [00:00<00:00, 46.89batch/s]\u001b[A\n",
      "Eval of epoch 402/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8853\n",
      "Eval loss: 19.0657\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 403/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 403/50000: 100%|███████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 403/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7835\n",
      "Eval loss: 17.6201\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 404/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 404/50000: 100%|███████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 404/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3284\n",
      "Eval loss: 17.4382\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 405/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.47batch/s]\n",
      "Training of epoch 405/50000: 100%|███████████| 32/32 [00:00<00:00, 46.87batch/s]\u001b[A\n",
      "Eval of epoch 405/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5861\n",
      "Eval loss: 17.3211\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 406/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.99batch/s]\n",
      "Training of epoch 406/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 406/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.853\n",
      "Eval loss: 17.6953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 407/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 407/50000: 100%|███████████| 32/32 [00:00<00:00, 46.08batch/s]\u001b[A\n",
      "Eval of epoch 407/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3586\n",
      "Eval loss: 18.5724\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 408/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.67batch/s]\n",
      "Training of epoch 408/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 408/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2208\n",
      "Eval loss: 18.397\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 409/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.09batch/s]\n",
      "Training of epoch 409/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 409/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4221\n",
      "Eval loss: 20.1442\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 410/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 410/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 410/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2858\n",
      "Eval loss: 17.5624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 411/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.43batch/s]\n",
      "Training of epoch 411/50000: 100%|███████████| 32/32 [00:00<00:00, 46.85batch/s]\u001b[A\n",
      "Eval of epoch 411/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1331\n",
      "Eval loss: 18.0746\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 412/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 412/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 412/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1204\n",
      "Eval loss: 18.9624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 413/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 413/50000: 100%|███████████| 32/32 [00:00<00:00, 46.05batch/s]\u001b[A\n",
      "Eval of epoch 413/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9961\n",
      "Eval loss: 17.0088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 414/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.90batch/s]\n",
      "Training of epoch 414/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 414/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0096\n",
      "Eval loss: 18.3405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 415/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 415/50000: 100%|███████████| 32/32 [00:00<00:00, 46.83batch/s]\u001b[A\n",
      "Eval of epoch 415/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0863\n",
      "Eval loss: 16.8748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 416/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 416/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 416/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0338\n",
      "Eval loss: 18.6846\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 417/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 417/50000: 100%|███████████| 32/32 [00:00<00:00, 46.77batch/s]\u001b[A\n",
      "Eval of epoch 417/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1812\n",
      "Eval loss: 18.6583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 418/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 418/50000: 100%|███████████| 32/32 [00:00<00:00, 46.93batch/s]\u001b[A\n",
      "Eval of epoch 418/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9338\n",
      "Eval loss: 18.57\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 419/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.60batch/s]\n",
      "Training of epoch 419/50000: 100%|███████████| 32/32 [00:00<00:00, 46.98batch/s]\u001b[A\n",
      "Eval of epoch 419/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7633\n",
      "Eval loss: 17.4505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 420/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 420/50000: 100%|███████████| 32/32 [00:00<00:00, 47.01batch/s]\u001b[A\n",
      "Eval of epoch 420/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8912\n",
      "Eval loss: 16.7335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 421/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 421/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 421/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7382\n",
      "Eval loss: 17.3803\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 422/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.43batch/s]\n",
      "Training of epoch 422/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 422/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3769\n",
      "Eval loss: 20.0055\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 423/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.53batch/s]\n",
      "Training of epoch 423/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 423/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2069\n",
      "Eval loss: 16.84\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 424/50000:  97%|██████████▋| 31/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 424/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 424/50000: 100%|█████████████████| 4/4 [00:00<00:00, 69.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5468\n",
      "Eval loss: 18.4451\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 425/50000:  97%|██████████▋| 31/32 [00:00<00:00, 48.48batch/s]\n",
      "Training of epoch 425/50000: 100%|███████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 425/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1822\n",
      "Eval loss: 17.4461\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 426/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 426/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 426/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4309\n",
      "Eval loss: 18.0022\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 427/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 427/50000: 100%|███████████| 32/32 [00:00<00:00, 45.54batch/s]\u001b[A\n",
      "Eval of epoch 427/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.971\n",
      "Eval loss: 17.2474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 428/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 428/50000: 100%|███████████| 32/32 [00:00<00:00, 45.93batch/s]\u001b[A\n",
      "Eval of epoch 428/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7425\n",
      "Eval loss: 18.3231\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 429/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.42batch/s]\n",
      "Training of epoch 429/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 429/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.089\n",
      "Eval loss: 17.9429\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 430/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.31batch/s]\n",
      "Training of epoch 430/50000: 100%|███████████| 32/32 [00:00<00:00, 45.79batch/s]\u001b[A\n",
      "Eval of epoch 430/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9267\n",
      "Eval loss: 18.3793\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 431/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.65batch/s]\n",
      "Training of epoch 431/50000: 100%|███████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 431/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0685\n",
      "Eval loss: 18.6925\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 432/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.40batch/s]\n",
      "Training of epoch 432/50000: 100%|███████████| 32/32 [00:00<00:00, 45.53batch/s]\u001b[A\n",
      "Eval of epoch 432/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8587\n",
      "Eval loss: 16.5184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 433/50000: 100%|███████████| 32/32 [00:00<00:00, 51.64batch/s]\n",
      "Training of epoch 433/50000: 100%|███████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 433/50000: 100%|█████████████████| 4/4 [00:00<00:00, 58.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.973\n",
      "Eval loss: 17.7066\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 434/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.63batch/s]\n",
      "Training of epoch 434/50000: 100%|███████████| 32/32 [00:00<00:00, 45.76batch/s]\u001b[A\n",
      "Eval of epoch 434/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8926\n",
      "Eval loss: 18.0793\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 435/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.10batch/s]\n",
      "Training of epoch 435/50000: 100%|███████████| 32/32 [00:00<00:00, 45.35batch/s]\u001b[A\n",
      "Eval of epoch 435/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0742\n",
      "Eval loss: 17.8582\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 436/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.55batch/s]\n",
      "Training of epoch 436/50000: 100%|███████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 436/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.161\n",
      "Eval loss: 18.4848\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 437/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.51batch/s]\n",
      "Training of epoch 437/50000: 100%|███████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 437/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1583\n",
      "Eval loss: 18.437\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 438/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 438/50000: 100%|███████████| 32/32 [00:00<00:00, 46.02batch/s]\u001b[A\n",
      "Eval of epoch 438/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0339\n",
      "Eval loss: 17.9311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 439/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.71batch/s]\n",
      "Training of epoch 439/50000: 100%|███████████| 32/32 [00:00<00:00, 45.93batch/s]\u001b[A\n",
      "Eval of epoch 439/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9359\n",
      "Eval loss: 17.9777\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 440/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 440/50000: 100%|███████████| 32/32 [00:00<00:00, 45.97batch/s]\u001b[A\n",
      "Eval of epoch 440/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0107\n",
      "Eval loss: 17.239\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 441/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.74batch/s]\n",
      "Training of epoch 441/50000: 100%|███████████| 32/32 [00:00<00:00, 46.22batch/s]\u001b[A\n",
      "Eval of epoch 441/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5914\n",
      "Eval loss: 17.4679\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 442/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.11batch/s]\n",
      "Training of epoch 442/50000: 100%|███████████| 32/32 [00:00<00:00, 45.34batch/s]\u001b[A\n",
      "Eval of epoch 442/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2374\n",
      "Eval loss: 17.7567\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 443/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.97batch/s]\n",
      "Training of epoch 443/50000: 100%|███████████| 32/32 [00:00<00:00, 46.29batch/s]\u001b[A\n",
      "Eval of epoch 443/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9532\n",
      "Eval loss: 17.2647\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 444/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.04batch/s]\n",
      "Training of epoch 444/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 444/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0671\n",
      "Eval loss: 17.6704\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 445/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.55batch/s]\n",
      "Training of epoch 445/50000: 100%|███████████| 32/32 [00:00<00:00, 45.45batch/s]\u001b[A\n",
      "Eval of epoch 445/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.063\n",
      "Eval loss: 17.7815\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 446/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.32batch/s]\n",
      "Training of epoch 446/50000: 100%|███████████| 32/32 [00:00<00:00, 45.81batch/s]\u001b[A\n",
      "Eval of epoch 446/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2303\n",
      "Eval loss: 17.2873\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 447/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.04batch/s]\n",
      "Training of epoch 447/50000: 100%|███████████| 32/32 [00:00<00:00, 46.50batch/s]\u001b[A\n",
      "Eval of epoch 447/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1437\n",
      "Eval loss: 17.1577\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 448/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 448/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 448/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1053\n",
      "Eval loss: 16.9371\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 449/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 449/50000: 100%|███████████| 32/32 [00:00<00:00, 46.84batch/s]\u001b[A\n",
      "Eval of epoch 449/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2979\n",
      "Eval loss: 17.9843\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 450/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 450/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 450/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8458\n",
      "Eval loss: 18.1683\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 451/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 451/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 451/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.077\n",
      "Eval loss: 18.6192\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 452/50000: 100%|███████████| 32/32 [00:00<00:00, 51.32batch/s]\n",
      "Training of epoch 452/50000: 100%|███████████| 32/32 [00:00<00:00, 45.12batch/s]\u001b[A\n",
      "Eval of epoch 452/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9976\n",
      "Eval loss: 17.1791\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 453/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 453/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 453/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1958\n",
      "Eval loss: 17.3476\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 454/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 454/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 454/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.633\n",
      "Eval loss: 18.6\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 455/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 455/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 455/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3405\n",
      "Eval loss: 17.0298\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 456/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.07batch/s]\n",
      "Training of epoch 456/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 456/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2717\n",
      "Eval loss: 17.2487\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 457/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 457/50000: 100%|███████████| 32/32 [00:00<00:00, 46.75batch/s]\u001b[A\n",
      "Eval of epoch 457/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2145\n",
      "Eval loss: 17.7827\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 458/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.91batch/s]\n",
      "Training of epoch 458/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 458/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.112\n",
      "Eval loss: 17.0243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 459/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 459/50000: 100%|███████████| 32/32 [00:00<00:00, 46.73batch/s]\u001b[A\n",
      "Eval of epoch 459/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1211\n",
      "Eval loss: 18.8129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 460/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 460/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 460/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5298\n",
      "Eval loss: 17.5196\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 461/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.28batch/s]\n",
      "Training of epoch 461/50000: 100%|███████████| 32/32 [00:00<00:00, 46.77batch/s]\u001b[A\n",
      "Eval of epoch 461/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9369\n",
      "Eval loss: 17.4911\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 462/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 462/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 462/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8953\n",
      "Eval loss: 17.4624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 463/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 463/50000: 100%|███████████| 32/32 [00:00<00:00, 46.29batch/s]\u001b[A\n",
      "Eval of epoch 463/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2369\n",
      "Eval loss: 17.6642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 464/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.90batch/s]\n",
      "Training of epoch 464/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 464/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9819\n",
      "Eval loss: 17.2404\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 465/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 465/50000: 100%|███████████| 32/32 [00:00<00:00, 46.87batch/s]\u001b[A\n",
      "Eval of epoch 465/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0486\n",
      "Eval loss: 18.5792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 466/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.02batch/s]\n",
      "Training of epoch 466/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 466/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8111\n",
      "Eval loss: 17.3135\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 467/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 467/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 467/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1258\n",
      "Eval loss: 17.5865\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 468/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.68batch/s]\n",
      "Training of epoch 468/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 468/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0337\n",
      "Eval loss: 17.6523\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 469/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.72batch/s]\n",
      "Training of epoch 469/50000: 100%|███████████| 32/32 [00:00<00:00, 46.20batch/s]\u001b[A\n",
      "Eval of epoch 469/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8706\n",
      "Eval loss: 17.0985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 470/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.85batch/s]\n",
      "Training of epoch 470/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 470/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4129\n",
      "Eval loss: 16.5914\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 471/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.74batch/s]\n",
      "Training of epoch 471/50000: 100%|███████████| 32/32 [00:00<00:00, 46.36batch/s]\u001b[A\n",
      "Eval of epoch 471/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2647\n",
      "Eval loss: 17.4708\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 472/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.68batch/s]\n",
      "Training of epoch 472/50000: 100%|███████████| 32/32 [00:00<00:00, 47.07batch/s]\u001b[A\n",
      "Eval of epoch 472/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0636\n",
      "Eval loss: 17.0359\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 473/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.64batch/s]\n",
      "Training of epoch 473/50000: 100%|███████████| 32/32 [00:00<00:00, 46.94batch/s]\u001b[A\n",
      "Eval of epoch 473/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0319\n",
      "Eval loss: 16.8347\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 474/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 474/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 474/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1918\n",
      "Eval loss: 17.3695\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 475/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.42batch/s]\n",
      "Training of epoch 475/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 475/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2376\n",
      "Eval loss: 16.9045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 476/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.84batch/s]\n",
      "Training of epoch 476/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 476/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2686\n",
      "Eval loss: 17.7298\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 477/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.44batch/s]\n",
      "Training of epoch 477/50000: 100%|███████████| 32/32 [00:00<00:00, 45.94batch/s]\u001b[A\n",
      "Eval of epoch 477/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9206\n",
      "Eval loss: 17.6664\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 478/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.91batch/s]\n",
      "Training of epoch 478/50000: 100%|███████████| 32/32 [00:00<00:00, 46.40batch/s]\u001b[A\n",
      "Eval of epoch 478/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7021\n",
      "Eval loss: 17.6697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 479/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.48batch/s]\n",
      "Training of epoch 479/50000: 100%|███████████| 32/32 [00:00<00:00, 45.84batch/s]\u001b[A\n",
      "Eval of epoch 479/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0137\n",
      "Eval loss: 17.8168\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 480/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.80batch/s]\n",
      "Training of epoch 480/50000: 100%|███████████| 32/32 [00:00<00:00, 46.28batch/s]\u001b[A\n",
      "Eval of epoch 480/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9403\n",
      "Eval loss: 17.7276\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 481/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.02batch/s]\n",
      "Training of epoch 481/50000: 100%|███████████| 32/32 [00:00<00:00, 46.12batch/s]\u001b[A\n",
      "Eval of epoch 481/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8237\n",
      "Eval loss: 16.5697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 482/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.92batch/s]\n",
      "Training of epoch 482/50000: 100%|███████████| 32/32 [00:00<00:00, 46.26batch/s]\u001b[A\n",
      "Eval of epoch 482/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9146\n",
      "Eval loss: 18.5728\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 483/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.65batch/s]\n",
      "Training of epoch 483/50000: 100%|███████████| 32/32 [00:00<00:00, 46.95batch/s]\u001b[A\n",
      "Eval of epoch 483/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7655\n",
      "Eval loss: 17.6612\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 484/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 484/50000: 100%|███████████| 32/32 [00:00<00:00, 46.83batch/s]\u001b[A\n",
      "Eval of epoch 484/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8318\n",
      "Eval loss: 16.7749\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 485/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 485/50000: 100%|███████████| 32/32 [00:00<00:00, 46.78batch/s]\u001b[A\n",
      "Eval of epoch 485/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2106\n",
      "Eval loss: 17.2148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 486/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.61batch/s]\n",
      "Training of epoch 486/50000: 100%|███████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 486/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4227\n",
      "Eval loss: 18.7789\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 487/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.61batch/s]\n",
      "Training of epoch 487/50000: 100%|███████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 487/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0397\n",
      "Eval loss: 17.0217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 488/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 488/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 488/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2644\n",
      "Eval loss: 18.2902\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 489/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.68batch/s]\n",
      "Training of epoch 489/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 489/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0784\n",
      "Eval loss: 18.6861\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 490/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 490/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 490/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1702\n",
      "Eval loss: 16.7411\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 491/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 491/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 491/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0293\n",
      "Eval loss: 18.5916\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 492/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 492/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 492/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1719\n",
      "Eval loss: 17.9797\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 493/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 493/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 493/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1257\n",
      "Eval loss: 16.9249\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 494/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.07batch/s]\n",
      "Training of epoch 494/50000: 100%|███████████| 32/32 [00:00<00:00, 46.50batch/s]\u001b[A\n",
      "Eval of epoch 494/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9138\n",
      "Eval loss: 17.6347\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 495/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.88batch/s]\n",
      "Training of epoch 495/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 495/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.037\n",
      "Eval loss: 17.0862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 496/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 496/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 496/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8283\n",
      "Eval loss: 17.4006\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 497/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 497/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 497/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2663\n",
      "Eval loss: 17.4273\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 498/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 498/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 498/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7857\n",
      "Eval loss: 17.8779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 499/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.88batch/s]\n",
      "Training of epoch 499/50000: 100%|███████████| 32/32 [00:00<00:00, 47.16batch/s]\u001b[A\n",
      "Eval of epoch 499/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0121\n",
      "Eval loss: 17.9191\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 500/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.11batch/s]\n",
      "Training of epoch 500/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 500/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8484\n",
      "Eval loss: 17.6541\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 501/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 501/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 501/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3877\n",
      "Eval loss: 17.0474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 502/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.89batch/s]\n",
      "Training of epoch 502/50000: 100%|███████████| 32/32 [00:00<00:00, 46.32batch/s]\u001b[A\n",
      "Eval of epoch 502/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1786\n",
      "Eval loss: 16.5106\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 503/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 503/50000: 100%|███████████| 32/32 [00:00<00:00, 46.54batch/s]\u001b[A\n",
      "Eval of epoch 503/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1009\n",
      "Eval loss: 18.0641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 504/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.52batch/s]\n",
      "Training of epoch 504/50000: 100%|███████████| 32/32 [00:00<00:00, 46.89batch/s]\u001b[A\n",
      "Eval of epoch 504/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0045\n",
      "Eval loss: 16.9076\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 505/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 505/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 505/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9011\n",
      "Eval loss: 18.2617\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 506/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 506/50000: 100%|███████████| 32/32 [00:00<00:00, 46.52batch/s]\u001b[A\n",
      "Eval of epoch 506/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.337\n",
      "Eval loss: 16.9098\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 507/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.09batch/s]\n",
      "Training of epoch 507/50000: 100%|███████████| 32/32 [00:00<00:00, 46.33batch/s]\u001b[A\n",
      "Eval of epoch 507/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4191\n",
      "Eval loss: 18.1444\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 508/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.07batch/s]\n",
      "Training of epoch 508/50000: 100%|███████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 508/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0555\n",
      "Eval loss: 18.1385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 509/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 509/50000: 100%|███████████| 32/32 [00:00<00:00, 46.09batch/s]\u001b[A\n",
      "Eval of epoch 509/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.017\n",
      "Eval loss: 17.0771\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 510/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.49batch/s]\n",
      "Training of epoch 510/50000: 100%|███████████| 32/32 [00:00<00:00, 45.97batch/s]\u001b[A\n",
      "Eval of epoch 510/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3039\n",
      "Eval loss: 17.2255\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 511/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 511/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 511/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9593\n",
      "Eval loss: 18.0754\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 512/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.86batch/s]\n",
      "Training of epoch 512/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 512/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7843\n",
      "Eval loss: 17.5238\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 513/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.36batch/s]\n",
      "Training of epoch 513/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 513/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1534\n",
      "Eval loss: 17.4823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 514/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 514/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 514/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9105\n",
      "Eval loss: 18.0708\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 515/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 515/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 515/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0736\n",
      "Eval loss: 18.5825\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 516/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.96batch/s]\n",
      "Training of epoch 516/50000: 100%|███████████| 32/32 [00:00<00:00, 46.36batch/s]\u001b[A\n",
      "Eval of epoch 516/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1037\n",
      "Eval loss: 17.9573\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 517/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 517/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 517/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6985\n",
      "Eval loss: 18.7432\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 518/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.57batch/s]\n",
      "Training of epoch 518/50000: 100%|███████████| 32/32 [00:00<00:00, 46.96batch/s]\u001b[A\n",
      "Eval of epoch 518/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1637\n",
      "Eval loss: 17.1539\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 519/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 519/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 519/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0883\n",
      "Eval loss: 17.8467\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 520/50000: 100%|███████████| 32/32 [00:00<00:00, 52.06batch/s]\n",
      "Training of epoch 520/50000: 100%|███████████| 32/32 [00:00<00:00, 46.31batch/s]\u001b[A\n",
      "Eval of epoch 520/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9881\n",
      "Eval loss: 18.0147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 521/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 521/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 521/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9385\n",
      "Eval loss: 18.3083\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 522/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.74batch/s]\n",
      "Training of epoch 522/50000: 100%|███████████| 32/32 [00:00<00:00, 46.38batch/s]\u001b[A\n",
      "Eval of epoch 522/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0407\n",
      "Eval loss: 18.5074\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 523/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.52batch/s]\n",
      "Training of epoch 523/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 523/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5941\n",
      "Eval loss: 17.9076\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 524/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 524/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 524/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8797\n",
      "Eval loss: 17.9743\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 525/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.58batch/s]\n",
      "Training of epoch 525/50000: 100%|███████████| 32/32 [00:00<00:00, 46.90batch/s]\u001b[A\n",
      "Eval of epoch 525/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0747\n",
      "Eval loss: 17.025\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 526/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.46batch/s]\n",
      "Training of epoch 526/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 526/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2219\n",
      "Eval loss: 17.0382\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 527/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 527/50000: 100%|███████████| 32/32 [00:00<00:00, 46.43batch/s]\u001b[A\n",
      "Eval of epoch 527/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8799\n",
      "Eval loss: 17.9298\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 528/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 528/50000: 100%|███████████| 32/32 [00:00<00:00, 47.00batch/s]\u001b[A\n",
      "Eval of epoch 528/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0595\n",
      "Eval loss: 18.5306\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 529/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 529/50000: 100%|███████████| 32/32 [00:00<00:00, 46.88batch/s]\u001b[A\n",
      "Eval of epoch 529/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.328\n",
      "Eval loss: 18.4365\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 530/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 530/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 530/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8898\n",
      "Eval loss: 17.9568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 531/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 531/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 531/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2232\n",
      "Eval loss: 16.9852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 532/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 532/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 532/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9842\n",
      "Eval loss: 17.7419\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 533/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 533/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 533/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1387\n",
      "Eval loss: 17.3237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 534/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.16batch/s]\n",
      "Training of epoch 534/50000: 100%|███████████| 32/32 [00:00<00:00, 46.57batch/s]\u001b[A\n",
      "Eval of epoch 534/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1548\n",
      "Eval loss: 17.7796\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 535/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 535/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 535/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9385\n",
      "Eval loss: 17.0314\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 536/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 536/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 536/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0395\n",
      "Eval loss: 18.6881\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 537/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 537/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 537/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9291\n",
      "Eval loss: 17.9939\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 538/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.48batch/s]\n",
      "Training of epoch 538/50000: 100%|███████████| 32/32 [00:00<00:00, 46.77batch/s]\u001b[A\n",
      "Eval of epoch 538/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1123\n",
      "Eval loss: 17.3259\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 539/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 539/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 539/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5956\n",
      "Eval loss: 19.1069\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 540/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.18batch/s]\n",
      "Training of epoch 540/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 540/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0037\n",
      "Eval loss: 17.7383\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 541/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 541/50000: 100%|███████████| 32/32 [00:00<00:00, 46.35batch/s]\u001b[A\n",
      "Eval of epoch 541/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.141\n",
      "Eval loss: 18.8312\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 542/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.53batch/s]\n",
      "Training of epoch 542/50000: 100%|███████████| 32/32 [00:00<00:00, 46.97batch/s]\u001b[A\n",
      "Eval of epoch 542/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1477\n",
      "Eval loss: 17.6247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 543/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.65batch/s]\n",
      "Training of epoch 543/50000: 100%|███████████| 32/32 [00:00<00:00, 47.10batch/s]\u001b[A\n",
      "Eval of epoch 543/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4211\n",
      "Eval loss: 17.4606\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 544/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.64batch/s]\n",
      "Training of epoch 544/50000: 100%|███████████| 32/32 [00:00<00:00, 46.95batch/s]\u001b[A\n",
      "Eval of epoch 544/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.89\n",
      "Eval loss: 17.6429\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 545/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.59batch/s]\n",
      "Training of epoch 545/50000: 100%|███████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 545/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0871\n",
      "Eval loss: 18.9161\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 546/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.51batch/s]\n",
      "Training of epoch 546/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 546/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3717\n",
      "Eval loss: 18.6014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 547/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 547/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 547/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3024\n",
      "Eval loss: 17.3798\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 548/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.08batch/s]\n",
      "Training of epoch 548/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 548/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3273\n",
      "Eval loss: 18.4061\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 549/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 549/50000: 100%|███████████| 32/32 [00:00<00:00, 46.72batch/s]\u001b[A\n",
      "Eval of epoch 549/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1493\n",
      "Eval loss: 18.4505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 550/50000: 100%|███████████| 32/32 [00:00<00:00, 51.38batch/s]\n",
      "Training of epoch 550/50000: 100%|███████████| 32/32 [00:00<00:00, 45.31batch/s]\u001b[A\n",
      "Eval of epoch 550/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2527\n",
      "Eval loss: 17.6284\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 551/50000: 100%|███████████| 32/32 [00:00<00:00, 51.54batch/s]\n",
      "Training of epoch 551/50000: 100%|███████████| 32/32 [00:00<00:00, 45.52batch/s]\u001b[A\n",
      "Eval of epoch 551/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.055\n",
      "Eval loss: 17.079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 552/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.14batch/s]\n",
      "Training of epoch 552/50000: 100%|███████████| 32/32 [00:00<00:00, 45.71batch/s]\u001b[A\n",
      "Eval of epoch 552/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1271\n",
      "Eval loss: 18.0311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 553/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.86batch/s]\n",
      "Training of epoch 553/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 553/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.004\n",
      "Eval loss: 17.0372\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 554/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.24batch/s]\n",
      "Training of epoch 554/50000: 100%|███████████| 32/32 [00:00<00:00, 46.62batch/s]\u001b[A\n",
      "Eval of epoch 554/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1756\n",
      "Eval loss: 17.0369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 555/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 555/50000: 100%|███████████| 32/32 [00:00<00:00, 46.57batch/s]\u001b[A\n",
      "Eval of epoch 555/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1089\n",
      "Eval loss: 17.7854\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 556/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 556/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 556/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1224\n",
      "Eval loss: 18.225\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 557/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 557/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 557/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7491\n",
      "Eval loss: 17.3891\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 558/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 558/50000: 100%|███████████| 32/32 [00:00<00:00, 46.54batch/s]\u001b[A\n",
      "Eval of epoch 558/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.941\n",
      "Eval loss: 16.2689\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 559/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.14batch/s]\n",
      "Training of epoch 559/50000: 100%|███████████| 32/32 [00:00<00:00, 46.50batch/s]\u001b[A\n",
      "Eval of epoch 559/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0081\n",
      "Eval loss: 17.9637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 560/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 560/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 560/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1043\n",
      "Eval loss: 17.4737\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 561/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.29batch/s]\n",
      "Training of epoch 561/50000: 100%|███████████| 32/32 [00:00<00:00, 46.69batch/s]\u001b[A\n",
      "Eval of epoch 561/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8066\n",
      "Eval loss: 17.59\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 562/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 562/50000: 100%|███████████| 32/32 [00:00<00:00, 46.82batch/s]\u001b[A\n",
      "Eval of epoch 562/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1064\n",
      "Eval loss: 18.1836\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 563/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 563/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 563/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0781\n",
      "Eval loss: 17.6055\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 564/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 564/50000: 100%|███████████| 32/32 [00:00<00:00, 46.71batch/s]\u001b[A\n",
      "Eval of epoch 564/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.038\n",
      "Eval loss: 16.6596\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 565/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.16batch/s]\n",
      "Training of epoch 565/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 565/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8686\n",
      "Eval loss: 17.8395\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 566/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.10batch/s]\n",
      "Training of epoch 566/50000: 100%|███████████| 32/32 [00:00<00:00, 46.09batch/s]\u001b[A\n",
      "Eval of epoch 566/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8668\n",
      "Eval loss: 17.1702\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 567/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 567/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 567/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9245\n",
      "Eval loss: 19.9193\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 568/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.28batch/s]\n",
      "Training of epoch 568/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 568/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9921\n",
      "Eval loss: 17.9922\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 569/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.39batch/s]\n",
      "Training of epoch 569/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 569/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9938\n",
      "Eval loss: 17.5003\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 570/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 570/50000: 100%|███████████| 32/32 [00:00<00:00, 46.78batch/s]\u001b[A\n",
      "Eval of epoch 570/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9497\n",
      "Eval loss: 16.9164\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 571/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 571/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 571/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0416\n",
      "Eval loss: 17.2722\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 572/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.04batch/s]\n",
      "Training of epoch 572/50000: 100%|███████████| 32/32 [00:00<00:00, 46.41batch/s]\u001b[A\n",
      "Eval of epoch 572/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0409\n",
      "Eval loss: 18.1152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 573/50000: 100%|███████████| 32/32 [00:00<00:00, 51.94batch/s]\n",
      "Training of epoch 573/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 573/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0183\n",
      "Eval loss: 19.0127\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 574/50000: 100%|███████████| 32/32 [00:00<00:00, 51.86batch/s]\n",
      "Training of epoch 574/50000: 100%|███████████| 32/32 [00:00<00:00, 45.96batch/s]\u001b[A\n",
      "Eval of epoch 574/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2225\n",
      "Eval loss: 17.4137\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 575/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 575/50000: 100%|███████████| 32/32 [00:00<00:00, 46.76batch/s]\u001b[A\n",
      "Eval of epoch 575/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2173\n",
      "Eval loss: 18.3603\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 576/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.64batch/s]\n",
      "Training of epoch 576/50000: 100%|███████████| 32/32 [00:00<00:00, 46.96batch/s]\u001b[A\n",
      "Eval of epoch 576/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0887\n",
      "Eval loss: 17.3733\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 577/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.16batch/s]\n",
      "Training of epoch 577/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 577/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0023\n",
      "Eval loss: 18.1833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 578/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 578/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 578/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0379\n",
      "Eval loss: 16.658\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 579/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 579/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 579/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9879\n",
      "Eval loss: 17.7631\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 580/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.47batch/s]\n",
      "Training of epoch 580/50000: 100%|███████████| 32/32 [00:00<00:00, 46.75batch/s]\u001b[A\n",
      "Eval of epoch 580/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2156\n",
      "Eval loss: 18.0753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 581/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.69batch/s]\n",
      "Training of epoch 581/50000: 100%|███████████| 32/32 [00:00<00:00, 47.05batch/s]\u001b[A\n",
      "Eval of epoch 581/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2615\n",
      "Eval loss: 18.5501\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 582/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 582/50000: 100%|███████████| 32/32 [00:00<00:00, 46.54batch/s]\u001b[A\n",
      "Eval of epoch 582/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9971\n",
      "Eval loss: 16.9343\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 583/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 583/50000: 100%|███████████| 32/32 [00:00<00:00, 46.64batch/s]\u001b[A\n",
      "Eval of epoch 583/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0669\n",
      "Eval loss: 17.1759\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 584/50000: 100%|███████████| 32/32 [00:00<00:00, 52.03batch/s]\n",
      "Training of epoch 584/50000: 100%|███████████| 32/32 [00:00<00:00, 46.31batch/s]\u001b[A\n",
      "Eval of epoch 584/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9898\n",
      "Eval loss: 16.9381\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 585/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 585/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 585/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0272\n",
      "Eval loss: 16.9256\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 586/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 586/50000: 100%|███████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 586/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3338\n",
      "Eval loss: 17.8297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 587/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.83batch/s]\n",
      "Training of epoch 587/50000: 100%|███████████| 32/32 [00:00<00:00, 46.25batch/s]\u001b[A\n",
      "Eval of epoch 587/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0691\n",
      "Eval loss: 17.5339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 588/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.13batch/s]\n",
      "Training of epoch 588/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 588/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0128\n",
      "Eval loss: 17.7648\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 589/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.36batch/s]\n",
      "Training of epoch 589/50000: 100%|███████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 589/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.22\n",
      "Eval loss: 18.5409\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 590/50000: 100%|███████████| 32/32 [00:00<00:00, 52.04batch/s]\n",
      "Training of epoch 590/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 590/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2933\n",
      "Eval loss: 17.4456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 591/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 591/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 591/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9605\n",
      "Eval loss: 17.627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 592/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 592/50000: 100%|███████████| 32/32 [00:00<00:00, 46.65batch/s]\u001b[A\n",
      "Eval of epoch 592/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2883\n",
      "Eval loss: 17.8157\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 593/50000: 100%|███████████| 32/32 [00:00<00:00, 51.82batch/s]\n",
      "Training of epoch 593/50000: 100%|███████████| 32/32 [00:00<00:00, 45.93batch/s]\u001b[A\n",
      "Eval of epoch 593/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2282\n",
      "Eval loss: 17.3469\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 594/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.38batch/s]\n",
      "Training of epoch 594/50000: 100%|███████████| 32/32 [00:00<00:00, 46.68batch/s]\u001b[A\n",
      "Eval of epoch 594/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0079\n",
      "Eval loss: 17.0385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 595/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.44batch/s]\n",
      "Training of epoch 595/50000: 100%|███████████| 32/32 [00:00<00:00, 46.81batch/s]\u001b[A\n",
      "Eval of epoch 595/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0253\n",
      "Eval loss: 17.0339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 596/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 596/50000: 100%|███████████| 32/32 [00:00<00:00, 46.87batch/s]\u001b[A\n",
      "Eval of epoch 596/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0843\n",
      "Eval loss: 17.1475\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 597/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.40batch/s]\n",
      "Training of epoch 597/50000: 100%|███████████| 32/32 [00:00<00:00, 46.74batch/s]\u001b[A\n",
      "Eval of epoch 597/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2981\n",
      "Eval loss: 17.0899\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 598/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 598/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 598/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1387\n",
      "Eval loss: 19.4653\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 599/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.68batch/s]\n",
      "Training of epoch 599/50000: 100%|███████████| 32/32 [00:00<00:00, 46.90batch/s]\u001b[A\n",
      "Eval of epoch 599/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1523\n",
      "Eval loss: 17.9862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 600/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 600/50000: 100%|███████████| 32/32 [00:00<00:00, 46.48batch/s]\u001b[A\n",
      "Eval of epoch 600/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1411\n",
      "Eval loss: 18.2717\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 601/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.14batch/s]\n",
      "Training of epoch 601/50000: 100%|███████████| 32/32 [00:00<00:00, 46.43batch/s]\u001b[A\n",
      "Eval of epoch 601/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2278\n",
      "Eval loss: 16.8591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 602/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.51batch/s]\n",
      "Training of epoch 602/50000: 100%|███████████| 32/32 [00:00<00:00, 46.80batch/s]\u001b[A\n",
      "Eval of epoch 602/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9233\n",
      "Eval loss: 17.2896\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 603/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 603/50000: 100%|███████████| 32/32 [00:00<00:00, 46.57batch/s]\u001b[A\n",
      "Eval of epoch 603/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2921\n",
      "Eval loss: 18.1089\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 604/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.15batch/s]\n",
      "Training of epoch 604/50000: 100%|███████████| 32/32 [00:00<00:00, 46.51batch/s]\u001b[A\n",
      "Eval of epoch 604/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0023\n",
      "Eval loss: 18.2738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 605/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.19batch/s]\n",
      "Training of epoch 605/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 605/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0033\n",
      "Eval loss: 18.2266\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 606/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 606/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 606/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1831\n",
      "Eval loss: 16.6511\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 607/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 607/50000: 100%|███████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 607/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0692\n",
      "Eval loss: 17.0739\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 608/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.02batch/s]\n",
      "Training of epoch 608/50000: 100%|███████████| 32/32 [00:00<00:00, 47.06batch/s]\u001b[A\n",
      "Eval of epoch 608/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2978\n",
      "Eval loss: 18.0016\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 609/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.08batch/s]\n",
      "Training of epoch 609/50000: 100%|███████████| 32/32 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Eval of epoch 609/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0369\n",
      "Eval loss: 19.3326\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 610/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.85batch/s]\n",
      "Training of epoch 610/50000: 100%|███████████| 32/32 [00:00<00:00, 46.28batch/s]\u001b[A\n",
      "Eval of epoch 610/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0103\n",
      "Eval loss: 18.542\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 611/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 611/50000: 100%|███████████| 32/32 [00:00<00:00, 46.58batch/s]\u001b[A\n",
      "Eval of epoch 611/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3494\n",
      "Eval loss: 18.3124\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 612/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 612/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 612/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9965\n",
      "Eval loss: 17.7456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 613/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.20batch/s]\n",
      "Training of epoch 613/50000: 100%|███████████| 32/32 [00:00<00:00, 46.53batch/s]\u001b[A\n",
      "Eval of epoch 613/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9832\n",
      "Eval loss: 17.6942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 614/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.41batch/s]\n",
      "Training of epoch 614/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 614/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8547\n",
      "Eval loss: 17.2038\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 615/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.32batch/s]\n",
      "Training of epoch 615/50000: 100%|███████████| 32/32 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Eval of epoch 615/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.5141\n",
      "Eval loss: 17.7116\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 616/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.60batch/s]\n",
      "Training of epoch 616/50000: 100%|███████████| 32/32 [00:00<00:00, 47.00batch/s]\u001b[A\n",
      "Eval of epoch 616/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9845\n",
      "Eval loss: 18.5279\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 617/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.77batch/s]\n",
      "Training of epoch 617/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 617/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8828\n",
      "Eval loss: 18.1547\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 618/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.20batch/s]\n",
      "Training of epoch 618/50000: 100%|███████████| 32/32 [00:00<00:00, 47.33batch/s]\u001b[A\n",
      "Eval of epoch 618/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7531\n",
      "Eval loss: 17.2714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 619/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.09batch/s]\n",
      "Training of epoch 619/50000: 100%|███████████| 32/32 [00:00<00:00, 46.33batch/s]\u001b[A\n",
      "Eval of epoch 619/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0263\n",
      "Eval loss: 18.8786\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 620/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.52batch/s]\n",
      "Training of epoch 620/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 620/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9789\n",
      "Eval loss: 17.2344\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 621/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 621/50000: 100%|███████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 621/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6768\n",
      "Eval loss: 19.0173\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 622/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.53batch/s]\n",
      "Training of epoch 622/50000: 100%|███████████| 32/32 [00:00<00:00, 46.92batch/s]\u001b[A\n",
      "Eval of epoch 622/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7952\n",
      "Eval loss: 17.9539\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 623/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.53batch/s]\n",
      "Training of epoch 623/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 623/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0911\n",
      "Eval loss: 17.1865\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 624/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.45batch/s]\n",
      "Training of epoch 624/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 624/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0814\n",
      "Eval loss: 17.4808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 625/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.00batch/s]\n",
      "Training of epoch 625/50000: 100%|███████████| 32/32 [00:00<00:00, 47.25batch/s]\u001b[A\n",
      "Eval of epoch 625/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0558\n",
      "Eval loss: 17.3469\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 626/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.47batch/s]\n",
      "Training of epoch 626/50000: 100%|███████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 626/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0087\n",
      "Eval loss: 17.4978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 627/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.57batch/s]\n",
      "Training of epoch 627/50000: 100%|███████████| 32/32 [00:00<00:00, 46.96batch/s]\u001b[A\n",
      "Eval of epoch 627/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.177\n",
      "Eval loss: 17.1163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 628/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.23batch/s]\n",
      "Training of epoch 628/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 628/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0022\n",
      "Eval loss: 17.3255\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 629/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.13batch/s]\n",
      "Training of epoch 629/50000: 100%|███████████| 32/32 [00:00<00:00, 47.19batch/s]\u001b[A\n",
      "Eval of epoch 629/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7191\n",
      "Eval loss: 16.8374\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 630/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 630/50000: 100%|███████████| 32/32 [00:00<00:00, 46.30batch/s]\u001b[A\n",
      "Eval of epoch 630/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0022\n",
      "Eval loss: 17.8388\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 631/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.74batch/s]\n",
      "Training of epoch 631/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 631/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9081\n",
      "Eval loss: 17.983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 632/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.90batch/s]\n",
      "Training of epoch 632/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 632/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0954\n",
      "Eval loss: 17.6027\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 633/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 48.88batch/s]\n",
      "Training of epoch 633/50000: 100%|███████████| 32/32 [00:00<00:00, 44.99batch/s]\u001b[A\n",
      "Eval of epoch 633/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2876\n",
      "Eval loss: 17.6018\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 634/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.43batch/s]\n",
      "Training of epoch 634/50000: 100%|███████████| 32/32 [00:00<00:00, 46.17batch/s]\u001b[A\n",
      "Eval of epoch 634/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8437\n",
      "Eval loss: 17.0862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 635/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 635/50000: 100%|███████████| 32/32 [00:00<00:00, 46.27batch/s]\u001b[A\n",
      "Eval of epoch 635/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0489\n",
      "Eval loss: 17.5345\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 636/50000: 100%|███████████| 32/32 [00:00<00:00, 51.60batch/s]\n",
      "Training of epoch 636/50000: 100%|███████████| 32/32 [00:00<00:00, 45.49batch/s]\u001b[A\n",
      "Eval of epoch 636/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8674\n",
      "Eval loss: 17.087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 637/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.27batch/s]\n",
      "Training of epoch 637/50000: 100%|███████████| 32/32 [00:00<00:00, 45.42batch/s]\u001b[A\n",
      "Eval of epoch 637/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1849\n",
      "Eval loss: 17.8156\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 638/50000: 100%|███████████| 32/32 [00:00<00:00, 51.61batch/s]\n",
      "Training of epoch 638/50000: 100%|███████████| 32/32 [00:00<00:00, 45.72batch/s]\u001b[A\n",
      "Eval of epoch 638/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7591\n",
      "Eval loss: 18.2161\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 639/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 639/50000: 100%|███████████| 32/32 [00:00<00:00, 45.80batch/s]\u001b[A\n",
      "Eval of epoch 639/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7377\n",
      "Eval loss: 18.3491\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 640/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 640/50000: 100%|███████████| 32/32 [00:00<00:00, 45.65batch/s]\u001b[A\n",
      "Eval of epoch 640/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8519\n",
      "Eval loss: 16.8651\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 641/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.34batch/s]\n",
      "Training of epoch 641/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 641/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9733\n",
      "Eval loss: 17.6869\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 642/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.22batch/s]\n",
      "Training of epoch 642/50000: 100%|███████████| 32/32 [00:00<00:00, 46.49batch/s]\u001b[A\n",
      "Eval of epoch 642/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1516\n",
      "Eval loss: 18.351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 643/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.67batch/s]\n",
      "Training of epoch 643/50000: 100%|███████████| 32/32 [00:00<00:00, 46.34batch/s]\u001b[A\n",
      "Eval of epoch 643/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9828\n",
      "Eval loss: 16.8025\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 644/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.28batch/s]\n",
      "Training of epoch 644/50000: 100%|███████████| 32/32 [00:00<00:00, 46.67batch/s]\u001b[A\n",
      "Eval of epoch 644/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.159\n",
      "Eval loss: 18.288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 645/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.62batch/s]\n",
      "Training of epoch 645/50000: 100%|███████████| 32/32 [00:00<00:00, 45.79batch/s]\u001b[A\n",
      "Eval of epoch 645/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6654\n",
      "Eval loss: 17.1326\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 646/50000: 100%|███████████| 32/32 [00:00<00:00, 51.79batch/s]\n",
      "Training of epoch 646/50000: 100%|███████████| 32/32 [00:00<00:00, 45.99batch/s]\u001b[A\n",
      "Eval of epoch 646/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3461\n",
      "Eval loss: 18.5687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 647/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.95batch/s]\n",
      "Training of epoch 647/50000: 100%|███████████| 32/32 [00:00<00:00, 45.36batch/s]\u001b[A\n",
      "Eval of epoch 647/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8727\n",
      "Eval loss: 17.0363\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 648/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.84batch/s]\n",
      "Training of epoch 648/50000: 100%|███████████| 32/32 [00:00<00:00, 45.58batch/s]\u001b[A\n",
      "Eval of epoch 648/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9193\n",
      "Eval loss: 18.8975\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 649/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.22batch/s]\n",
      "Training of epoch 649/50000: 100%|███████████| 32/32 [00:00<00:00, 45.75batch/s]\u001b[A\n",
      "Eval of epoch 649/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1629\n",
      "Eval loss: 19.1037\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 650/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.38batch/s]\n",
      "Training of epoch 650/50000: 100%|███████████| 32/32 [00:00<00:00, 45.88batch/s]\u001b[A\n",
      "Eval of epoch 650/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8914\n",
      "Eval loss: 17.1749\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 651/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.50batch/s]\n",
      "Training of epoch 651/50000: 100%|███████████| 32/32 [00:00<00:00, 45.73batch/s]\u001b[A\n",
      "Eval of epoch 651/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9562\n",
      "Eval loss: 17.4843\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 652/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.61batch/s]\n",
      "Training of epoch 652/50000: 100%|███████████| 32/32 [00:00<00:00, 45.68batch/s]\u001b[A\n",
      "Eval of epoch 652/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.07\n",
      "Eval loss: 17.5994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 653/50000: 100%|███████████| 32/32 [00:00<00:00, 51.83batch/s]\n",
      "Training of epoch 653/50000: 100%|███████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 653/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4834\n",
      "Eval loss: 17.433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 654/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.42batch/s]\n",
      "Training of epoch 654/50000: 100%|███████████| 32/32 [00:00<00:00, 45.76batch/s]\u001b[A\n",
      "Eval of epoch 654/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0334\n",
      "Eval loss: 16.7497\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 655/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.05batch/s]\n",
      "Training of epoch 655/50000: 100%|███████████| 32/32 [00:00<00:00, 45.46batch/s]\u001b[A\n",
      "Eval of epoch 655/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9868\n",
      "Eval loss: 18.9184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 656/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.81batch/s]\n",
      "Training of epoch 656/50000: 100%|███████████| 32/32 [00:00<00:00, 45.45batch/s]\u001b[A\n",
      "Eval of epoch 656/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1657\n",
      "Eval loss: 16.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 657/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.99batch/s]\n",
      "Training of epoch 657/50000: 100%|███████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 657/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9135\n",
      "Eval loss: 16.9503\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 658/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.83batch/s]\n",
      "Training of epoch 658/50000: 100%|███████████| 32/32 [00:00<00:00, 45.41batch/s]\u001b[A\n",
      "Eval of epoch 658/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9197\n",
      "Eval loss: 17.7517\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 659/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.66batch/s]\n",
      "Training of epoch 659/50000: 100%|███████████| 32/32 [00:00<00:00, 45.92batch/s]\u001b[A\n",
      "Eval of epoch 659/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7821\n",
      "Eval loss: 17.6923\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 660/50000: 100%|███████████| 32/32 [00:00<00:00, 51.70batch/s]\n",
      "Training of epoch 660/50000: 100%|███████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 660/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9352\n",
      "Eval loss: 17.0325\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 661/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.78batch/s]\n",
      "Training of epoch 661/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 661/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9714\n",
      "Eval loss: 17.8511\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 662/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.67batch/s]\n",
      "Training of epoch 662/50000: 100%|███████████| 32/32 [00:00<00:00, 46.06batch/s]\u001b[A\n",
      "Eval of epoch 662/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9866\n",
      "Eval loss: 19.1175\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 663/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.38batch/s]\n",
      "Training of epoch 663/50000: 100%|███████████| 32/32 [00:00<00:00, 45.21batch/s]\u001b[A\n",
      "Eval of epoch 663/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2329\n",
      "Eval loss: 17.5089\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 664/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.45batch/s]\n",
      "Training of epoch 664/50000: 100%|███████████| 32/32 [00:00<00:00, 45.72batch/s]\u001b[A\n",
      "Eval of epoch 664/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8912\n",
      "Eval loss: 18.3686\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 665/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.11batch/s]\n",
      "Training of epoch 665/50000: 100%|███████████| 32/32 [00:00<00:00, 45.31batch/s]\u001b[A\n",
      "Eval of epoch 665/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1767\n",
      "Eval loss: 16.8608\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 666/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 666/50000: 100%|███████████| 32/32 [00:00<00:00, 45.84batch/s]\u001b[A\n",
      "Eval of epoch 666/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8194\n",
      "Eval loss: 16.7732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 667/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.71batch/s]\n",
      "Training of epoch 667/50000: 100%|███████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 667/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8473\n",
      "Eval loss: 18.4974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 668/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.45batch/s]\n",
      "Training of epoch 668/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 668/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9548\n",
      "Eval loss: 16.8973\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 669/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.15batch/s]\n",
      "Training of epoch 669/50000: 100%|███████████| 32/32 [00:00<00:00, 45.46batch/s]\u001b[A\n",
      "Eval of epoch 669/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9249\n",
      "Eval loss: 17.7462\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 670/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.65batch/s]\n",
      "Training of epoch 670/50000: 100%|███████████| 32/32 [00:00<00:00, 46.19batch/s]\u001b[A\n",
      "Eval of epoch 670/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8652\n",
      "Eval loss: 17.4584\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 671/50000: 100%|███████████| 32/32 [00:00<00:00, 51.18batch/s]\n",
      "Training of epoch 671/50000: 100%|███████████| 32/32 [00:00<00:00, 45.71batch/s]\u001b[A\n",
      "Eval of epoch 671/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8359\n",
      "Eval loss: 18.2356\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 672/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 672/50000: 100%|███████████| 32/32 [00:00<00:00, 45.84batch/s]\u001b[A\n",
      "Eval of epoch 672/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0816\n",
      "Eval loss: 17.9006\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 673/50000: 100%|███████████| 32/32 [00:00<00:00, 51.58batch/s]\n",
      "Training of epoch 673/50000: 100%|███████████| 32/32 [00:00<00:00, 45.75batch/s]\u001b[A\n",
      "Eval of epoch 673/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1673\n",
      "Eval loss: 17.3795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 674/50000: 100%|███████████| 32/32 [00:00<00:00, 51.56batch/s]\n",
      "Training of epoch 674/50000: 100%|███████████| 32/32 [00:00<00:00, 45.48batch/s]\u001b[A\n",
      "Eval of epoch 674/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0012\n",
      "Eval loss: 17.2869\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 675/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.16batch/s]\n",
      "Training of epoch 675/50000: 100%|███████████| 32/32 [00:00<00:00, 45.26batch/s]\u001b[A\n",
      "Eval of epoch 675/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0939\n",
      "Eval loss: 18.6401\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 676/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.38batch/s]\n",
      "Training of epoch 676/50000: 100%|███████████| 32/32 [00:00<00:00, 45.62batch/s]\u001b[A\n",
      "Eval of epoch 676/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.4515\n",
      "Eval loss: 17.7596\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 677/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.59batch/s]\n",
      "Training of epoch 677/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 677/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3503\n",
      "Eval loss: 17.9046\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 678/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.68batch/s]\n",
      "Training of epoch 678/50000: 100%|███████████| 32/32 [00:00<00:00, 46.13batch/s]\u001b[A\n",
      "Eval of epoch 678/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1533\n",
      "Eval loss: 18.1438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 679/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.63batch/s]\n",
      "Training of epoch 679/50000: 100%|███████████| 32/32 [00:00<00:00, 46.04batch/s]\u001b[A\n",
      "Eval of epoch 679/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1758\n",
      "Eval loss: 18.5779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 680/50000: 100%|███████████| 32/32 [00:00<00:00, 51.68batch/s]\n",
      "Training of epoch 680/50000: 100%|███████████| 32/32 [00:00<00:00, 45.86batch/s]\u001b[A\n",
      "Eval of epoch 680/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7646\n",
      "Eval loss: 17.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 681/50000: 100%|███████████| 32/32 [00:00<00:00, 51.41batch/s]\n",
      "Training of epoch 681/50000: 100%|███████████| 32/32 [00:00<00:00, 45.55batch/s]\u001b[A\n",
      "Eval of epoch 681/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8834\n",
      "Eval loss: 17.7677\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 682/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.30batch/s]\n",
      "Training of epoch 682/50000: 100%|███████████| 32/32 [00:00<00:00, 45.78batch/s]\u001b[A\n",
      "Eval of epoch 682/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2643\n",
      "Eval loss: 16.6326\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 683/50000: 100%|███████████| 32/32 [00:00<00:00, 51.44batch/s]\n",
      "Training of epoch 683/50000: 100%|███████████| 32/32 [00:00<00:00, 45.52batch/s]\u001b[A\n",
      "Eval of epoch 683/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9693\n",
      "Eval loss: 18.2408\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 684/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.06batch/s]\n",
      "Training of epoch 684/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 684/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9872\n",
      "Eval loss: 16.7976\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 685/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.79batch/s]\n",
      "Training of epoch 685/50000: 100%|███████████| 32/32 [00:00<00:00, 46.24batch/s]\u001b[A\n",
      "Eval of epoch 685/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0232\n",
      "Eval loss: 17.4652\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 686/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.03batch/s]\n",
      "Training of epoch 686/50000: 100%|███████████| 32/32 [00:00<00:00, 46.17batch/s]\u001b[A\n",
      "Eval of epoch 686/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.923\n",
      "Eval loss: 18.4638\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 687/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.46batch/s]\n",
      "Training of epoch 687/50000: 100%|███████████| 32/32 [00:00<00:00, 45.89batch/s]\u001b[A\n",
      "Eval of epoch 687/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7469\n",
      "Eval loss: 18.1766\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 688/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.15batch/s]\n",
      "Training of epoch 688/50000: 100%|███████████| 32/32 [00:00<00:00, 45.80batch/s]\u001b[A\n",
      "Eval of epoch 688/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2419\n",
      "Eval loss: 17.5212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 689/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.94batch/s]\n",
      "Training of epoch 689/50000: 100%|███████████| 32/32 [00:00<00:00, 46.39batch/s]\u001b[A\n",
      "Eval of epoch 689/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9065\n",
      "Eval loss: 17.8527\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 690/50000: 100%|███████████| 32/32 [00:00<00:00, 51.43batch/s]\n",
      "Training of epoch 690/50000: 100%|███████████| 32/32 [00:00<00:00, 45.60batch/s]\u001b[A\n",
      "Eval of epoch 690/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8835\n",
      "Eval loss: 16.8136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 691/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.55batch/s]\n",
      "Training of epoch 691/50000: 100%|███████████| 32/32 [00:00<00:00, 45.80batch/s]\u001b[A\n",
      "Eval of epoch 691/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9073\n",
      "Eval loss: 17.9882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 692/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.22batch/s]\n",
      "Training of epoch 692/50000: 100%|███████████| 32/32 [00:00<00:00, 45.80batch/s]\u001b[A\n",
      "Eval of epoch 692/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1692\n",
      "Eval loss: 17.2583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 693/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.01batch/s]\n",
      "Training of epoch 693/50000: 100%|███████████| 32/32 [00:00<00:00, 45.51batch/s]\u001b[A\n",
      "Eval of epoch 693/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9056\n",
      "Eval loss: 16.8603\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 694/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 694/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 694/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0074\n",
      "Eval loss: 18.7145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 695/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.36batch/s]\n",
      "Training of epoch 695/50000: 100%|███████████| 32/32 [00:00<00:00, 46.09batch/s]\u001b[A\n",
      "Eval of epoch 695/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2077\n",
      "Eval loss: 17.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 696/50000: 100%|███████████| 32/32 [00:00<00:00, 51.79batch/s]\n",
      "Training of epoch 696/50000: 100%|███████████| 32/32 [00:00<00:00, 46.12batch/s]\u001b[A\n",
      "Eval of epoch 696/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.747\n",
      "Eval loss: 18.2583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 697/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.72batch/s]\n",
      "Training of epoch 697/50000: 100%|███████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 697/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8203\n",
      "Eval loss: 17.1184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 698/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.30batch/s]\n",
      "Training of epoch 698/50000: 100%|███████████| 32/32 [00:00<00:00, 45.69batch/s]\u001b[A\n",
      "Eval of epoch 698/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.988\n",
      "Eval loss: 16.5787\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 699/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.29batch/s]\n",
      "Training of epoch 699/50000: 100%|███████████| 32/32 [00:00<00:00, 45.74batch/s]\u001b[A\n",
      "Eval of epoch 699/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.3277\n",
      "Eval loss: 17.7607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 700/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 700/50000: 100%|███████████| 32/32 [00:00<00:00, 46.15batch/s]\u001b[A\n",
      "Eval of epoch 700/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2635\n",
      "Eval loss: 17.4867\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 701/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.90batch/s]\n",
      "Training of epoch 701/50000: 100%|███████████| 32/32 [00:00<00:00, 46.07batch/s]\u001b[A\n",
      "Eval of epoch 701/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0372\n",
      "Eval loss: 18.2283\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 702/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.67batch/s]\n",
      "Training of epoch 702/50000: 100%|███████████| 32/32 [00:00<00:00, 45.82batch/s]\u001b[A\n",
      "Eval of epoch 702/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9556\n",
      "Eval loss: 17.1834\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 703/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.00batch/s]\n",
      "Training of epoch 703/50000: 100%|███████████| 32/32 [00:00<00:00, 46.31batch/s]\u001b[A\n",
      "Eval of epoch 703/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8781\n",
      "Eval loss: 18.594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 704/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.98batch/s]\n",
      "Training of epoch 704/50000: 100%|███████████| 32/32 [00:00<00:00, 46.47batch/s]\u001b[A\n",
      "Eval of epoch 704/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7026\n",
      "Eval loss: 17.4426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 705/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.39batch/s]\n",
      "Training of epoch 705/50000: 100%|███████████| 32/32 [00:00<00:00, 46.06batch/s]\u001b[A\n",
      "Eval of epoch 705/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7273\n",
      "Eval loss: 17.6209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 706/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.97batch/s]\n",
      "Training of epoch 706/50000: 100%|███████████| 32/32 [00:00<00:00, 46.37batch/s]\u001b[A\n",
      "Eval of epoch 706/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9544\n",
      "Eval loss: 17.037\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 707/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.34batch/s]\n",
      "Training of epoch 707/50000: 100%|███████████| 32/32 [00:00<00:00, 46.66batch/s]\u001b[A\n",
      "Eval of epoch 707/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9748\n",
      "Eval loss: 17.6271\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 708/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.17batch/s]\n",
      "Training of epoch 708/50000: 100%|███████████| 32/32 [00:00<00:00, 46.55batch/s]\u001b[A\n",
      "Eval of epoch 708/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7569\n",
      "Eval loss: 17.4237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 709/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.30batch/s]\n",
      "Training of epoch 709/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 709/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0345\n",
      "Eval loss: 17.7241\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 710/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.35batch/s]\n",
      "Training of epoch 710/50000: 100%|███████████| 32/32 [00:00<00:00, 46.72batch/s]\u001b[A\n",
      "Eval of epoch 710/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8266\n",
      "Eval loss: 17.0962\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 711/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 49.30batch/s]\n",
      "Training of epoch 711/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 711/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7259\n",
      "Eval loss: 17.6899\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 712/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 712/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 712/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9423\n",
      "Eval loss: 17.5735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 713/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.12batch/s]\n",
      "Training of epoch 713/50000: 100%|███████████| 32/32 [00:00<00:00, 47.25batch/s]\u001b[A\n",
      "Eval of epoch 713/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9074\n",
      "Eval loss: 16.2164\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 714/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.48batch/s]\n",
      "Training of epoch 714/50000: 100%|███████████| 32/32 [00:00<00:00, 45.58batch/s]\u001b[A\n",
      "Eval of epoch 714/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.2365\n",
      "Eval loss: 16.6457\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 715/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.93batch/s]\n",
      "Training of epoch 715/50000: 100%|███████████| 32/32 [00:00<00:00, 46.18batch/s]\u001b[A\n",
      "Eval of epoch 715/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.998\n",
      "Eval loss: 17.5138\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 716/50000: 100%|███████████| 32/32 [00:00<00:00, 51.79batch/s]\n",
      "Training of epoch 716/50000: 100%|███████████| 32/32 [00:00<00:00, 46.01batch/s]\u001b[A\n",
      "Eval of epoch 716/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8172\n",
      "Eval loss: 17.8463\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 717/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.11batch/s]\n",
      "Training of epoch 717/50000: 100%|███████████| 32/32 [00:00<00:00, 46.44batch/s]\u001b[A\n",
      "Eval of epoch 717/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9224\n",
      "Eval loss: 17.3401\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 718/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.63batch/s]\n",
      "Training of epoch 718/50000: 100%|███████████| 32/32 [00:00<00:00, 46.13batch/s]\u001b[A\n",
      "Eval of epoch 718/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1634\n",
      "Eval loss: 18.993\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 719/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 719/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 719/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7899\n",
      "Eval loss: 17.8784\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 720/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 720/50000: 100%|███████████| 32/32 [00:00<00:00, 46.83batch/s]\u001b[A\n",
      "Eval of epoch 720/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.5331\n",
      "Eval loss: 17.0944\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 721/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.63batch/s]\n",
      "Training of epoch 721/50000: 100%|███████████| 32/32 [00:00<00:00, 46.79batch/s]\u001b[A\n",
      "Eval of epoch 721/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.5266\n",
      "Eval loss: 17.5477\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 722/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.62batch/s]\n",
      "Training of epoch 722/50000: 100%|███████████| 32/32 [00:00<00:00, 46.90batch/s]\u001b[A\n",
      "Eval of epoch 722/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.1151\n",
      "Eval loss: 17.5673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 723/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.59batch/s]\n",
      "Training of epoch 723/50000: 100%|███████████| 32/32 [00:00<00:00, 46.83batch/s]\u001b[A\n",
      "Eval of epoch 723/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6212\n",
      "Eval loss: 17.3869\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 724/50000: 100%|███████████| 32/32 [00:00<00:00, 52.26batch/s]\n",
      "Training of epoch 724/50000: 100%|███████████| 32/32 [00:00<00:00, 46.43batch/s]\u001b[A\n",
      "Eval of epoch 724/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0762\n",
      "Eval loss: 17.438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 725/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 725/50000: 100%|███████████| 32/32 [00:00<00:00, 46.00batch/s]\u001b[A\n",
      "Eval of epoch 725/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6498\n",
      "Eval loss: 17.6839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 726/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.37batch/s]\n",
      "Training of epoch 726/50000: 100%|███████████| 32/32 [00:00<00:00, 46.71batch/s]\u001b[A\n",
      "Eval of epoch 726/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 19.0317\n",
      "Eval loss: 17.0427\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 727/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.01batch/s]\n",
      "Training of epoch 727/50000: 100%|███████████| 32/32 [00:00<00:00, 46.43batch/s]\u001b[A\n",
      "Eval of epoch 727/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9699\n",
      "Eval loss: 17.9878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 728/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.26batch/s]\n",
      "Training of epoch 728/50000: 100%|███████████| 32/32 [00:00<00:00, 46.59batch/s]\u001b[A\n",
      "Eval of epoch 728/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7813\n",
      "Eval loss: 17.7723\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 729/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.09batch/s]\n",
      "Training of epoch 729/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 729/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.868\n",
      "Eval loss: 16.7027\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 730/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 48.60batch/s]\n",
      "Training of epoch 730/50000: 100%|███████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 730/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8284\n",
      "Eval loss: 18.4671\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 731/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.49batch/s]\n",
      "Training of epoch 731/50000: 100%|███████████| 32/32 [00:00<00:00, 46.71batch/s]\u001b[A\n",
      "Eval of epoch 731/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.734\n",
      "Eval loss: 17.0005\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 732/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.64batch/s]\n",
      "Training of epoch 732/50000: 100%|███████████| 32/32 [00:00<00:00, 46.91batch/s]\u001b[A\n",
      "Eval of epoch 732/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.8873\n",
      "Eval loss: 17.2108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 733/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.61batch/s]\n",
      "Training of epoch 733/50000: 100%|███████████| 32/32 [00:00<00:00, 46.95batch/s]\u001b[A\n",
      "Eval of epoch 733/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7235\n",
      "Eval loss: 17.4318\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 734/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.34batch/s]\n",
      "Training of epoch 734/50000: 100%|███████████| 32/32 [00:00<00:00, 46.36batch/s]\u001b[A\n",
      "Eval of epoch 734/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6864\n",
      "Eval loss: 18.084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 735/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.54batch/s]\n",
      "Training of epoch 735/50000: 100%|███████████| 32/32 [00:00<00:00, 46.78batch/s]\u001b[A\n",
      "Eval of epoch 735/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7027\n",
      "Eval loss: 17.8811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 736/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.50batch/s]\n",
      "Training of epoch 736/50000: 100%|███████████| 32/32 [00:00<00:00, 46.79batch/s]\u001b[A\n",
      "Eval of epoch 736/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.4497\n",
      "Eval loss: 18.2299\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 737/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.47batch/s]\n",
      "Training of epoch 737/50000: 100%|███████████| 32/32 [00:00<00:00, 46.77batch/s]\u001b[A\n",
      "Eval of epoch 737/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7734\n",
      "Eval loss: 16.8809\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 738/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.33batch/s]\n",
      "Training of epoch 738/50000: 100%|███████████| 32/32 [00:00<00:00, 46.63batch/s]\u001b[A\n",
      "Eval of epoch 738/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.4438\n",
      "Eval loss: 17.4541\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 739/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.67batch/s]\n",
      "Training of epoch 739/50000: 100%|███████████| 32/32 [00:00<00:00, 47.11batch/s]\u001b[A\n",
      "Eval of epoch 739/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.9237\n",
      "Eval loss: 17.3184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 740/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 51.29batch/s]\n",
      "Training of epoch 740/50000: 100%|███████████| 32/32 [00:00<00:00, 47.43batch/s]\u001b[A\n",
      "Eval of epoch 740/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.7509\n",
      "Eval loss: 16.4147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 741/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.25batch/s]\n",
      "Training of epoch 741/50000: 100%|███████████| 32/32 [00:00<00:00, 46.56batch/s]\u001b[A\n",
      "Eval of epoch 741/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.548\n",
      "Eval loss: 17.1457\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 742/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.21batch/s]\n",
      "Training of epoch 742/50000: 100%|███████████| 32/32 [00:00<00:00, 46.60batch/s]\u001b[A\n",
      "Eval of epoch 742/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.6152\n",
      "Eval loss: 16.9253\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 743/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.31batch/s]\n",
      "Training of epoch 743/50000: 100%|███████████| 32/32 [00:00<00:00, 46.95batch/s]\u001b[A\n",
      "Eval of epoch 743/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.4775\n",
      "Eval loss: 16.8004\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 744/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.46batch/s]\n",
      "Training of epoch 744/50000: 100%|███████████| 32/32 [00:00<00:00, 46.86batch/s]\u001b[A\n",
      "Eval of epoch 744/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.3156\n",
      "Eval loss: 16.4072\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 745/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 50.70batch/s]\n",
      "Training of epoch 745/50000: 100%|███████████| 32/32 [00:00<00:00, 46.99batch/s]\u001b[A\n",
      "Eval of epoch 745/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.5642\n",
      "Eval loss: 17.6478\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 746/50000:  94%|██████████▎| 30/32 [00:00<00:00, 50.90batch/s]\n",
      "Training of epoch 746/50000: 100%|███████████| 32/32 [00:00<00:00, 47.29batch/s]\u001b[A\n",
      "Eval of epoch 746/50000: 100%|█████████████████| 4/4 [00:00<00:00, 68.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.0146\n",
      "Eval loss: 16.6619\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 747/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.16batch/s]\n",
      "Training of epoch 747/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 747/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 18.0553\n",
      "Eval loss: 16.4813\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 748/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.48batch/s]\n",
      "Training of epoch 748/50000: 100%|███████████| 32/32 [00:00<00:00, 46.61batch/s]\u001b[A\n",
      "Eval of epoch 748/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8007\n",
      "Eval loss: 16.1793\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 749/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 50.36batch/s]\n",
      "Training of epoch 749/50000: 100%|███████████| 32/32 [00:00<00:00, 46.42batch/s]\u001b[A\n",
      "Eval of epoch 749/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8444\n",
      "Eval loss: 15.7572\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 750/50000:  97%|██████████▋| 31/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 750/50000: 100%|███████████| 32/32 [00:00<00:00, 44.35batch/s]\u001b[A\n",
      "Eval of epoch 750/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8362\n",
      "Eval loss: 16.2776\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 751/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.26batch/s]\n",
      "Training of epoch 751/50000: 100%|███████████| 32/32 [00:00<00:00, 45.64batch/s]\u001b[A\n",
      "Eval of epoch 751/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8818\n",
      "Eval loss: 17.5628\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 752/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.45batch/s]\n",
      "Training of epoch 752/50000: 100%|███████████| 32/32 [00:00<00:00, 45.85batch/s]\u001b[A\n",
      "Eval of epoch 752/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8819\n",
      "Eval loss: 16.3157\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 753/50000: 100%|███████████| 32/32 [00:00<00:00, 51.91batch/s]\n",
      "Training of epoch 753/50000: 100%|███████████| 32/32 [00:00<00:00, 46.03batch/s]\u001b[A\n",
      "Eval of epoch 753/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6057\n",
      "Eval loss: 16.4009\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 754/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.96batch/s]\n",
      "Training of epoch 754/50000: 100%|███████████| 32/32 [00:00<00:00, 46.14batch/s]\u001b[A\n",
      "Eval of epoch 754/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7445\n",
      "Eval loss: 16.5351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 755/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.72batch/s]\n",
      "Training of epoch 755/50000: 100%|███████████| 32/32 [00:00<00:00, 45.02batch/s]\u001b[A\n",
      "Eval of epoch 755/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5672\n",
      "Eval loss: 16.043\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 756/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.35batch/s]\n",
      "Training of epoch 756/50000: 100%|███████████| 32/32 [00:00<00:00, 45.52batch/s]\u001b[A\n",
      "Eval of epoch 756/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6745\n",
      "Eval loss: 16.6767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 757/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.17batch/s]\n",
      "Training of epoch 757/50000: 100%|███████████| 32/32 [00:00<00:00, 45.72batch/s]\u001b[A\n",
      "Eval of epoch 757/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5058\n",
      "Eval loss: 16.4193\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 758/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.39batch/s]\n",
      "Training of epoch 758/50000: 100%|███████████| 32/32 [00:00<00:00, 45.35batch/s]\u001b[A\n",
      "Eval of epoch 758/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5616\n",
      "Eval loss: 16.8646\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 759/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.91batch/s]\n",
      "Training of epoch 759/50000: 100%|███████████| 32/32 [00:00<00:00, 46.11batch/s]\u001b[A\n",
      "Eval of epoch 759/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7933\n",
      "Eval loss: 15.7179\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 760/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.47batch/s]\n",
      "Training of epoch 760/50000: 100%|███████████| 32/32 [00:00<00:00, 45.44batch/s]\u001b[A\n",
      "Eval of epoch 760/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9666\n",
      "Eval loss: 16.4014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 761/50000:  88%|█████████▋ | 28/32 [00:00<00:00, 49.96batch/s]\n",
      "Training of epoch 761/50000: 100%|███████████| 32/32 [00:00<00:00, 45.98batch/s]\u001b[A\n",
      "Eval of epoch 761/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7512\n",
      "Eval loss: 17.5769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 762/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 50.07batch/s]\n",
      "Training of epoch 762/50000: 100%|███████████| 32/32 [00:00<00:00, 45.60batch/s]\u001b[A\n",
      "Eval of epoch 762/50000: 100%|█████████████████| 4/4 [00:00<00:00, 56.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7444\n",
      "Eval loss: 15.6355\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 763/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.74batch/s]\n",
      "Training of epoch 763/50000: 100%|███████████| 32/32 [00:00<00:00, 44.88batch/s]\u001b[A\n",
      "Eval of epoch 763/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5292\n",
      "Eval loss: 16.8058\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 764/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.12batch/s]\n",
      "Training of epoch 764/50000: 100%|███████████| 32/32 [00:00<00:00, 44.49batch/s]\u001b[A\n",
      "Eval of epoch 764/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7542\n",
      "Eval loss: 16.5033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 765/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.61batch/s]\n",
      "Training of epoch 765/50000: 100%|███████████| 32/32 [00:00<00:00, 44.98batch/s]\u001b[A\n",
      "Eval of epoch 765/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4592\n",
      "Eval loss: 15.7087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 766/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.71batch/s]\n",
      "Training of epoch 766/50000: 100%|███████████| 32/32 [00:00<00:00, 44.19batch/s]\u001b[A\n",
      "Eval of epoch 766/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6095\n",
      "Eval loss: 16.6604\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 767/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.50batch/s]\n",
      "Training of epoch 767/50000: 100%|███████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 767/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7336\n",
      "Eval loss: 15.6225\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 768/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.07batch/s]\n",
      "Training of epoch 768/50000: 100%|███████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 768/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9242\n",
      "Eval loss: 16.183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 769/50000: 100%|███████████| 32/32 [00:00<00:00, 51.32batch/s]\n",
      "Training of epoch 769/50000: 100%|███████████| 32/32 [00:00<00:00, 45.29batch/s]\u001b[A\n",
      "Eval of epoch 769/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4972\n",
      "Eval loss: 16.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 770/50000:  97%|██████████▋| 31/32 [00:00<00:00, 48.96batch/s]\n",
      "Training of epoch 770/50000: 100%|███████████| 32/32 [00:00<00:00, 45.45batch/s]\u001b[A\n",
      "Eval of epoch 770/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9035\n",
      "Eval loss: 17.6746\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 771/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.38batch/s]\n",
      "Training of epoch 771/50000: 100%|███████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 771/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9004\n",
      "Eval loss: 16.628\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 772/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.55batch/s]\n",
      "Training of epoch 772/50000: 100%|███████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 772/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5704\n",
      "Eval loss: 17.6292\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 773/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.45batch/s]\n",
      "Training of epoch 773/50000: 100%|███████████| 32/32 [00:00<00:00, 45.58batch/s]\u001b[A\n",
      "Eval of epoch 773/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5994\n",
      "Eval loss: 17.1427\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 774/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.53batch/s]\n",
      "Training of epoch 774/50000: 100%|███████████| 32/32 [00:00<00:00, 43.38batch/s]\u001b[A\n",
      "Eval of epoch 774/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5984\n",
      "Eval loss: 16.1389\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 775/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.71batch/s]\n",
      "Training of epoch 775/50000: 100%|███████████| 32/32 [00:00<00:00, 44.14batch/s]\u001b[A\n",
      "Eval of epoch 775/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6025\n",
      "Eval loss: 16.0775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 776/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.64batch/s]\n",
      "Training of epoch 776/50000: 100%|███████████| 32/32 [00:00<00:00, 44.42batch/s]\u001b[A\n",
      "Eval of epoch 776/50000: 100%|█████████████████| 4/4 [00:00<00:00, 59.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.549\n",
      "Eval loss: 15.4703\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 777/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.38batch/s]\n",
      "Training of epoch 777/50000: 100%|███████████| 32/32 [00:00<00:00, 44.60batch/s]\u001b[A\n",
      "Eval of epoch 777/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4343\n",
      "Eval loss: 16.4599\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 778/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.69batch/s]\n",
      "Training of epoch 778/50000: 100%|███████████| 32/32 [00:00<00:00, 44.94batch/s]\u001b[A\n",
      "Eval of epoch 778/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8463\n",
      "Eval loss: 16.9792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 779/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.70batch/s]\n",
      "Training of epoch 779/50000: 100%|███████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 779/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4831\n",
      "Eval loss: 15.6749\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 780/50000:  84%|█████████▎ | 27/32 [00:00<00:00, 49.40batch/s]\n",
      "Training of epoch 780/50000: 100%|███████████| 32/32 [00:00<00:00, 45.67batch/s]\u001b[A\n",
      "Eval of epoch 780/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.674\n",
      "Eval loss: 16.2178\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 781/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.04batch/s]\n",
      "Training of epoch 781/50000: 100%|███████████| 32/32 [00:00<00:00, 45.16batch/s]\u001b[A\n",
      "Eval of epoch 781/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6446\n",
      "Eval loss: 16.4964\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 782/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.70batch/s]\n",
      "Training of epoch 782/50000: 100%|███████████| 32/32 [00:00<00:00, 45.10batch/s]\u001b[A\n",
      "Eval of epoch 782/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7197\n",
      "Eval loss: 16.2392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 783/50000:  97%|██████████▋| 31/32 [00:00<00:00, 48.92batch/s]\n",
      "Training of epoch 783/50000: 100%|███████████| 32/32 [00:00<00:00, 45.43batch/s]\u001b[A\n",
      "Eval of epoch 783/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3992\n",
      "Eval loss: 16.7145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 784/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.09batch/s]\n",
      "Training of epoch 784/50000: 100%|███████████| 32/32 [00:00<00:00, 45.45batch/s]\u001b[A\n",
      "Eval of epoch 784/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6774\n",
      "Eval loss: 16.559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 785/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.95batch/s]\n",
      "Training of epoch 785/50000: 100%|███████████| 32/32 [00:00<00:00, 45.41batch/s]\u001b[A\n",
      "Eval of epoch 785/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6348\n",
      "Eval loss: 16.4153\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 786/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.28batch/s]\n",
      "Training of epoch 786/50000: 100%|███████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 786/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.533\n",
      "Eval loss: 16.3272\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 787/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.41batch/s]\n",
      "Training of epoch 787/50000: 100%|███████████| 32/32 [00:00<00:00, 44.96batch/s]\u001b[A\n",
      "Eval of epoch 787/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5543\n",
      "Eval loss: 16.367\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 788/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.69batch/s]\n",
      "Training of epoch 788/50000: 100%|███████████| 32/32 [00:00<00:00, 44.89batch/s]\u001b[A\n",
      "Eval of epoch 788/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.489\n",
      "Eval loss: 15.9355\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 789/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 789/50000: 100%|███████████| 32/32 [00:00<00:00, 44.98batch/s]\u001b[A\n",
      "Eval of epoch 789/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4518\n",
      "Eval loss: 16.0831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 790/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.30batch/s]\n",
      "Training of epoch 790/50000: 100%|███████████| 32/32 [00:00<00:00, 45.24batch/s]\u001b[A\n",
      "Eval of epoch 790/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4952\n",
      "Eval loss: 17.2911\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 791/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.20batch/s]\n",
      "Training of epoch 791/50000: 100%|███████████| 32/32 [00:00<00:00, 44.41batch/s]\u001b[A\n",
      "Eval of epoch 791/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3908\n",
      "Eval loss: 17.0904\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 792/50000:  97%|██████████▋| 31/32 [00:00<00:00, 48.98batch/s]\n",
      "Training of epoch 792/50000: 100%|███████████| 32/32 [00:00<00:00, 44.37batch/s]\u001b[A\n",
      "Eval of epoch 792/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3184\n",
      "Eval loss: 15.9611\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 793/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.66batch/s]\n",
      "Training of epoch 793/50000: 100%|███████████| 32/32 [00:00<00:00, 45.04batch/s]\u001b[A\n",
      "Eval of epoch 793/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3804\n",
      "Eval loss: 16.1763\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 794/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.40batch/s]\n",
      "Training of epoch 794/50000: 100%|███████████| 32/32 [00:00<00:00, 45.03batch/s]\u001b[A\n",
      "Eval of epoch 794/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7853\n",
      "Eval loss: 16.822\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 795/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.24batch/s]\n",
      "Training of epoch 795/50000: 100%|███████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 795/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.514\n",
      "Eval loss: 15.6774\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 796/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.00batch/s]\n",
      "Training of epoch 796/50000: 100%|███████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 796/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5419\n",
      "Eval loss: 16.1166\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 797/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.73batch/s]\n",
      "Training of epoch 797/50000: 100%|███████████| 32/32 [00:00<00:00, 45.04batch/s]\u001b[A\n",
      "Eval of epoch 797/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4199\n",
      "Eval loss: 16.1325\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 798/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.21batch/s]\n",
      "Training of epoch 798/50000: 100%|███████████| 32/32 [00:00<00:00, 44.82batch/s]\u001b[A\n",
      "Eval of epoch 798/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3417\n",
      "Eval loss: 16.2576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 799/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.89batch/s]\n",
      "Training of epoch 799/50000: 100%|███████████| 32/32 [00:00<00:00, 45.29batch/s]\u001b[A\n",
      "Eval of epoch 799/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4236\n",
      "Eval loss: 17.057\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 800/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.29batch/s]\n",
      "Training of epoch 800/50000: 100%|███████████| 32/32 [00:00<00:00, 45.26batch/s]\u001b[A\n",
      "Eval of epoch 800/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5547\n",
      "Eval loss: 16.4195\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 801/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.81batch/s]\n",
      "Training of epoch 801/50000: 100%|███████████| 32/32 [00:00<00:00, 46.16batch/s]\u001b[A\n",
      "Eval of epoch 801/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6414\n",
      "Eval loss: 16.0692\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 802/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.36batch/s]\n",
      "Training of epoch 802/50000: 100%|███████████| 32/32 [00:00<00:00, 44.92batch/s]\u001b[A\n",
      "Eval of epoch 802/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5927\n",
      "Eval loss: 17.1418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 803/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.44batch/s]\n",
      "Training of epoch 803/50000: 100%|███████████| 32/32 [00:00<00:00, 44.45batch/s]\u001b[A\n",
      "Eval of epoch 803/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6028\n",
      "Eval loss: 15.9903\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 804/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.40batch/s]\n",
      "Training of epoch 804/50000: 100%|███████████| 32/32 [00:00<00:00, 44.77batch/s]\u001b[A\n",
      "Eval of epoch 804/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5239\n",
      "Eval loss: 15.8832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 805/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.02batch/s]\n",
      "Training of epoch 805/50000: 100%|███████████| 32/32 [00:00<00:00, 44.40batch/s]\u001b[A\n",
      "Eval of epoch 805/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5201\n",
      "Eval loss: 16.1944\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 806/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.15batch/s]\n",
      "Training of epoch 806/50000: 100%|███████████| 32/32 [00:00<00:00, 45.49batch/s]\u001b[A\n",
      "Eval of epoch 806/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2938\n",
      "Eval loss: 15.9075\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 807/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.85batch/s]\n",
      "Training of epoch 807/50000: 100%|███████████| 32/32 [00:00<00:00, 45.18batch/s]\u001b[A\n",
      "Eval of epoch 807/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6977\n",
      "Eval loss: 16.6331\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 808/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.32batch/s]\n",
      "Training of epoch 808/50000: 100%|███████████| 32/32 [00:00<00:00, 44.86batch/s]\u001b[A\n",
      "Eval of epoch 808/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5158\n",
      "Eval loss: 16.2145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 809/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.86batch/s]\n",
      "Training of epoch 809/50000: 100%|███████████| 32/32 [00:00<00:00, 45.15batch/s]\u001b[A\n",
      "Eval of epoch 809/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4757\n",
      "Eval loss: 17.644\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 810/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.16batch/s]\n",
      "Training of epoch 810/50000: 100%|███████████| 32/32 [00:00<00:00, 45.21batch/s]\u001b[A\n",
      "Eval of epoch 810/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7124\n",
      "Eval loss: 16.5766\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 811/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.79batch/s]\n",
      "Training of epoch 811/50000: 100%|███████████| 32/32 [00:00<00:00, 44.39batch/s]\u001b[A\n",
      "Eval of epoch 811/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6812\n",
      "Eval loss: 16.1548\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 812/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.50batch/s]\n",
      "Training of epoch 812/50000: 100%|███████████| 32/32 [00:00<00:00, 44.99batch/s]\u001b[A\n",
      "Eval of epoch 812/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7586\n",
      "Eval loss: 16.5005\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 813/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.60batch/s]\n",
      "Training of epoch 813/50000: 100%|███████████| 32/32 [00:00<00:00, 45.05batch/s]\u001b[A\n",
      "Eval of epoch 813/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7774\n",
      "Eval loss: 15.9603\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 814/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.81batch/s]\n",
      "Training of epoch 814/50000: 100%|███████████| 32/32 [00:00<00:00, 44.54batch/s]\u001b[A\n",
      "Eval of epoch 814/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5989\n",
      "Eval loss: 16.7871\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 815/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.39batch/s]\n",
      "Training of epoch 815/50000: 100%|███████████| 32/32 [00:00<00:00, 44.77batch/s]\u001b[A\n",
      "Eval of epoch 815/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4076\n",
      "Eval loss: 16.4907\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 816/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.49batch/s]\n",
      "Training of epoch 816/50000: 100%|███████████| 32/32 [00:00<00:00, 44.05batch/s]\u001b[A\n",
      "Eval of epoch 816/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6748\n",
      "Eval loss: 16.8893\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 817/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.26batch/s]\n",
      "Training of epoch 817/50000: 100%|███████████| 32/32 [00:00<00:00, 44.55batch/s]\u001b[A\n",
      "Eval of epoch 817/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5977\n",
      "Eval loss: 17.1912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 818/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.13batch/s]\n",
      "Training of epoch 818/50000: 100%|███████████| 32/32 [00:00<00:00, 44.54batch/s]\u001b[A\n",
      "Eval of epoch 818/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6582\n",
      "Eval loss: 16.0288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 819/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.35batch/s]\n",
      "Training of epoch 819/50000: 100%|███████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 819/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6302\n",
      "Eval loss: 18.1676\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 820/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.74batch/s]\n",
      "Training of epoch 820/50000: 100%|███████████| 32/32 [00:00<00:00, 44.01batch/s]\u001b[A\n",
      "Eval of epoch 820/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7089\n",
      "Eval loss: 16.9473\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 821/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.64batch/s]\n",
      "Training of epoch 821/50000: 100%|███████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 821/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7121\n",
      "Eval loss: 16.2313\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 822/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.87batch/s]\n",
      "Training of epoch 822/50000: 100%|███████████| 32/32 [00:00<00:00, 44.37batch/s]\u001b[A\n",
      "Eval of epoch 822/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6779\n",
      "Eval loss: 16.2939\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 823/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.85batch/s]\n",
      "Training of epoch 823/50000: 100%|███████████| 32/32 [00:00<00:00, 44.33batch/s]\u001b[A\n",
      "Eval of epoch 823/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4588\n",
      "Eval loss: 16.7071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 824/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 824/50000: 100%|███████████| 32/32 [00:00<00:00, 44.52batch/s]\u001b[A\n",
      "Eval of epoch 824/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8361\n",
      "Eval loss: 16.2521\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 825/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.26batch/s]\n",
      "Training of epoch 825/50000: 100%|███████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 825/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.96\n",
      "Eval loss: 15.9343\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 826/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 826/50000: 100%|███████████| 32/32 [00:00<00:00, 44.40batch/s]\u001b[A\n",
      "Eval of epoch 826/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8308\n",
      "Eval loss: 17.2628\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 827/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.62batch/s]\n",
      "Training of epoch 827/50000: 100%|███████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 827/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6859\n",
      "Eval loss: 16.3985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 828/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 828/50000: 100%|███████████| 32/32 [00:00<00:00, 44.82batch/s]\u001b[A\n",
      "Eval of epoch 828/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5599\n",
      "Eval loss: 16.4568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 829/50000:  97%|██████████▋| 31/32 [00:00<00:00, 49.37batch/s]\n",
      "Training of epoch 829/50000: 100%|███████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 829/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6609\n",
      "Eval loss: 16.7148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 830/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.53batch/s]\n",
      "Training of epoch 830/50000: 100%|███████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 830/50000: 100%|█████████████████| 4/4 [00:00<00:00, 67.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8622\n",
      "Eval loss: 15.8122\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 831/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.85batch/s]\n",
      "Training of epoch 831/50000: 100%|███████████| 32/32 [00:00<00:00, 44.51batch/s]\u001b[A\n",
      "Eval of epoch 831/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6884\n",
      "Eval loss: 16.2544\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 832/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.28batch/s]\n",
      "Training of epoch 832/50000: 100%|███████████| 32/32 [00:00<00:00, 45.57batch/s]\u001b[A\n",
      "Eval of epoch 832/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3748\n",
      "Eval loss: 16.1059\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 833/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.44batch/s]\n",
      "Training of epoch 833/50000: 100%|███████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 833/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4583\n",
      "Eval loss: 16.3076\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 834/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.49batch/s]\n",
      "Training of epoch 834/50000: 100%|███████████| 32/32 [00:00<00:00, 44.80batch/s]\u001b[A\n",
      "Eval of epoch 834/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5535\n",
      "Eval loss: 15.9035\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 835/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.11batch/s]\n",
      "Training of epoch 835/50000: 100%|███████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 835/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4185\n",
      "Eval loss: 16.6676\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 836/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.96batch/s]\n",
      "Training of epoch 836/50000: 100%|███████████| 32/32 [00:00<00:00, 44.40batch/s]\u001b[A\n",
      "Eval of epoch 836/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6796\n",
      "Eval loss: 16.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 837/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.02batch/s]\n",
      "Training of epoch 837/50000: 100%|███████████| 32/32 [00:00<00:00, 44.19batch/s]\u001b[A\n",
      "Eval of epoch 837/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8214\n",
      "Eval loss: 16.0191\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 838/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.59batch/s]\n",
      "Training of epoch 838/50000: 100%|███████████| 32/32 [00:00<00:00, 44.26batch/s]\u001b[A\n",
      "Eval of epoch 838/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.684\n",
      "Eval loss: 15.3243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 839/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.25batch/s]\n",
      "Training of epoch 839/50000: 100%|███████████| 32/32 [00:00<00:00, 44.80batch/s]\u001b[A\n",
      "Eval of epoch 839/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4555\n",
      "Eval loss: 16.1468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 840/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.08batch/s]\n",
      "Training of epoch 840/50000: 100%|███████████| 32/32 [00:00<00:00, 45.27batch/s]\u001b[A\n",
      "Eval of epoch 840/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.582\n",
      "Eval loss: 16.345\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 841/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.92batch/s]\n",
      "Training of epoch 841/50000: 100%|███████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 841/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5184\n",
      "Eval loss: 16.5884\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 842/50000:  91%|█████████▉ | 29/32 [00:00<00:00, 46.99batch/s]\n",
      "Training of epoch 842/50000: 100%|███████████| 32/32 [00:00<00:00, 43.43batch/s]\u001b[A\n",
      "Eval of epoch 842/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4811\n",
      "Eval loss: 17.0114\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 843/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.87batch/s]\n",
      "Training of epoch 843/50000: 100%|███████████| 32/32 [00:00<00:00, 45.15batch/s]\u001b[A\n",
      "Eval of epoch 843/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4762\n",
      "Eval loss: 16.579\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 844/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.31batch/s]\n",
      "Training of epoch 844/50000: 100%|███████████| 32/32 [00:00<00:00, 45.47batch/s]\u001b[A\n",
      "Eval of epoch 844/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3121\n",
      "Eval loss: 16.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 845/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.90batch/s]\n",
      "Training of epoch 845/50000: 100%|███████████| 32/32 [00:00<00:00, 45.28batch/s]\u001b[A\n",
      "Eval of epoch 845/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6574\n",
      "Eval loss: 14.9626\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 846/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 846/50000: 100%|███████████| 32/32 [00:00<00:00, 45.16batch/s]\u001b[A\n",
      "Eval of epoch 846/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5514\n",
      "Eval loss: 15.4334\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 847/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.39batch/s]\n",
      "Training of epoch 847/50000: 100%|███████████| 32/32 [00:00<00:00, 44.54batch/s]\u001b[A\n",
      "Eval of epoch 847/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6596\n",
      "Eval loss: 16.913\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 848/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.30batch/s]\n",
      "Training of epoch 848/50000: 100%|███████████| 32/32 [00:00<00:00, 44.46batch/s]\u001b[A\n",
      "Eval of epoch 848/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5543\n",
      "Eval loss: 16.5441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 849/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 849/50000: 100%|███████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 849/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5867\n",
      "Eval loss: 15.9939\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 850/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.21batch/s]\n",
      "Training of epoch 850/50000: 100%|███████████| 32/32 [00:00<00:00, 45.69batch/s]\u001b[A\n",
      "Eval of epoch 850/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9369\n",
      "Eval loss: 17.0972\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 851/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.81batch/s]\n",
      "Training of epoch 851/50000: 100%|███████████| 32/32 [00:00<00:00, 43.58batch/s]\u001b[A\n",
      "Eval of epoch 851/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5295\n",
      "Eval loss: 16.6678\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 852/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.47batch/s]\n",
      "Training of epoch 852/50000: 100%|███████████| 32/32 [00:00<00:00, 43.02batch/s]\u001b[A\n",
      "Eval of epoch 852/50000: 100%|█████████████████| 4/4 [00:00<00:00, 44.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5512\n",
      "Eval loss: 17.0376\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 853/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.11batch/s]\n",
      "Training of epoch 853/50000: 100%|███████████| 32/32 [00:00<00:00, 44.60batch/s]\u001b[A\n",
      "Eval of epoch 853/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8223\n",
      "Eval loss: 15.5916\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 854/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.10batch/s]\n",
      "Training of epoch 854/50000: 100%|███████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 854/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6353\n",
      "Eval loss: 15.3168\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 855/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.73batch/s]\n",
      "Training of epoch 855/50000: 100%|███████████| 32/32 [00:00<00:00, 44.71batch/s]\u001b[A\n",
      "Eval of epoch 855/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3064\n",
      "Eval loss: 15.6786\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 856/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.33batch/s]\n",
      "Training of epoch 856/50000: 100%|███████████| 32/32 [00:00<00:00, 45.54batch/s]\u001b[A\n",
      "Eval of epoch 856/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5155\n",
      "Eval loss: 15.8325\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 857/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.46batch/s]\n",
      "Training of epoch 857/50000: 100%|███████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 857/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.707\n",
      "Eval loss: 16.023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 858/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.82batch/s]\n",
      "Training of epoch 858/50000: 100%|███████████| 32/32 [00:00<00:00, 44.39batch/s]\u001b[A\n",
      "Eval of epoch 858/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6529\n",
      "Eval loss: 17.2304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 859/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.94batch/s]\n",
      "Training of epoch 859/50000: 100%|███████████| 32/32 [00:00<00:00, 45.48batch/s]\u001b[A\n",
      "Eval of epoch 859/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6175\n",
      "Eval loss: 15.7458\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 860/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.96batch/s]\n",
      "Training of epoch 860/50000: 100%|███████████| 32/32 [00:00<00:00, 44.45batch/s]\u001b[A\n",
      "Eval of epoch 860/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4973\n",
      "Eval loss: 15.7395\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 861/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.48batch/s]\n",
      "Training of epoch 861/50000: 100%|███████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 861/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2754\n",
      "Eval loss: 16.9977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 862/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.09batch/s]\n",
      "Training of epoch 862/50000: 100%|███████████| 32/32 [00:00<00:00, 43.72batch/s]\u001b[A\n",
      "Eval of epoch 862/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5084\n",
      "Eval loss: 15.7278\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 863/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.77batch/s]\n",
      "Training of epoch 863/50000: 100%|███████████| 32/32 [00:00<00:00, 44.19batch/s]\u001b[A\n",
      "Eval of epoch 863/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4482\n",
      "Eval loss: 16.7346\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 864/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 864/50000: 100%|███████████| 32/32 [00:00<00:00, 44.73batch/s]\u001b[A\n",
      "Eval of epoch 864/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4916\n",
      "Eval loss: 16.297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 865/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.83batch/s]\n",
      "Training of epoch 865/50000: 100%|███████████| 32/32 [00:00<00:00, 44.72batch/s]\u001b[A\n",
      "Eval of epoch 865/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7069\n",
      "Eval loss: 16.2028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 866/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.15batch/s]\n",
      "Training of epoch 866/50000: 100%|███████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 866/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6143\n",
      "Eval loss: 15.8466\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 867/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.18batch/s]\n",
      "Training of epoch 867/50000: 100%|███████████| 32/32 [00:00<00:00, 44.83batch/s]\u001b[A\n",
      "Eval of epoch 867/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6074\n",
      "Eval loss: 16.6431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 868/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.39batch/s]\n",
      "Training of epoch 868/50000: 100%|███████████| 32/32 [00:00<00:00, 45.01batch/s]\u001b[A\n",
      "Eval of epoch 868/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5722\n",
      "Eval loss: 16.8858\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 869/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.30batch/s]\n",
      "Training of epoch 869/50000: 100%|███████████| 32/32 [00:00<00:00, 45.00batch/s]\u001b[A\n",
      "Eval of epoch 869/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6377\n",
      "Eval loss: 17.2074\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 870/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.82batch/s]\n",
      "Training of epoch 870/50000: 100%|███████████| 32/32 [00:00<00:00, 44.88batch/s]\u001b[A\n",
      "Eval of epoch 870/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7217\n",
      "Eval loss: 15.808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 871/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.05batch/s]\n",
      "Training of epoch 871/50000: 100%|███████████| 32/32 [00:00<00:00, 45.20batch/s]\u001b[A\n",
      "Eval of epoch 871/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7177\n",
      "Eval loss: 15.6655\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 872/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.35batch/s]\n",
      "Training of epoch 872/50000: 100%|███████████| 32/32 [00:00<00:00, 45.18batch/s]\u001b[A\n",
      "Eval of epoch 872/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7721\n",
      "Eval loss: 15.4575\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 873/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.73batch/s]\n",
      "Training of epoch 873/50000: 100%|███████████| 32/32 [00:00<00:00, 44.01batch/s]\u001b[A\n",
      "Eval of epoch 873/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6868\n",
      "Eval loss: 16.0931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 874/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.74batch/s]\n",
      "Training of epoch 874/50000: 100%|███████████| 32/32 [00:00<00:00, 44.39batch/s]\u001b[A\n",
      "Eval of epoch 874/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4012\n",
      "Eval loss: 16.1362\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 875/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.43batch/s]\n",
      "Training of epoch 875/50000: 100%|███████████| 32/32 [00:00<00:00, 45.07batch/s]\u001b[A\n",
      "Eval of epoch 875/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6841\n",
      "Eval loss: 18.2964\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 876/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.04batch/s]\n",
      "Training of epoch 876/50000: 100%|███████████| 32/32 [00:00<00:00, 44.83batch/s]\u001b[A\n",
      "Eval of epoch 876/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7105\n",
      "Eval loss: 16.4112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 877/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.04batch/s]\n",
      "Training of epoch 877/50000: 100%|███████████| 32/32 [00:00<00:00, 44.77batch/s]\u001b[A\n",
      "Eval of epoch 877/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4983\n",
      "Eval loss: 16.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 878/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.26batch/s]\n",
      "Training of epoch 878/50000: 100%|███████████| 32/32 [00:00<00:00, 44.72batch/s]\u001b[A\n",
      "Eval of epoch 878/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6766\n",
      "Eval loss: 16.5034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 879/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.56batch/s]\n",
      "Training of epoch 879/50000: 100%|███████████| 32/32 [00:00<00:00, 43.94batch/s]\u001b[A\n",
      "Eval of epoch 879/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3513\n",
      "Eval loss: 15.9594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 880/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.56batch/s]\n",
      "Training of epoch 880/50000: 100%|███████████| 32/32 [00:00<00:00, 44.96batch/s]\u001b[A\n",
      "Eval of epoch 880/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5832\n",
      "Eval loss: 16.4584\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 881/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.48batch/s]\n",
      "Training of epoch 881/50000: 100%|███████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 881/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.496\n",
      "Eval loss: 17.4628\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 882/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.30batch/s]\n",
      "Training of epoch 882/50000: 100%|███████████| 32/32 [00:00<00:00, 44.58batch/s]\u001b[A\n",
      "Eval of epoch 882/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6208\n",
      "Eval loss: 15.1112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 883/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 883/50000: 100%|███████████| 32/32 [00:00<00:00, 44.58batch/s]\u001b[A\n",
      "Eval of epoch 883/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8507\n",
      "Eval loss: 16.3822\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 884/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.80batch/s]\n",
      "Training of epoch 884/50000: 100%|███████████| 32/32 [00:00<00:00, 44.15batch/s]\u001b[A\n",
      "Eval of epoch 884/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7767\n",
      "Eval loss: 15.9055\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 885/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.10batch/s]\n",
      "Training of epoch 885/50000: 100%|███████████| 32/32 [00:00<00:00, 43.79batch/s]\u001b[A\n",
      "Eval of epoch 885/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4193\n",
      "Eval loss: 15.5896\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 886/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.17batch/s]\n",
      "Training of epoch 886/50000: 100%|███████████| 32/32 [00:00<00:00, 44.70batch/s]\u001b[A\n",
      "Eval of epoch 886/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4369\n",
      "Eval loss: 16.387\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 887/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.20batch/s]\n",
      "Training of epoch 887/50000: 100%|███████████| 32/32 [00:00<00:00, 44.52batch/s]\u001b[A\n",
      "Eval of epoch 887/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3967\n",
      "Eval loss: 15.7944\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 888/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.45batch/s]\n",
      "Training of epoch 888/50000: 100%|███████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 888/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8463\n",
      "Eval loss: 15.7055\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 889/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.20batch/s]\n",
      "Training of epoch 889/50000: 100%|███████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 889/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.554\n",
      "Eval loss: 16.3207\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 890/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.72batch/s]\n",
      "Training of epoch 890/50000: 100%|███████████| 32/32 [00:00<00:00, 44.07batch/s]\u001b[A\n",
      "Eval of epoch 890/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6151\n",
      "Eval loss: 16.0674\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 891/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 891/50000: 100%|███████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 891/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7453\n",
      "Eval loss: 16.4775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 892/50000:  94%|██████████▎| 30/32 [00:00<00:00, 49.19batch/s]\n",
      "Training of epoch 892/50000: 100%|███████████| 32/32 [00:00<00:00, 45.40batch/s]\u001b[A\n",
      "Eval of epoch 892/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9877\n",
      "Eval loss: 16.5285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 893/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.27batch/s]\n",
      "Training of epoch 893/50000: 100%|███████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 893/50000: 100%|█████████████████| 4/4 [00:00<00:00, 61.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5328\n",
      "Eval loss: 16.4236\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 894/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.76batch/s]\n",
      "Training of epoch 894/50000: 100%|███████████| 32/32 [00:00<00:00, 44.97batch/s]\u001b[A\n",
      "Eval of epoch 894/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5189\n",
      "Eval loss: 16.9996\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 895/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.25batch/s]\n",
      "Training of epoch 895/50000: 100%|███████████| 32/32 [00:00<00:00, 44.52batch/s]\u001b[A\n",
      "Eval of epoch 895/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5614\n",
      "Eval loss: 16.6763\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 896/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.36batch/s]\n",
      "Training of epoch 896/50000: 100%|███████████| 32/32 [00:00<00:00, 43.78batch/s]\u001b[A\n",
      "Eval of epoch 896/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6474\n",
      "Eval loss: 16.4159\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 897/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.85batch/s]\n",
      "Training of epoch 897/50000: 100%|███████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 897/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6901\n",
      "Eval loss: 17.1368\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 898/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 898/50000: 100%|███████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 898/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5889\n",
      "Eval loss: 16.6158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 899/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.94batch/s]\n",
      "Training of epoch 899/50000: 100%|███████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 899/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5648\n",
      "Eval loss: 16.5196\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 900/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.74batch/s]\n",
      "Training of epoch 900/50000: 100%|███████████| 32/32 [00:00<00:00, 44.29batch/s]\u001b[A\n",
      "Eval of epoch 900/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7055\n",
      "Eval loss: 17.9538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 901/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.47batch/s]\n",
      "Training of epoch 901/50000: 100%|███████████| 32/32 [00:00<00:00, 43.75batch/s]\u001b[A\n",
      "Eval of epoch 901/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5391\n",
      "Eval loss: 15.1932\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 902/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.31batch/s]\n",
      "Training of epoch 902/50000: 100%|███████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 902/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5557\n",
      "Eval loss: 15.4378\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 903/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 903/50000: 100%|███████████| 32/32 [00:00<00:00, 44.49batch/s]\u001b[A\n",
      "Eval of epoch 903/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5399\n",
      "Eval loss: 15.1734\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 904/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.93batch/s]\n",
      "Training of epoch 904/50000: 100%|███████████| 32/32 [00:00<00:00, 44.07batch/s]\u001b[A\n",
      "Eval of epoch 904/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.8401\n",
      "Eval loss: 16.7426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 905/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.79batch/s]\n",
      "Training of epoch 905/50000: 100%|███████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 905/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5914\n",
      "Eval loss: 16.4194\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 906/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.88batch/s]\n",
      "Training of epoch 906/50000: 100%|███████████| 32/32 [00:00<00:00, 44.55batch/s]\u001b[A\n",
      "Eval of epoch 906/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4729\n",
      "Eval loss: 16.8958\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 907/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.53batch/s]\n",
      "Training of epoch 907/50000: 100%|███████████| 32/32 [00:00<00:00, 44.25batch/s]\u001b[A\n",
      "Eval of epoch 907/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4579\n",
      "Eval loss: 16.2433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 908/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.13batch/s]\n",
      "Training of epoch 908/50000: 100%|███████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 908/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5938\n",
      "Eval loss: 15.9155\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 909/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.99batch/s]\n",
      "Training of epoch 909/50000: 100%|███████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 909/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7621\n",
      "Eval loss: 17.5212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 910/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.80batch/s]\n",
      "Training of epoch 910/50000: 100%|███████████| 32/32 [00:00<00:00, 44.76batch/s]\u001b[A\n",
      "Eval of epoch 910/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6408\n",
      "Eval loss: 15.5212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 911/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.49batch/s]\n",
      "Training of epoch 911/50000: 100%|███████████| 32/32 [00:00<00:00, 44.57batch/s]\u001b[A\n",
      "Eval of epoch 911/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6066\n",
      "Eval loss: 15.6803\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 912/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.12batch/s]\n",
      "Training of epoch 912/50000: 100%|███████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 912/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3609\n",
      "Eval loss: 15.8914\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 913/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.90batch/s]\n",
      "Training of epoch 913/50000: 100%|███████████| 32/32 [00:00<00:00, 44.40batch/s]\u001b[A\n",
      "Eval of epoch 913/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.447\n",
      "Eval loss: 16.9147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 914/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.83batch/s]\n",
      "Training of epoch 914/50000: 100%|███████████| 32/32 [00:00<00:00, 44.33batch/s]\u001b[A\n",
      "Eval of epoch 914/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7037\n",
      "Eval loss: 16.8452\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 915/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.74batch/s]\n",
      "Training of epoch 915/50000: 100%|███████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 915/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3817\n",
      "Eval loss: 16.0018\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 916/50000:  94%|██████████▎| 30/32 [00:00<00:00, 46.99batch/s]\n",
      "Training of epoch 916/50000: 100%|███████████| 32/32 [00:00<00:00, 43.80batch/s]\u001b[A\n",
      "Eval of epoch 916/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5267\n",
      "Eval loss: 15.0028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 917/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.34batch/s]\n",
      "Training of epoch 917/50000: 100%|███████████| 32/32 [00:00<00:00, 44.32batch/s]\u001b[A\n",
      "Eval of epoch 917/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3716\n",
      "Eval loss: 16.2685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 918/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.54batch/s]\n",
      "Training of epoch 918/50000: 100%|███████████| 32/32 [00:00<00:00, 45.10batch/s]\u001b[A\n",
      "Eval of epoch 918/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.425\n",
      "Eval loss: 15.6051\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 919/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.01batch/s]\n",
      "Training of epoch 919/50000: 100%|███████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 919/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3373\n",
      "Eval loss: 16.622\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 920/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.56batch/s]\n",
      "Training of epoch 920/50000: 100%|███████████| 32/32 [00:00<00:00, 44.95batch/s]\u001b[A\n",
      "Eval of epoch 920/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4944\n",
      "Eval loss: 16.0566\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 921/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.77batch/s]\n",
      "Training of epoch 921/50000: 100%|███████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 921/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2985\n",
      "Eval loss: 16.2036\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 922/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.46batch/s]\n",
      "Training of epoch 922/50000: 100%|███████████| 32/32 [00:00<00:00, 44.09batch/s]\u001b[A\n",
      "Eval of epoch 922/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6999\n",
      "Eval loss: 17.2612\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 923/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.45batch/s]\n",
      "Training of epoch 923/50000: 100%|███████████| 32/32 [00:00<00:00, 44.69batch/s]\u001b[A\n",
      "Eval of epoch 923/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.7578\n",
      "Eval loss: 15.9314\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 924/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.26batch/s]\n",
      "Training of epoch 924/50000: 100%|███████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 924/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1865\n",
      "Eval loss: 16.1956\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 925/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.88batch/s]\n",
      "Training of epoch 925/50000: 100%|███████████| 32/32 [00:00<00:00, 44.42batch/s]\u001b[A\n",
      "Eval of epoch 925/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4995\n",
      "Eval loss: 15.9885\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 926/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.54batch/s]\n",
      "Training of epoch 926/50000: 100%|███████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 926/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5183\n",
      "Eval loss: 16.5621\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 927/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.82batch/s]\n",
      "Training of epoch 927/50000: 100%|███████████| 32/32 [00:00<00:00, 45.40batch/s]\u001b[A\n",
      "Eval of epoch 927/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.529\n",
      "Eval loss: 16.0034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 928/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.55batch/s]\n",
      "Training of epoch 928/50000: 100%|███████████| 32/32 [00:00<00:00, 44.84batch/s]\u001b[A\n",
      "Eval of epoch 928/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3311\n",
      "Eval loss: 16.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 929/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.27batch/s]\n",
      "Training of epoch 929/50000: 100%|███████████| 32/32 [00:00<00:00, 44.98batch/s]\u001b[A\n",
      "Eval of epoch 929/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6017\n",
      "Eval loss: 16.8697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 930/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.45batch/s]\n",
      "Training of epoch 930/50000: 100%|███████████| 32/32 [00:00<00:00, 44.23batch/s]\u001b[A\n",
      "Eval of epoch 930/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4821\n",
      "Eval loss: 16.2368\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 931/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.27batch/s]\n",
      "Training of epoch 931/50000: 100%|███████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 931/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3322\n",
      "Eval loss: 16.2724\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 932/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.53batch/s]\n",
      "Training of epoch 932/50000: 100%|███████████| 32/32 [00:00<00:00, 44.85batch/s]\u001b[A\n",
      "Eval of epoch 932/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.228\n",
      "Eval loss: 16.5027\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 933/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.63batch/s]\n",
      "Training of epoch 933/50000: 100%|███████████| 32/32 [00:00<00:00, 43.97batch/s]\u001b[A\n",
      "Eval of epoch 933/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.154\n",
      "Eval loss: 16.4841\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 934/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.75batch/s]\n",
      "Training of epoch 934/50000: 100%|███████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 934/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6425\n",
      "Eval loss: 16.356\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 935/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.55batch/s]\n",
      "Training of epoch 935/50000: 100%|███████████| 32/32 [00:00<00:00, 44.70batch/s]\u001b[A\n",
      "Eval of epoch 935/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4468\n",
      "Eval loss: 15.5138\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 936/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.86batch/s]\n",
      "Training of epoch 936/50000: 100%|███████████| 32/32 [00:00<00:00, 44.45batch/s]\u001b[A\n",
      "Eval of epoch 936/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2753\n",
      "Eval loss: 15.6726\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 937/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.00batch/s]\n",
      "Training of epoch 937/50000: 100%|███████████| 32/32 [00:00<00:00, 44.85batch/s]\u001b[A\n",
      "Eval of epoch 937/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3368\n",
      "Eval loss: 15.3286\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 938/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.35batch/s]\n",
      "Training of epoch 938/50000: 100%|███████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 938/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4096\n",
      "Eval loss: 15.5096\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 939/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.56batch/s]\n",
      "Training of epoch 939/50000: 100%|███████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 939/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2012\n",
      "Eval loss: 16.597\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 940/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 940/50000: 100%|███████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 940/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3789\n",
      "Eval loss: 16.3261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 941/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.62batch/s]\n",
      "Training of epoch 941/50000: 100%|███████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 941/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6531\n",
      "Eval loss: 16.86\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 942/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.86batch/s]\n",
      "Training of epoch 942/50000: 100%|███████████| 32/32 [00:00<00:00, 44.46batch/s]\u001b[A\n",
      "Eval of epoch 942/50000: 100%|█████████████████| 4/4 [00:00<00:00, 61.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6231\n",
      "Eval loss: 16.3993\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 943/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.63batch/s]\n",
      "Training of epoch 943/50000: 100%|███████████| 32/32 [00:00<00:00, 44.21batch/s]\u001b[A\n",
      "Eval of epoch 943/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3329\n",
      "Eval loss: 18.1003\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 944/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.90batch/s]\n",
      "Training of epoch 944/50000: 100%|███████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 944/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4497\n",
      "Eval loss: 16.1199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 945/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 945/50000: 100%|███████████| 32/32 [00:00<00:00, 44.69batch/s]\u001b[A\n",
      "Eval of epoch 945/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3325\n",
      "Eval loss: 16.2223\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 946/50000:  94%|██████████▎| 30/32 [00:00<00:00, 45.76batch/s]\n",
      "Training of epoch 946/50000: 100%|███████████| 32/32 [00:00<00:00, 43.32batch/s]\u001b[A\n",
      "Eval of epoch 946/50000: 100%|█████████████████| 4/4 [00:00<00:00, 61.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.9699\n",
      "Eval loss: 16.5392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 947/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.34batch/s]\n",
      "Training of epoch 947/50000: 100%|███████████| 32/32 [00:00<00:00, 43.64batch/s]\u001b[A\n",
      "Eval of epoch 947/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.521\n",
      "Eval loss: 15.4158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 948/50000:  94%|██████████▎| 30/32 [00:00<00:00, 46.85batch/s]\n",
      "Training of epoch 948/50000: 100%|███████████| 32/32 [00:00<00:00, 43.31batch/s]\u001b[A\n",
      "Eval of epoch 948/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5354\n",
      "Eval loss: 16.0033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 949/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.24batch/s]\n",
      "Training of epoch 949/50000: 100%|███████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 949/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3878\n",
      "Eval loss: 15.4536\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 950/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.31batch/s]\n",
      "Training of epoch 950/50000: 100%|███████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 950/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5099\n",
      "Eval loss: 16.7878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 951/50000:  94%|██████████▎| 30/32 [00:00<00:00, 46.46batch/s]\n",
      "Training of epoch 951/50000: 100%|███████████| 32/32 [00:00<00:00, 43.40batch/s]\u001b[A\n",
      "Eval of epoch 951/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5227\n",
      "Eval loss: 16.1608\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 952/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.08batch/s]\n",
      "Training of epoch 952/50000: 100%|███████████| 32/32 [00:00<00:00, 44.65batch/s]\u001b[A\n",
      "Eval of epoch 952/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2886\n",
      "Eval loss: 16.7578\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 953/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.51batch/s]\n",
      "Training of epoch 953/50000: 100%|███████████| 32/32 [00:00<00:00, 44.02batch/s]\u001b[A\n",
      "Eval of epoch 953/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3906\n",
      "Eval loss: 16.117\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 954/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.21batch/s]\n",
      "Training of epoch 954/50000: 100%|███████████| 32/32 [00:00<00:00, 44.51batch/s]\u001b[A\n",
      "Eval of epoch 954/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2218\n",
      "Eval loss: 16.5527\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 955/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.62batch/s]\n",
      "Training of epoch 955/50000: 100%|███████████| 32/32 [00:00<00:00, 44.96batch/s]\u001b[A\n",
      "Eval of epoch 955/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1918\n",
      "Eval loss: 15.7077\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 956/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.15batch/s]\n",
      "Training of epoch 956/50000: 100%|███████████| 32/32 [00:00<00:00, 44.71batch/s]\u001b[A\n",
      "Eval of epoch 956/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3426\n",
      "Eval loss: 16.1208\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 957/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.25batch/s]\n",
      "Training of epoch 957/50000: 100%|███████████| 32/32 [00:00<00:00, 44.72batch/s]\u001b[A\n",
      "Eval of epoch 957/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2981\n",
      "Eval loss: 16.0744\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 958/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.30batch/s]\n",
      "Training of epoch 958/50000: 100%|███████████| 32/32 [00:00<00:00, 43.87batch/s]\u001b[A\n",
      "Eval of epoch 958/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4512\n",
      "Eval loss: 15.605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 959/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.07batch/s]\n",
      "Training of epoch 959/50000: 100%|███████████| 32/32 [00:00<00:00, 44.41batch/s]\u001b[A\n",
      "Eval of epoch 959/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2956\n",
      "Eval loss: 15.0818\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 960/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.09batch/s]\n",
      "Training of epoch 960/50000: 100%|███████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 960/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3516\n",
      "Eval loss: 16.3008\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 961/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.31batch/s]\n",
      "Training of epoch 961/50000: 100%|███████████| 32/32 [00:00<00:00, 44.86batch/s]\u001b[A\n",
      "Eval of epoch 961/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1793\n",
      "Eval loss: 15.271\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 962/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.24batch/s]\n",
      "Training of epoch 962/50000: 100%|███████████| 32/32 [00:00<00:00, 44.02batch/s]\u001b[A\n",
      "Eval of epoch 962/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.4628\n",
      "Eval loss: 16.0996\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 963/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.84batch/s]\n",
      "Training of epoch 963/50000: 100%|███████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 963/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3492\n",
      "Eval loss: 15.5775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 964/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.77batch/s]\n",
      "Training of epoch 964/50000: 100%|███████████| 32/32 [00:00<00:00, 44.96batch/s]\u001b[A\n",
      "Eval of epoch 964/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.238\n",
      "Eval loss: 16.0743\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 965/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.60batch/s]\n",
      "Training of epoch 965/50000: 100%|███████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 965/50000: 100%|█████████████████| 4/4 [00:00<00:00, 62.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.5158\n",
      "Eval loss: 16.8052\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 966/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.03batch/s]\n",
      "Training of epoch 966/50000: 100%|███████████| 32/32 [00:00<00:00, 43.40batch/s]\u001b[A\n",
      "Eval of epoch 966/50000: 100%|█████████████████| 4/4 [00:00<00:00, 61.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.54\n",
      "Eval loss: 16.7177\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 967/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.22batch/s]\n",
      "Training of epoch 967/50000: 100%|███████████| 32/32 [00:00<00:00, 43.99batch/s]\u001b[A\n",
      "Eval of epoch 967/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.6262\n",
      "Eval loss: 16.6609\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 968/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.23batch/s]\n",
      "Training of epoch 968/50000: 100%|███████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 968/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2683\n",
      "Eval loss: 16.2688\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 969/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.40batch/s]\n",
      "Training of epoch 969/50000: 100%|███████████| 32/32 [00:00<00:00, 44.94batch/s]\u001b[A\n",
      "Eval of epoch 969/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2965\n",
      "Eval loss: 16.3432\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 970/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.34batch/s]\n",
      "Training of epoch 970/50000: 100%|███████████| 32/32 [00:00<00:00, 44.71batch/s]\u001b[A\n",
      "Eval of epoch 970/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.0174\n",
      "Eval loss: 16.1639\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 971/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.30batch/s]\n",
      "Training of epoch 971/50000: 100%|███████████| 32/32 [00:00<00:00, 44.03batch/s]\u001b[A\n",
      "Eval of epoch 971/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3597\n",
      "Eval loss: 15.6045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 972/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.71batch/s]\n",
      "Training of epoch 972/50000: 100%|███████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 972/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2175\n",
      "Eval loss: 15.57\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 973/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.47batch/s]\n",
      "Training of epoch 973/50000: 100%|███████████| 32/32 [00:00<00:00, 44.70batch/s]\u001b[A\n",
      "Eval of epoch 973/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2001\n",
      "Eval loss: 16.3945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 974/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.07batch/s]\n",
      "Training of epoch 974/50000: 100%|███████████| 32/32 [00:00<00:00, 44.57batch/s]\u001b[A\n",
      "Eval of epoch 974/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.0542\n",
      "Eval loss: 16.2198\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 975/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.24batch/s]\n",
      "Training of epoch 975/50000: 100%|███████████| 32/32 [00:00<00:00, 44.04batch/s]\u001b[A\n",
      "Eval of epoch 975/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2823\n",
      "Eval loss: 16.4099\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 976/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.19batch/s]\n",
      "Training of epoch 976/50000: 100%|███████████| 32/32 [00:00<00:00, 43.98batch/s]\u001b[A\n",
      "Eval of epoch 976/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1626\n",
      "Eval loss: 15.6324\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 977/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.51batch/s]\n",
      "Training of epoch 977/50000: 100%|███████████| 32/32 [00:00<00:00, 44.16batch/s]\u001b[A\n",
      "Eval of epoch 977/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3571\n",
      "Eval loss: 15.3897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 978/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.87batch/s]\n",
      "Training of epoch 978/50000: 100%|███████████| 32/32 [00:00<00:00, 44.97batch/s]\u001b[A\n",
      "Eval of epoch 978/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2411\n",
      "Eval loss: 15.3439\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 979/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.46batch/s]\n",
      "Training of epoch 979/50000: 100%|███████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 979/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.2516\n",
      "Eval loss: 15.362\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 980/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.31batch/s]\n",
      "Training of epoch 980/50000: 100%|███████████| 32/32 [00:00<00:00, 45.05batch/s]\u001b[A\n",
      "Eval of epoch 980/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1676\n",
      "Eval loss: 15.2001\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 981/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.89batch/s]\n",
      "Training of epoch 981/50000: 100%|███████████| 32/32 [00:00<00:00, 44.35batch/s]\u001b[A\n",
      "Eval of epoch 981/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.0417\n",
      "Eval loss: 15.9118\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 982/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.52batch/s]\n",
      "Training of epoch 982/50000: 100%|███████████| 32/32 [00:00<00:00, 44.89batch/s]\u001b[A\n",
      "Eval of epoch 982/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.212\n",
      "Eval loss: 16.3262\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 983/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.09batch/s]\n",
      "Training of epoch 983/50000: 100%|███████████| 32/32 [00:00<00:00, 44.52batch/s]\u001b[A\n",
      "Eval of epoch 983/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.0893\n",
      "Eval loss: 15.5915\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 984/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.39batch/s]\n",
      "Training of epoch 984/50000: 100%|███████████| 32/32 [00:00<00:00, 44.17batch/s]\u001b[A\n",
      "Eval of epoch 984/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1008\n",
      "Eval loss: 15.7191\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 985/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 985/50000: 100%|███████████| 32/32 [00:00<00:00, 44.72batch/s]\u001b[A\n",
      "Eval of epoch 985/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1254\n",
      "Eval loss: 15.6321\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 986/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 986/50000: 100%|███████████| 32/32 [00:00<00:00, 44.51batch/s]\u001b[A\n",
      "Eval of epoch 986/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.3813\n",
      "Eval loss: 15.317\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 987/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 987/50000: 100%|███████████| 32/32 [00:00<00:00, 44.41batch/s]\u001b[A\n",
      "Eval of epoch 987/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1853\n",
      "Eval loss: 16.178\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 988/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.70batch/s]\n",
      "Training of epoch 988/50000: 100%|███████████| 32/32 [00:00<00:00, 43.93batch/s]\u001b[A\n",
      "Eval of epoch 988/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7547\n",
      "Eval loss: 15.5466\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 989/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.60batch/s]\n",
      "Training of epoch 989/50000: 100%|███████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 989/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7724\n",
      "Eval loss: 17.0034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 990/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.27batch/s]\n",
      "Training of epoch 990/50000: 100%|███████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 990/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.8931\n",
      "Eval loss: 15.0933\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 991/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.65batch/s]\n",
      "Training of epoch 991/50000: 100%|███████████| 32/32 [00:00<00:00, 45.00batch/s]\u001b[A\n",
      "Eval of epoch 991/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7046\n",
      "Eval loss: 15.9524\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 992/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.81batch/s]\n",
      "Training of epoch 992/50000: 100%|███████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 992/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.6804\n",
      "Eval loss: 15.9268\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 993/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.15batch/s]\n",
      "Training of epoch 993/50000: 100%|███████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 993/50000: 100%|█████████████████| 4/4 [00:00<00:00, 64.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.9735\n",
      "Eval loss: 15.9598\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 994/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.17batch/s]\n",
      "Training of epoch 994/50000: 100%|███████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 994/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 17.1384\n",
      "Eval loss: 15.2364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 995/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 995/50000: 100%|███████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 995/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.5904\n",
      "Eval loss: 15.3228\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 996/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.16batch/s]\n",
      "Training of epoch 996/50000: 100%|███████████| 32/32 [00:00<00:00, 44.82batch/s]\u001b[A\n",
      "Eval of epoch 996/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7441\n",
      "Eval loss: 15.4351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 997/50000:  94%|██████████▎| 30/32 [00:00<00:00, 47.89batch/s]\n",
      "Training of epoch 997/50000: 100%|███████████| 32/32 [00:00<00:00, 44.66batch/s]\u001b[A\n",
      "Eval of epoch 997/50000: 100%|█████████████████| 4/4 [00:00<00:00, 63.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7301\n",
      "Eval loss: 15.4592\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 998/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.10batch/s]\n",
      "Training of epoch 998/50000: 100%|███████████| 32/32 [00:00<00:00, 44.95batch/s]\u001b[A\n",
      "Eval of epoch 998/50000: 100%|█████████████████| 4/4 [00:00<00:00, 66.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7015\n",
      "Eval loss: 15.2136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 999/50000:  94%|██████████▎| 30/32 [00:00<00:00, 48.34batch/s]\n",
      "Training of epoch 999/50000: 100%|███████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 999/50000: 100%|█████████████████| 4/4 [00:00<00:00, 65.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.6418\n",
      "Eval loss: 15.4406\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1000/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.57batch/s]\n",
      "Training of epoch 1000/50000: 100%|██████████| 32/32 [00:00<00:00, 44.21batch/s]\u001b[A\n",
      "Eval of epoch 1000/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.6601\n",
      "Eval loss: 15.3808\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1001/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.11batch/s]\n",
      "Training of epoch 1001/50000: 100%|██████████| 32/32 [00:00<00:00, 44.21batch/s]\u001b[A\n",
      "Eval of epoch 1001/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7354\n",
      "Eval loss: 15.4073\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1002/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.15batch/s]\n",
      "Training of epoch 1002/50000: 100%|██████████| 32/32 [00:00<00:00, 44.60batch/s]\u001b[A\n",
      "Eval of epoch 1002/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.7662\n",
      "Eval loss: 15.3705\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1003/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.62batch/s]\n",
      "Training of epoch 1003/50000: 100%|██████████| 32/32 [00:00<00:00, 45.04batch/s]\u001b[A\n",
      "Eval of epoch 1003/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.6825\n",
      "Eval loss: 15.5489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1004/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.05batch/s]\n",
      "Training of epoch 1004/50000: 100%|██████████| 32/32 [00:00<00:00, 44.71batch/s]\u001b[A\n",
      "Eval of epoch 1004/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.4074\n",
      "Eval loss: 14.9644\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1005/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.58batch/s]\n",
      "Training of epoch 1005/50000: 100%|██████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 1005/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.3488\n",
      "Eval loss: 15.3038\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1006/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.84batch/s]\n",
      "Training of epoch 1006/50000: 100%|██████████| 32/32 [00:00<00:00, 44.27batch/s]\u001b[A\n",
      "Eval of epoch 1006/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2771\n",
      "Eval loss: 16.2666\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1007/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.55batch/s]\n",
      "Training of epoch 1007/50000: 100%|██████████| 32/32 [00:00<00:00, 44.17batch/s]\u001b[A\n",
      "Eval of epoch 1007/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.382\n",
      "Eval loss: 15.3432\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1008/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.71batch/s]\n",
      "Training of epoch 1008/50000: 100%|██████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 1008/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.335\n",
      "Eval loss: 16.4264\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1009/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.55batch/s]\n",
      "Training of epoch 1009/50000: 100%|██████████| 32/32 [00:00<00:00, 44.08batch/s]\u001b[A\n",
      "Eval of epoch 1009/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.4723\n",
      "Eval loss: 15.7359\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1010/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 1010/50000: 100%|██████████| 32/32 [00:00<00:00, 44.52batch/s]\u001b[A\n",
      "Eval of epoch 1010/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.5839\n",
      "Eval loss: 15.5028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1011/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.33batch/s]\n",
      "Training of epoch 1011/50000: 100%|██████████| 32/32 [00:00<00:00, 44.09batch/s]\u001b[A\n",
      "Eval of epoch 1011/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.4172\n",
      "Eval loss: 15.0353\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1012/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.11batch/s]\n",
      "Training of epoch 1012/50000: 100%|██████████| 32/32 [00:00<00:00, 44.69batch/s]\u001b[A\n",
      "Eval of epoch 1012/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2683\n",
      "Eval loss: 16.2237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1013/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.51batch/s]\n",
      "Training of epoch 1013/50000: 100%|██████████| 32/32 [00:00<00:00, 44.04batch/s]\u001b[A\n",
      "Eval of epoch 1013/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2726\n",
      "Eval loss: 14.5071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1014/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.77batch/s]\n",
      "Training of epoch 1014/50000: 100%|██████████| 32/32 [00:00<00:00, 44.23batch/s]\u001b[A\n",
      "Eval of epoch 1014/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.3048\n",
      "Eval loss: 15.6979\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1015/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.13batch/s]\n",
      "Training of epoch 1015/50000: 100%|██████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 1015/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2639\n",
      "Eval loss: 14.9008\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1016/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.38batch/s]\n",
      "Training of epoch 1016/50000: 100%|██████████| 32/32 [00:00<00:00, 44.14batch/s]\u001b[A\n",
      "Eval of epoch 1016/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.3361\n",
      "Eval loss: 15.5521\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1017/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.06batch/s]\n",
      "Training of epoch 1017/50000: 100%|██████████| 32/32 [00:00<00:00, 44.04batch/s]\u001b[A\n",
      "Eval of epoch 1017/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.0289\n",
      "Eval loss: 14.5952\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1018/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1018/50000: 100%|██████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 1018/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.309\n",
      "Eval loss: 15.793\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1019/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.09batch/s]\n",
      "Training of epoch 1019/50000: 100%|██████████| 32/32 [00:00<00:00, 44.15batch/s]\u001b[A\n",
      "Eval of epoch 1019/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1335\n",
      "Eval loss: 15.4868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1020/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.60batch/s]\n",
      "Training of epoch 1020/50000: 100%|██████████| 32/32 [00:00<00:00, 45.02batch/s]\u001b[A\n",
      "Eval of epoch 1020/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2591\n",
      "Eval loss: 15.0367\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1021/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.16batch/s]\n",
      "Training of epoch 1021/50000: 100%|██████████| 32/32 [00:00<00:00, 44.80batch/s]\u001b[A\n",
      "Eval of epoch 1021/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.3298\n",
      "Eval loss: 15.3457\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1022/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.21batch/s]\n",
      "Training of epoch 1022/50000: 100%|██████████| 32/32 [00:00<00:00, 44.72batch/s]\u001b[A\n",
      "Eval of epoch 1022/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.654\n",
      "Eval loss: 15.626\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1023/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.92batch/s]\n",
      "Training of epoch 1023/50000: 100%|██████████| 32/32 [00:00<00:00, 44.27batch/s]\u001b[A\n",
      "Eval of epoch 1023/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.119\n",
      "Eval loss: 16.42\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1024/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.56batch/s]\n",
      "Training of epoch 1024/50000: 100%|██████████| 32/32 [00:00<00:00, 44.22batch/s]\u001b[A\n",
      "Eval of epoch 1024/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1512\n",
      "Eval loss: 14.7247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1025/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.27batch/s]\n",
      "Training of epoch 1025/50000: 100%|██████████| 32/32 [00:00<00:00, 43.98batch/s]\u001b[A\n",
      "Eval of epoch 1025/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.4533\n",
      "Eval loss: 14.711\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1026/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.90batch/s]\n",
      "Training of epoch 1026/50000: 100%|██████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 1026/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1208\n",
      "Eval loss: 15.1327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1027/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.88batch/s]\n",
      "Training of epoch 1027/50000: 100%|██████████| 32/32 [00:00<00:00, 44.06batch/s]\u001b[A\n",
      "Eval of epoch 1027/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1185\n",
      "Eval loss: 14.7241\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1028/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.21batch/s]\n",
      "Training of epoch 1028/50000: 100%|██████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 1028/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1901\n",
      "Eval loss: 15.688\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1029/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1029/50000: 100%|██████████| 32/32 [00:00<00:00, 44.24batch/s]\u001b[A\n",
      "Eval of epoch 1029/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.9867\n",
      "Eval loss: 15.0565\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1030/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.15batch/s]\n",
      "Training of epoch 1030/50000: 100%|██████████| 32/32 [00:00<00:00, 43.93batch/s]\u001b[A\n",
      "Eval of epoch 1030/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1602\n",
      "Eval loss: 15.4769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1031/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.64batch/s]\n",
      "Training of epoch 1031/50000: 100%|██████████| 32/32 [00:00<00:00, 44.17batch/s]\u001b[A\n",
      "Eval of epoch 1031/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2118\n",
      "Eval loss: 15.5917\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1032/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.54batch/s]\n",
      "Training of epoch 1032/50000: 100%|██████████| 32/32 [00:00<00:00, 44.24batch/s]\u001b[A\n",
      "Eval of epoch 1032/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1233\n",
      "Eval loss: 14.9515\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1033/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.77batch/s]\n",
      "Training of epoch 1033/50000: 100%|██████████| 32/32 [00:00<00:00, 45.06batch/s]\u001b[A\n",
      "Eval of epoch 1033/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.2326\n",
      "Eval loss: 14.6161\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1034/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.47batch/s]\n",
      "Training of epoch 1034/50000: 100%|██████████| 32/32 [00:00<00:00, 44.98batch/s]\u001b[A\n",
      "Eval of epoch 1034/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.8878\n",
      "Eval loss: 14.6559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1035/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.25batch/s]\n",
      "Training of epoch 1035/50000: 100%|██████████| 32/32 [00:00<00:00, 44.98batch/s]\u001b[A\n",
      "Eval of epoch 1035/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.14\n",
      "Eval loss: 15.7153\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1036/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.80batch/s]\n",
      "Training of epoch 1036/50000: 100%|██████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 1036/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1163\n",
      "Eval loss: 16.1963\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1037/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.82batch/s]\n",
      "Training of epoch 1037/50000: 100%|██████████| 32/32 [00:00<00:00, 44.40batch/s]\u001b[A\n",
      "Eval of epoch 1037/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.858\n",
      "Eval loss: 15.2564\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1038/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.60batch/s]\n",
      "Training of epoch 1038/50000: 100%|██████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 1038/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.1877\n",
      "Eval loss: 15.5058\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1039/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.86batch/s]\n",
      "Training of epoch 1039/50000: 100%|██████████| 32/32 [00:00<00:00, 43.80batch/s]\u001b[A\n",
      "Eval of epoch 1039/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 16.0947\n",
      "Eval loss: 14.7413\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1040/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.52batch/s]\n",
      "Training of epoch 1040/50000: 100%|██████████| 32/32 [00:00<00:00, 45.12batch/s]\u001b[A\n",
      "Eval of epoch 1040/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.6848\n",
      "Eval loss: 14.8359\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1041/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 1041/50000: 100%|██████████| 32/32 [00:00<00:00, 44.92batch/s]\u001b[A\n",
      "Eval of epoch 1041/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.9153\n",
      "Eval loss: 14.6615\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1042/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.41batch/s]\n",
      "Training of epoch 1042/50000: 100%|██████████| 32/32 [00:00<00:00, 45.03batch/s]\u001b[A\n",
      "Eval of epoch 1042/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.9103\n",
      "Eval loss: 14.9663\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1043/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.82batch/s]\n",
      "Training of epoch 1043/50000: 100%|██████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 1043/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.8189\n",
      "Eval loss: 15.9729\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1044/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.18batch/s]\n",
      "Training of epoch 1044/50000: 100%|██████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 1044/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5617\n",
      "Eval loss: 15.6432\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1045/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1045/50000: 100%|██████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 1045/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.8941\n",
      "Eval loss: 14.8611\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1046/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.42batch/s]\n",
      "Training of epoch 1046/50000: 100%|██████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 1046/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.8822\n",
      "Eval loss: 14.2832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1047/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1047/50000: 100%|██████████| 32/32 [00:00<00:00, 44.62batch/s]\u001b[A\n",
      "Eval of epoch 1047/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.6412\n",
      "Eval loss: 15.1515\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1048/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 1048/50000: 100%|██████████| 32/32 [00:00<00:00, 44.82batch/s]\u001b[A\n",
      "Eval of epoch 1048/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5454\n",
      "Eval loss: 14.6234\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1049/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.74batch/s]\n",
      "Training of epoch 1049/50000: 100%|██████████| 32/32 [00:00<00:00, 44.29batch/s]\u001b[A\n",
      "Eval of epoch 1049/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.6464\n",
      "Eval loss: 14.7456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1050/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.04batch/s]\n",
      "Training of epoch 1050/50000: 100%|██████████| 32/32 [00:00<00:00, 44.09batch/s]\u001b[A\n",
      "Eval of epoch 1050/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.6018\n",
      "Eval loss: 14.5457\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1051/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.87batch/s]\n",
      "Training of epoch 1051/50000: 100%|██████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 1051/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.628\n",
      "Eval loss: 14.5487\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1052/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.50batch/s]\n",
      "Training of epoch 1052/50000: 100%|██████████| 32/32 [00:00<00:00, 44.16batch/s]\u001b[A\n",
      "Eval of epoch 1052/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5695\n",
      "Eval loss: 14.6478\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1053/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.39batch/s]\n",
      "Training of epoch 1053/50000: 100%|██████████| 32/32 [00:00<00:00, 44.88batch/s]\u001b[A\n",
      "Eval of epoch 1053/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.6965\n",
      "Eval loss: 14.6832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1054/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.87batch/s]\n",
      "Training of epoch 1054/50000: 100%|██████████| 32/32 [00:00<00:00, 44.61batch/s]\u001b[A\n",
      "Eval of epoch 1054/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.4747\n",
      "Eval loss: 14.8839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1055/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.67batch/s]\n",
      "Training of epoch 1055/50000: 100%|██████████| 32/32 [00:00<00:00, 44.08batch/s]\u001b[A\n",
      "Eval of epoch 1055/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.4017\n",
      "Eval loss: 15.5021\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1056/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.33batch/s]\n",
      "Training of epoch 1056/50000: 100%|██████████| 32/32 [00:00<00:00, 44.92batch/s]\u001b[A\n",
      "Eval of epoch 1056/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.4962\n",
      "Eval loss: 15.9698\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1057/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.53batch/s]\n",
      "Training of epoch 1057/50000: 100%|██████████| 32/32 [00:00<00:00, 45.08batch/s]\u001b[A\n",
      "Eval of epoch 1057/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.3568\n",
      "Eval loss: 13.8615\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1058/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.13batch/s]\n",
      "Training of epoch 1058/50000: 100%|██████████| 32/32 [00:00<00:00, 43.74batch/s]\u001b[A\n",
      "Eval of epoch 1058/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.3414\n",
      "Eval loss: 14.223\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1059/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1059/50000: 100%|██████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 1059/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5445\n",
      "Eval loss: 14.332\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1060/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.57batch/s]\n",
      "Training of epoch 1060/50000: 100%|██████████| 32/32 [00:00<00:00, 45.01batch/s]\u001b[A\n",
      "Eval of epoch 1060/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5206\n",
      "Eval loss: 15.4893\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1061/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.37batch/s]\n",
      "Training of epoch 1061/50000: 100%|██████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 1061/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.3723\n",
      "Eval loss: 14.6237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1062/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.58batch/s]\n",
      "Training of epoch 1062/50000: 100%|██████████| 32/32 [00:00<00:00, 44.18batch/s]\u001b[A\n",
      "Eval of epoch 1062/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.3761\n",
      "Eval loss: 14.8876\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1063/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.05batch/s]\n",
      "Training of epoch 1063/50000: 100%|██████████| 32/32 [00:00<00:00, 44.70batch/s]\u001b[A\n",
      "Eval of epoch 1063/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.5541\n",
      "Eval loss: 14.7213\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1064/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.04batch/s]\n",
      "Training of epoch 1064/50000: 100%|██████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 1064/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.4168\n",
      "Eval loss: 14.5776\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1065/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.62batch/s]\n",
      "Training of epoch 1065/50000: 100%|██████████| 32/32 [00:00<00:00, 44.14batch/s]\u001b[A\n",
      "Eval of epoch 1065/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.9761\n",
      "Eval loss: 13.8305\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1066/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1066/50000: 100%|██████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 1066/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.0105\n",
      "Eval loss: 14.0767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1067/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.28batch/s]\n",
      "Training of epoch 1067/50000: 100%|██████████| 32/32 [00:00<00:00, 44.03batch/s]\u001b[A\n",
      "Eval of epoch 1067/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.2147\n",
      "Eval loss: 14.4397\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1068/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.26batch/s]\n",
      "Training of epoch 1068/50000: 100%|██████████| 32/32 [00:00<00:00, 44.07batch/s]\u001b[A\n",
      "Eval of epoch 1068/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.1856\n",
      "Eval loss: 14.6008\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1069/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.57batch/s]\n",
      "Training of epoch 1069/50000: 100%|██████████| 32/32 [00:00<00:00, 44.39batch/s]\u001b[A\n",
      "Eval of epoch 1069/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.9981\n",
      "Eval loss: 14.0571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1070/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.45batch/s]\n",
      "Training of epoch 1070/50000: 100%|██████████| 32/32 [00:00<00:00, 45.00batch/s]\u001b[A\n",
      "Eval of epoch 1070/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.995\n",
      "Eval loss: 14.0918\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1071/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.51batch/s]\n",
      "Training of epoch 1071/50000: 100%|██████████| 32/32 [00:00<00:00, 44.19batch/s]\u001b[A\n",
      "Eval of epoch 1071/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.945\n",
      "Eval loss: 14.7109\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1072/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.82batch/s]\n",
      "Training of epoch 1072/50000: 100%|██████████| 32/32 [00:00<00:00, 45.06batch/s]\u001b[A\n",
      "Eval of epoch 1072/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.8716\n",
      "Eval loss: 14.543\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1073/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.36batch/s]\n",
      "Training of epoch 1073/50000: 100%|██████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 1073/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.9525\n",
      "Eval loss: 13.7629\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1074/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 1074/50000: 100%|██████████| 32/32 [00:00<00:00, 44.78batch/s]\u001b[A\n",
      "Eval of epoch 1074/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.0048\n",
      "Eval loss: 14.0248\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1075/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 1075/50000: 100%|██████████| 32/32 [00:00<00:00, 44.65batch/s]\u001b[A\n",
      "Eval of epoch 1075/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.917\n",
      "Eval loss: 14.2406\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1076/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.91batch/s]\n",
      "Training of epoch 1076/50000: 100%|██████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 1076/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.6685\n",
      "Eval loss: 13.7954\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1077/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.49batch/s]\n",
      "Training of epoch 1077/50000: 100%|██████████| 32/32 [00:00<00:00, 44.13batch/s]\u001b[A\n",
      "Eval of epoch 1077/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.5918\n",
      "Eval loss: 14.851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1078/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.84batch/s]\n",
      "Training of epoch 1078/50000: 100%|██████████| 32/32 [00:00<00:00, 44.49batch/s]\u001b[A\n",
      "Eval of epoch 1078/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.7732\n",
      "Eval loss: 13.6408\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1079/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.14batch/s]\n",
      "Training of epoch 1079/50000: 100%|██████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 1079/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 15.0019\n",
      "Eval loss: 14.1652\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1080/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.72batch/s]\n",
      "Training of epoch 1080/50000: 100%|██████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 1080/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.7701\n",
      "Eval loss: 13.6368\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1081/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.56batch/s]\n",
      "Training of epoch 1081/50000: 100%|██████████| 32/32 [00:00<00:00, 44.06batch/s]\u001b[A\n",
      "Eval of epoch 1081/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.5836\n",
      "Eval loss: 13.6064\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1082/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.05batch/s]\n",
      "Training of epoch 1082/50000: 100%|██████████| 32/32 [00:00<00:00, 44.53batch/s]\u001b[A\n",
      "Eval of epoch 1082/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.6109\n",
      "Eval loss: 14.5639\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1083/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.64batch/s]\n",
      "Training of epoch 1083/50000: 100%|██████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 1083/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.6404\n",
      "Eval loss: 13.5004\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1084/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.58batch/s]\n",
      "Training of epoch 1084/50000: 100%|██████████| 32/32 [00:00<00:00, 43.51batch/s]\u001b[A\n",
      "Eval of epoch 1084/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.6302\n",
      "Eval loss: 14.256\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1085/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.63batch/s]\n",
      "Training of epoch 1085/50000: 100%|██████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 1085/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.4914\n",
      "Eval loss: 13.6766\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1086/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.64batch/s]\n",
      "Training of epoch 1086/50000: 100%|██████████| 32/32 [00:00<00:00, 44.13batch/s]\u001b[A\n",
      "Eval of epoch 1086/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.5956\n",
      "Eval loss: 13.4869\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1087/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.63batch/s]\n",
      "Training of epoch 1087/50000: 100%|██████████| 32/32 [00:00<00:00, 44.04batch/s]\u001b[A\n",
      "Eval of epoch 1087/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.7497\n",
      "Eval loss: 14.0648\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1088/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.66batch/s]\n",
      "Training of epoch 1088/50000: 100%|██████████| 32/32 [00:00<00:00, 45.03batch/s]\u001b[A\n",
      "Eval of epoch 1088/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.4049\n",
      "Eval loss: 13.3674\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1089/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.67batch/s]\n",
      "Training of epoch 1089/50000: 100%|██████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 1089/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.5752\n",
      "Eval loss: 13.8954\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1090/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.72batch/s]\n",
      "Training of epoch 1090/50000: 100%|██████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 1090/50000: 100%|████████████████| 4/4 [00:00<00:00, 60.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.7321\n",
      "Eval loss: 13.0013\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1091/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.54batch/s]\n",
      "Training of epoch 1091/50000: 100%|██████████| 32/32 [00:00<00:00, 43.50batch/s]\u001b[A\n",
      "Eval of epoch 1091/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.425\n",
      "Eval loss: 13.5087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1092/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.31batch/s]\n",
      "Training of epoch 1092/50000: 100%|██████████| 32/32 [00:00<00:00, 43.76batch/s]\u001b[A\n",
      "Eval of epoch 1092/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.6874\n",
      "Eval loss: 13.5949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1093/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.82batch/s]\n",
      "Training of epoch 1093/50000: 100%|██████████| 32/32 [00:00<00:00, 44.30batch/s]\u001b[A\n",
      "Eval of epoch 1093/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3514\n",
      "Eval loss: 13.6711\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1094/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.93batch/s]\n",
      "Training of epoch 1094/50000: 100%|██████████| 32/32 [00:00<00:00, 43.50batch/s]\u001b[A\n",
      "Eval of epoch 1094/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3377\n",
      "Eval loss: 13.7125\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1095/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.02batch/s]\n",
      "Training of epoch 1095/50000: 100%|██████████| 32/32 [00:00<00:00, 44.00batch/s]\u001b[A\n",
      "Eval of epoch 1095/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3098\n",
      "Eval loss: 14.0944\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1096/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.79batch/s]\n",
      "Training of epoch 1096/50000: 100%|██████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 1096/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3477\n",
      "Eval loss: 14.8352\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1097/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.71batch/s]\n",
      "Training of epoch 1097/50000: 100%|██████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 1097/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.2798\n",
      "Eval loss: 13.2905\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1098/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.65batch/s]\n",
      "Training of epoch 1098/50000: 100%|██████████| 32/32 [00:00<00:00, 45.09batch/s]\u001b[A\n",
      "Eval of epoch 1098/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.494\n",
      "Eval loss: 12.614\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1099/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.07batch/s]\n",
      "Training of epoch 1099/50000: 100%|██████████| 32/32 [00:00<00:00, 43.90batch/s]\u001b[A\n",
      "Eval of epoch 1099/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.2704\n",
      "Eval loss: 13.3116\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1100/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.44batch/s]\n",
      "Training of epoch 1100/50000: 100%|██████████| 32/32 [00:00<00:00, 44.01batch/s]\u001b[A\n",
      "Eval of epoch 1100/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3455\n",
      "Eval loss: 14.7413\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1101/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.47batch/s]\n",
      "Training of epoch 1101/50000: 100%|██████████| 32/32 [00:00<00:00, 44.10batch/s]\u001b[A\n",
      "Eval of epoch 1101/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.3098\n",
      "Eval loss: 13.547\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1102/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.35batch/s]\n",
      "Training of epoch 1102/50000: 100%|██████████| 32/32 [00:00<00:00, 44.14batch/s]\u001b[A\n",
      "Eval of epoch 1102/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.37\n",
      "Eval loss: 13.981\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1103/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.88batch/s]\n",
      "Training of epoch 1103/50000: 100%|██████████| 32/32 [00:00<00:00, 45.30batch/s]\u001b[A\n",
      "Eval of epoch 1103/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.2339\n",
      "Eval loss: 12.8942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1104/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.11batch/s]\n",
      "Training of epoch 1104/50000: 100%|██████████| 32/32 [00:00<00:00, 44.65batch/s]\u001b[A\n",
      "Eval of epoch 1104/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.0911\n",
      "Eval loss: 13.56\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1105/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.65batch/s]\n",
      "Training of epoch 1105/50000: 100%|██████████| 32/32 [00:00<00:00, 44.27batch/s]\u001b[A\n",
      "Eval of epoch 1105/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.1829\n",
      "Eval loss: 13.5673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1106/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.42batch/s]\n",
      "Training of epoch 1106/50000: 100%|██████████| 32/32 [00:00<00:00, 43.99batch/s]\u001b[A\n",
      "Eval of epoch 1106/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.2146\n",
      "Eval loss: 13.7697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1107/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.45batch/s]\n",
      "Training of epoch 1107/50000: 100%|██████████| 32/32 [00:00<00:00, 44.22batch/s]\u001b[A\n",
      "Eval of epoch 1107/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.2488\n",
      "Eval loss: 13.9021\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1108/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.60batch/s]\n",
      "Training of epoch 1108/50000: 100%|██████████| 32/32 [00:00<00:00, 44.30batch/s]\u001b[A\n",
      "Eval of epoch 1108/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.0247\n",
      "Eval loss: 12.9801\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1109/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.46batch/s]\n",
      "Training of epoch 1109/50000: 100%|██████████| 32/32 [00:00<00:00, 43.91batch/s]\u001b[A\n",
      "Eval of epoch 1109/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.1479\n",
      "Eval loss: 13.3299\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1110/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.76batch/s]\n",
      "Training of epoch 1110/50000: 100%|██████████| 32/32 [00:00<00:00, 44.07batch/s]\u001b[A\n",
      "Eval of epoch 1110/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.1581\n",
      "Eval loss: 13.3753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1111/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.90batch/s]\n",
      "Training of epoch 1111/50000: 100%|██████████| 32/32 [00:00<00:00, 44.45batch/s]\u001b[A\n",
      "Eval of epoch 1111/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9999\n",
      "Eval loss: 12.5549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1112/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.31batch/s]\n",
      "Training of epoch 1112/50000: 100%|██████████| 32/32 [00:00<00:00, 44.46batch/s]\u001b[A\n",
      "Eval of epoch 1112/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9055\n",
      "Eval loss: 13.0527\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1113/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.83batch/s]\n",
      "Training of epoch 1113/50000: 100%|██████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 1113/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7733\n",
      "Eval loss: 13.0614\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1114/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.16batch/s]\n",
      "Training of epoch 1114/50000: 100%|██████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 1114/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9056\n",
      "Eval loss: 13.0794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1115/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.75batch/s]\n",
      "Training of epoch 1115/50000: 100%|██████████| 32/32 [00:00<00:00, 44.50batch/s]\u001b[A\n",
      "Eval of epoch 1115/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9034\n",
      "Eval loss: 13.4852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1116/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.34batch/s]\n",
      "Training of epoch 1116/50000: 100%|██████████| 32/32 [00:00<00:00, 44.96batch/s]\u001b[A\n",
      "Eval of epoch 1116/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9742\n",
      "Eval loss: 13.3674\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1117/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.89batch/s]\n",
      "Training of epoch 1117/50000: 100%|██████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 1117/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.0594\n",
      "Eval loss: 13.6039\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1118/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.72batch/s]\n",
      "Training of epoch 1118/50000: 100%|██████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 1118/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7919\n",
      "Eval loss: 13.6485\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1119/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1119/50000: 100%|██████████| 32/32 [00:00<00:00, 44.74batch/s]\u001b[A\n",
      "Eval of epoch 1119/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.1886\n",
      "Eval loss: 13.617\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1120/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.53batch/s]\n",
      "Training of epoch 1120/50000: 100%|██████████| 32/32 [00:00<00:00, 44.82batch/s]\u001b[A\n",
      "Eval of epoch 1120/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.8996\n",
      "Eval loss: 13.1456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1121/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.61batch/s]\n",
      "Training of epoch 1121/50000: 100%|██████████| 32/32 [00:00<00:00, 45.44batch/s]\u001b[A\n",
      "Eval of epoch 1121/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.8753\n",
      "Eval loss: 13.1929\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1122/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.46batch/s]\n",
      "Training of epoch 1122/50000: 100%|██████████| 32/32 [00:00<00:00, 44.37batch/s]\u001b[A\n",
      "Eval of epoch 1122/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.9402\n",
      "Eval loss: 13.0969\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1123/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.38batch/s]\n",
      "Training of epoch 1123/50000: 100%|██████████| 32/32 [00:00<00:00, 44.80batch/s]\u001b[A\n",
      "Eval of epoch 1123/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.8195\n",
      "Eval loss: 13.2704\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1124/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.95batch/s]\n",
      "Training of epoch 1124/50000: 100%|██████████| 32/32 [00:00<00:00, 44.65batch/s]\u001b[A\n",
      "Eval of epoch 1124/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7758\n",
      "Eval loss: 12.9618\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1125/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.47batch/s]\n",
      "Training of epoch 1125/50000: 100%|██████████| 32/32 [00:00<00:00, 44.18batch/s]\u001b[A\n",
      "Eval of epoch 1125/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7075\n",
      "Eval loss: 12.8553\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1126/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.66batch/s]\n",
      "Training of epoch 1126/50000: 100%|██████████| 32/32 [00:00<00:00, 44.39batch/s]\u001b[A\n",
      "Eval of epoch 1126/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.8015\n",
      "Eval loss: 13.3205\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1127/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.34batch/s]\n",
      "Training of epoch 1127/50000: 100%|██████████| 32/32 [00:00<00:00, 43.91batch/s]\u001b[A\n",
      "Eval of epoch 1127/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6463\n",
      "Eval loss: 14.0867\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1128/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.73batch/s]\n",
      "Training of epoch 1128/50000: 100%|██████████| 32/32 [00:00<00:00, 43.72batch/s]\u001b[A\n",
      "Eval of epoch 1128/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6739\n",
      "Eval loss: 13.1448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1129/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.43batch/s]\n",
      "Training of epoch 1129/50000: 100%|██████████| 32/32 [00:00<00:00, 44.16batch/s]\u001b[A\n",
      "Eval of epoch 1129/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7185\n",
      "Eval loss: 14.2748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1130/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.34batch/s]\n",
      "Training of epoch 1130/50000: 100%|██████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 1130/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.836\n",
      "Eval loss: 12.6836\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1131/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.28batch/s]\n",
      "Training of epoch 1131/50000: 100%|██████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 1131/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7168\n",
      "Eval loss: 13.6541\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1132/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.97batch/s]\n",
      "Training of epoch 1132/50000: 100%|██████████| 32/32 [00:00<00:00, 45.31batch/s]\u001b[A\n",
      "Eval of epoch 1132/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.8194\n",
      "Eval loss: 13.3926\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1133/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.58batch/s]\n",
      "Training of epoch 1133/50000: 100%|██████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 1133/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.5912\n",
      "Eval loss: 12.584\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1134/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.16batch/s]\n",
      "Training of epoch 1134/50000: 100%|██████████| 32/32 [00:00<00:00, 43.99batch/s]\u001b[A\n",
      "Eval of epoch 1134/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7708\n",
      "Eval loss: 13.8244\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1135/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.44batch/s]\n",
      "Training of epoch 1135/50000: 100%|██████████| 32/32 [00:00<00:00, 44.94batch/s]\u001b[A\n",
      "Eval of epoch 1135/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6693\n",
      "Eval loss: 12.7901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1136/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.14batch/s]\n",
      "Training of epoch 1136/50000: 100%|██████████| 32/32 [00:00<00:00, 44.09batch/s]\u001b[A\n",
      "Eval of epoch 1136/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.521\n",
      "Eval loss: 13.0555\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1137/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.65batch/s]\n",
      "Training of epoch 1137/50000: 100%|██████████| 32/32 [00:00<00:00, 45.11batch/s]\u001b[A\n",
      "Eval of epoch 1137/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7206\n",
      "Eval loss: 13.3935\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1138/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.09batch/s]\n",
      "Training of epoch 1138/50000: 100%|██████████| 32/32 [00:00<00:00, 44.73batch/s]\u001b[A\n",
      "Eval of epoch 1138/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.7572\n",
      "Eval loss: 12.9672\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1139/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.17batch/s]\n",
      "Training of epoch 1139/50000: 100%|██████████| 32/32 [00:00<00:00, 44.08batch/s]\u001b[A\n",
      "Eval of epoch 1139/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6476\n",
      "Eval loss: 12.3364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1140/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.12batch/s]\n",
      "Training of epoch 1140/50000: 100%|██████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 1140/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6582\n",
      "Eval loss: 12.7423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1141/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 1141/50000: 100%|██████████| 32/32 [00:00<00:00, 44.75batch/s]\u001b[A\n",
      "Eval of epoch 1141/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6505\n",
      "Eval loss: 12.7506\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1142/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.75batch/s]\n",
      "Training of epoch 1142/50000: 100%|██████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 1142/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.6239\n",
      "Eval loss: 12.5687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1143/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.58batch/s]\n",
      "Training of epoch 1143/50000: 100%|██████████| 32/32 [00:00<00:00, 43.75batch/s]\u001b[A\n",
      "Eval of epoch 1143/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.4977\n",
      "Eval loss: 12.928\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1144/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.24batch/s]\n",
      "Training of epoch 1144/50000: 100%|██████████| 32/32 [00:00<00:00, 43.47batch/s]\u001b[A\n",
      "Eval of epoch 1144/50000: 100%|████████████████| 4/4 [00:00<00:00, 49.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.4637\n",
      "Eval loss: 13.0979\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1145/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.55batch/s]\n",
      "Training of epoch 1145/50000: 100%|██████████| 32/32 [00:00<00:00, 44.62batch/s]\u001b[A\n",
      "Eval of epoch 1145/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3897\n",
      "Eval loss: 13.0455\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1146/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.04batch/s]\n",
      "Training of epoch 1146/50000: 100%|██████████| 32/32 [00:00<00:00, 44.60batch/s]\u001b[A\n",
      "Eval of epoch 1146/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.5656\n",
      "Eval loss: 12.9915\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1147/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.57batch/s]\n",
      "Training of epoch 1147/50000: 100%|██████████| 32/32 [00:00<00:00, 45.02batch/s]\u001b[A\n",
      "Eval of epoch 1147/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.5083\n",
      "Eval loss: 12.4975\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1148/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 1148/50000: 100%|██████████| 32/32 [00:00<00:00, 44.50batch/s]\u001b[A\n",
      "Eval of epoch 1148/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.473\n",
      "Eval loss: 12.5797\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1149/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.01batch/s]\n",
      "Training of epoch 1149/50000: 100%|██████████| 32/32 [00:00<00:00, 44.42batch/s]\u001b[A\n",
      "Eval of epoch 1149/50000: 100%|████████████████| 4/4 [00:00<00:00, 61.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3586\n",
      "Eval loss: 13.8925\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1150/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.87batch/s]\n",
      "Training of epoch 1150/50000: 100%|██████████| 32/32 [00:00<00:00, 44.34batch/s]\u001b[A\n",
      "Eval of epoch 1150/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3037\n",
      "Eval loss: 13.3752\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1151/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.79batch/s]\n",
      "Training of epoch 1151/50000: 100%|██████████| 32/32 [00:00<00:00, 45.26batch/s]\u001b[A\n",
      "Eval of epoch 1151/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3746\n",
      "Eval loss: 12.7414\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1152/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.52batch/s]\n",
      "Training of epoch 1152/50000: 100%|██████████| 32/32 [00:00<00:00, 44.33batch/s]\u001b[A\n",
      "Eval of epoch 1152/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.5389\n",
      "Eval loss: 12.5433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1153/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.00batch/s]\n",
      "Training of epoch 1153/50000: 100%|██████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 1153/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3129\n",
      "Eval loss: 11.9872\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1154/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.80batch/s]\n",
      "Training of epoch 1154/50000: 100%|██████████| 32/32 [00:00<00:00, 44.43batch/s]\u001b[A\n",
      "Eval of epoch 1154/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.5248\n",
      "Eval loss: 12.8045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1155/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.52batch/s]\n",
      "Training of epoch 1155/50000: 100%|██████████| 32/32 [00:00<00:00, 44.20batch/s]\u001b[A\n",
      "Eval of epoch 1155/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3755\n",
      "Eval loss: 13.098\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1156/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.80batch/s]\n",
      "Training of epoch 1156/50000: 100%|██████████| 32/32 [00:00<00:00, 44.41batch/s]\u001b[A\n",
      "Eval of epoch 1156/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.4157\n",
      "Eval loss: 12.9599\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1157/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.72batch/s]\n",
      "Training of epoch 1157/50000: 100%|██████████| 32/32 [00:00<00:00, 44.32batch/s]\u001b[A\n",
      "Eval of epoch 1157/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.4497\n",
      "Eval loss: 12.6841\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1158/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.24batch/s]\n",
      "Training of epoch 1158/50000: 100%|██████████| 32/32 [00:00<00:00, 43.87batch/s]\u001b[A\n",
      "Eval of epoch 1158/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3972\n",
      "Eval loss: 12.5734\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1159/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.52batch/s]\n",
      "Training of epoch 1159/50000: 100%|██████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 1159/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3974\n",
      "Eval loss: 12.7292\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1160/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.64batch/s]\n",
      "Training of epoch 1160/50000: 100%|██████████| 32/32 [00:00<00:00, 44.99batch/s]\u001b[A\n",
      "Eval of epoch 1160/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.4157\n",
      "Eval loss: 12.037\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1161/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.98batch/s]\n",
      "Training of epoch 1161/50000: 100%|██████████| 32/32 [00:00<00:00, 44.79batch/s]\u001b[A\n",
      "Eval of epoch 1161/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.2888\n",
      "Eval loss: 12.8339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1162/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.29batch/s]\n",
      "Training of epoch 1162/50000: 100%|██████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 1162/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.1665\n",
      "Eval loss: 12.3924\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1163/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.65batch/s]\n",
      "Training of epoch 1163/50000: 100%|██████████| 32/32 [00:00<00:00, 44.18batch/s]\u001b[A\n",
      "Eval of epoch 1163/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3454\n",
      "Eval loss: 12.0677\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1164/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.69batch/s]\n",
      "Training of epoch 1164/50000: 100%|██████████| 32/32 [00:00<00:00, 44.21batch/s]\u001b[A\n",
      "Eval of epoch 1164/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.2771\n",
      "Eval loss: 13.1211\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1165/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.65batch/s]\n",
      "Training of epoch 1165/50000: 100%|██████████| 32/32 [00:00<00:00, 44.45batch/s]\u001b[A\n",
      "Eval of epoch 1165/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.3181\n",
      "Eval loss: 12.3791\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1166/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.65batch/s]\n",
      "Training of epoch 1166/50000: 100%|██████████| 32/32 [00:00<00:00, 44.94batch/s]\u001b[A\n",
      "Eval of epoch 1166/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.1609\n",
      "Eval loss: 11.8148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1167/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.83batch/s]\n",
      "Training of epoch 1167/50000: 100%|██████████| 32/32 [00:00<00:00, 44.55batch/s]\u001b[A\n",
      "Eval of epoch 1167/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.1172\n",
      "Eval loss: 12.485\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1168/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.03batch/s]\n",
      "Training of epoch 1168/50000: 100%|██████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 1168/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.154\n",
      "Eval loss: 12.3551\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1169/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.98batch/s]\n",
      "Training of epoch 1169/50000: 100%|██████████| 32/32 [00:00<00:00, 44.69batch/s]\u001b[A\n",
      "Eval of epoch 1169/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.2092\n",
      "Eval loss: 12.1449\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1170/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.59batch/s]\n",
      "Training of epoch 1170/50000: 100%|██████████| 32/32 [00:00<00:00, 44.16batch/s]\u001b[A\n",
      "Eval of epoch 1170/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.1228\n",
      "Eval loss: 12.19\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1171/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.34batch/s]\n",
      "Training of epoch 1171/50000: 100%|██████████| 32/32 [00:00<00:00, 44.97batch/s]\u001b[A\n",
      "Eval of epoch 1171/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0707\n",
      "Eval loss: 11.9768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1172/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.38batch/s]\n",
      "Training of epoch 1172/50000: 100%|██████████| 32/32 [00:00<00:00, 44.18batch/s]\u001b[A\n",
      "Eval of epoch 1172/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0946\n",
      "Eval loss: 12.5299\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1173/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.29batch/s]\n",
      "Training of epoch 1173/50000: 100%|██████████| 32/32 [00:00<00:00, 44.05batch/s]\u001b[A\n",
      "Eval of epoch 1173/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.127\n",
      "Eval loss: 12.6573\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1174/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.59batch/s]\n",
      "Training of epoch 1174/50000: 100%|██████████| 32/32 [00:00<00:00, 45.13batch/s]\u001b[A\n",
      "Eval of epoch 1174/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.023\n",
      "Eval loss: 12.9584\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1175/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.22batch/s]\n",
      "Training of epoch 1175/50000: 100%|██████████| 32/32 [00:00<00:00, 44.99batch/s]\u001b[A\n",
      "Eval of epoch 1175/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0167\n",
      "Eval loss: 12.024\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1176/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.14batch/s]\n",
      "Training of epoch 1176/50000: 100%|██████████| 32/32 [00:00<00:00, 44.12batch/s]\u001b[A\n",
      "Eval of epoch 1176/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0409\n",
      "Eval loss: 13.0769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1177/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.34batch/s]\n",
      "Training of epoch 1177/50000: 100%|██████████| 32/32 [00:00<00:00, 43.61batch/s]\u001b[A\n",
      "Eval of epoch 1177/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0783\n",
      "Eval loss: 12.4993\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1178/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.65batch/s]\n",
      "Training of epoch 1178/50000: 100%|██████████| 32/32 [00:00<00:00, 44.32batch/s]\u001b[A\n",
      "Eval of epoch 1178/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0256\n",
      "Eval loss: 12.2188\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1179/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.44batch/s]\n",
      "Training of epoch 1179/50000: 100%|██████████| 32/32 [00:00<00:00, 44.06batch/s]\u001b[A\n",
      "Eval of epoch 1179/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9824\n",
      "Eval loss: 12.8483\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1180/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.44batch/s]\n",
      "Training of epoch 1180/50000: 100%|██████████| 32/32 [00:00<00:00, 45.12batch/s]\u001b[A\n",
      "Eval of epoch 1180/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8825\n",
      "Eval loss: 12.3459\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1181/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.26batch/s]\n",
      "Training of epoch 1181/50000: 100%|██████████| 32/32 [00:00<00:00, 44.67batch/s]\u001b[A\n",
      "Eval of epoch 1181/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.2052\n",
      "Eval loss: 12.471\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1182/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.69batch/s]\n",
      "Training of epoch 1182/50000: 100%|██████████| 32/32 [00:00<00:00, 45.05batch/s]\u001b[A\n",
      "Eval of epoch 1182/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0672\n",
      "Eval loss: 12.5548\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1183/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.12batch/s]\n",
      "Training of epoch 1183/50000: 100%|██████████| 32/32 [00:00<00:00, 44.87batch/s]\u001b[A\n",
      "Eval of epoch 1183/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0967\n",
      "Eval loss: 12.1768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1184/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.18batch/s]\n",
      "Training of epoch 1184/50000: 100%|██████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 1184/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0141\n",
      "Eval loss: 12.4166\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1185/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.91batch/s]\n",
      "Training of epoch 1185/50000: 100%|██████████| 32/32 [00:00<00:00, 44.36batch/s]\u001b[A\n",
      "Eval of epoch 1185/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9361\n",
      "Eval loss: 13.0221\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1186/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.11batch/s]\n",
      "Training of epoch 1186/50000: 100%|██████████| 32/32 [00:00<00:00, 43.29batch/s]\u001b[A\n",
      "Eval of epoch 1186/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0781\n",
      "Eval loss: 12.5302\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1187/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.54batch/s]\n",
      "Training of epoch 1187/50000: 100%|██████████| 32/32 [00:00<00:00, 44.25batch/s]\u001b[A\n",
      "Eval of epoch 1187/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9471\n",
      "Eval loss: 12.1356\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1188/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.23batch/s]\n",
      "Training of epoch 1188/50000: 100%|██████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 1188/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9259\n",
      "Eval loss: 12.0165\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1189/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.77batch/s]\n",
      "Training of epoch 1189/50000: 100%|██████████| 32/32 [00:00<00:00, 45.15batch/s]\u001b[A\n",
      "Eval of epoch 1189/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.05\n",
      "Eval loss: 12.385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1190/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.78batch/s]\n",
      "Training of epoch 1190/50000: 100%|██████████| 32/32 [00:00<00:00, 45.29batch/s]\u001b[A\n",
      "Eval of epoch 1190/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8554\n",
      "Eval loss: 12.0545\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1191/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.79batch/s]\n",
      "Training of epoch 1191/50000: 100%|██████████| 32/32 [00:00<00:00, 44.33batch/s]\u001b[A\n",
      "Eval of epoch 1191/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8976\n",
      "Eval loss: 12.3802\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1192/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.42batch/s]\n",
      "Training of epoch 1192/50000: 100%|██████████| 32/32 [00:00<00:00, 44.08batch/s]\u001b[A\n",
      "Eval of epoch 1192/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7036\n",
      "Eval loss: 11.7179\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1193/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.79batch/s]\n",
      "Training of epoch 1193/50000: 100%|██████████| 32/32 [00:00<00:00, 44.32batch/s]\u001b[A\n",
      "Eval of epoch 1193/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9067\n",
      "Eval loss: 12.1826\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1194/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.98batch/s]\n",
      "Training of epoch 1194/50000: 100%|██████████| 32/32 [00:00<00:00, 44.30batch/s]\u001b[A\n",
      "Eval of epoch 1194/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9443\n",
      "Eval loss: 12.1934\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1195/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.64batch/s]\n",
      "Training of epoch 1195/50000: 100%|██████████| 32/32 [00:00<00:00, 44.54batch/s]\u001b[A\n",
      "Eval of epoch 1195/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8102\n",
      "Eval loss: 12.2788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1196/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.28batch/s]\n",
      "Training of epoch 1196/50000: 100%|██████████| 32/32 [00:00<00:00, 43.87batch/s]\u001b[A\n",
      "Eval of epoch 1196/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8019\n",
      "Eval loss: 12.1031\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1197/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.01batch/s]\n",
      "Training of epoch 1197/50000: 100%|██████████| 32/32 [00:00<00:00, 43.79batch/s]\u001b[A\n",
      "Eval of epoch 1197/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9725\n",
      "Eval loss: 12.3346\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1198/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.87batch/s]\n",
      "Training of epoch 1198/50000: 100%|██████████| 32/32 [00:00<00:00, 44.35batch/s]\u001b[A\n",
      "Eval of epoch 1198/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9528\n",
      "Eval loss: 12.0803\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1199/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.60batch/s]\n",
      "Training of epoch 1199/50000: 100%|██████████| 32/32 [00:00<00:00, 44.64batch/s]\u001b[A\n",
      "Eval of epoch 1199/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6474\n",
      "Eval loss: 12.4228\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1200/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.30batch/s]\n",
      "Training of epoch 1200/50000: 100%|██████████| 32/32 [00:00<00:00, 43.98batch/s]\u001b[A\n",
      "Eval of epoch 1200/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9042\n",
      "Eval loss: 12.8362\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1201/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.77batch/s]\n",
      "Training of epoch 1201/50000: 100%|██████████| 32/32 [00:00<00:00, 44.32batch/s]\u001b[A\n",
      "Eval of epoch 1201/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7342\n",
      "Eval loss: 12.1285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1202/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.98batch/s]\n",
      "Training of epoch 1202/50000: 100%|██████████| 32/32 [00:00<00:00, 44.29batch/s]\u001b[A\n",
      "Eval of epoch 1202/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 13.0061\n",
      "Eval loss: 12.3224\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1203/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.70batch/s]\n",
      "Training of epoch 1203/50000: 100%|██████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 1203/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9749\n",
      "Eval loss: 12.8536\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1204/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.82batch/s]\n",
      "Training of epoch 1204/50000: 100%|██████████| 32/32 [00:00<00:00, 44.62batch/s]\u001b[A\n",
      "Eval of epoch 1204/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8664\n",
      "Eval loss: 12.7426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1205/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.42batch/s]\n",
      "Training of epoch 1205/50000: 100%|██████████| 32/32 [00:00<00:00, 44.28batch/s]\u001b[A\n",
      "Eval of epoch 1205/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7812\n",
      "Eval loss: 11.8818\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1206/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 1206/50000: 100%|██████████| 32/32 [00:00<00:00, 44.83batch/s]\u001b[A\n",
      "Eval of epoch 1206/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.559\n",
      "Eval loss: 12.2465\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1207/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.19batch/s]\n",
      "Training of epoch 1207/50000: 100%|██████████| 32/32 [00:00<00:00, 44.90batch/s]\u001b[A\n",
      "Eval of epoch 1207/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8148\n",
      "Eval loss: 12.6281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1208/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.07batch/s]\n",
      "Training of epoch 1208/50000: 100%|██████████| 32/32 [00:00<00:00, 44.38batch/s]\u001b[A\n",
      "Eval of epoch 1208/50000: 100%|████████████████| 4/4 [00:00<00:00, 62.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8164\n",
      "Eval loss: 11.4841\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1209/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.64batch/s]\n",
      "Training of epoch 1209/50000: 100%|██████████| 32/32 [00:00<00:00, 44.76batch/s]\u001b[A\n",
      "Eval of epoch 1209/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7807\n",
      "Eval loss: 12.8728\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1210/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.47batch/s]\n",
      "Training of epoch 1210/50000: 100%|██████████| 32/32 [00:00<00:00, 44.24batch/s]\u001b[A\n",
      "Eval of epoch 1210/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7924\n",
      "Eval loss: 13.0357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1211/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.38batch/s]\n",
      "Training of epoch 1211/50000: 100%|██████████| 32/32 [00:00<00:00, 44.73batch/s]\u001b[A\n",
      "Eval of epoch 1211/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.9362\n",
      "Eval loss: 12.7194\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1212/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.92batch/s]\n",
      "Training of epoch 1212/50000: 100%|██████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 1212/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.8484\n",
      "Eval loss: 12.4116\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1213/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.06batch/s]\n",
      "Training of epoch 1213/50000: 100%|██████████| 32/32 [00:00<00:00, 44.81batch/s]\u001b[A\n",
      "Eval of epoch 1213/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7527\n",
      "Eval loss: 12.0661\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1214/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.97batch/s]\n",
      "Training of epoch 1214/50000: 100%|██████████| 32/32 [00:00<00:00, 43.61batch/s]\u001b[A\n",
      "Eval of epoch 1214/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6967\n",
      "Eval loss: 12.1272\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1215/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.41batch/s]\n",
      "Training of epoch 1215/50000: 100%|██████████| 32/32 [00:00<00:00, 44.31batch/s]\u001b[A\n",
      "Eval of epoch 1215/50000: 100%|████████████████| 4/4 [00:00<00:00, 66.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6869\n",
      "Eval loss: 12.8426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1216/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.53batch/s]\n",
      "Training of epoch 1216/50000: 100%|██████████| 32/32 [00:00<00:00, 44.44batch/s]\u001b[A\n",
      "Eval of epoch 1216/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6542\n",
      "Eval loss: 12.2385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1217/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.84batch/s]\n",
      "Training of epoch 1217/50000: 100%|██████████| 32/32 [00:00<00:00, 44.47batch/s]\u001b[A\n",
      "Eval of epoch 1217/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6572\n",
      "Eval loss: 12.1193\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1218/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.14batch/s]\n",
      "Training of epoch 1218/50000: 100%|██████████| 32/32 [00:00<00:00, 43.99batch/s]\u001b[A\n",
      "Eval of epoch 1218/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.625\n",
      "Eval loss: 11.968\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1219/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.43batch/s]\n",
      "Training of epoch 1219/50000: 100%|██████████| 32/32 [00:00<00:00, 43.44batch/s]\u001b[A\n",
      "Eval of epoch 1219/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6869\n",
      "Eval loss: 11.6159\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1220/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.09batch/s]\n",
      "Training of epoch 1220/50000: 100%|██████████| 32/32 [00:00<00:00, 44.59batch/s]\u001b[A\n",
      "Eval of epoch 1220/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.7837\n",
      "Eval loss: 11.7531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1221/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.65batch/s]\n",
      "Training of epoch 1221/50000: 100%|██████████| 32/32 [00:00<00:00, 44.27batch/s]\u001b[A\n",
      "Eval of epoch 1221/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6722\n",
      "Eval loss: 11.7931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1222/50000:  94%|█████████▍| 30/32 [00:00<00:00, 48.57batch/s]\n",
      "Training of epoch 1222/50000: 100%|██████████| 32/32 [00:00<00:00, 44.84batch/s]\u001b[A\n",
      "Eval of epoch 1222/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.6681\n",
      "Eval loss: 12.158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1223/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.42batch/s]\n",
      "Training of epoch 1223/50000: 100%|██████████| 32/32 [00:00<00:00, 44.16batch/s]\u001b[A\n",
      "Eval of epoch 1223/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.5925\n",
      "Eval loss: 11.8386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1224/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.96batch/s]\n",
      "Training of epoch 1224/50000: 100%|██████████| 32/32 [00:00<00:00, 44.56batch/s]\u001b[A\n",
      "Eval of epoch 1224/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.5445\n",
      "Eval loss: 12.0331\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1225/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.56batch/s]\n",
      "Training of epoch 1225/50000: 100%|██████████| 32/32 [00:00<00:00, 44.34batch/s]\u001b[A\n",
      "Eval of epoch 1225/50000: 100%|████████████████| 4/4 [00:00<00:00, 64.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.538\n",
      "Eval loss: 12.0321\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1226/50000:  94%|█████████▍| 30/32 [00:00<00:00, 47.73batch/s]\n",
      "Training of epoch 1226/50000: 100%|██████████| 32/32 [00:00<00:00, 44.63batch/s]\u001b[A\n",
      "Eval of epoch 1226/50000: 100%|████████████████| 4/4 [00:00<00:00, 65.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.5815\n",
      "Eval loss: 11.6941\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1227/50000:  94%|█████████▍| 30/32 [00:00<00:00, 46.52batch/s]\n",
      "Training of epoch 1227/50000: 100%|██████████| 32/32 [00:00<00:00, 43.20batch/s]\u001b[A\n",
      "Eval of epoch 1227/50000: 100%|████████████████| 4/4 [00:00<00:00, 63.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 12.4876\n",
      "Eval loss: 11.6504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 1228/50000:  78%|███████▊  | 25/32 [00:00<00:00, 48.48batch/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_data\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PhD/Y0/vae_sketch_to_sound/src/benchmark_VAE/src/pythae/pipelines/training.py:256\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, train_data, eval_data, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided training config is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 256\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PhD/Y0/vae_sketch_to_sound/src/benchmark_VAE/src/pythae/trainers/base_trainer/base_trainer.py:461\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, log_output_dir)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_begin(\n\u001b[1;32m    453\u001b[0m     training_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config,\n\u001b[1;32m    454\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    455\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader,\n\u001b[1;32m    456\u001b[0m     eval_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_loader,\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    459\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 461\u001b[0m epoch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch_train_loss\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/PhD/Y0/vae_sketch_to_sound/src/benchmark_VAE/src/pythae/trainers/base_trainer/base_trainer.py:621\u001b[0m, in \u001b[0;36mBaseTrainer.train_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    619\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m    623\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_inputs_to_device(inputs)\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp_context:\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrv(x)\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrr(x)\n\u001b[0;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(data\u001b[38;5;241m=\u001b[39mx)\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/_transform.py:50\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/_transform.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/_geometry.py:765\u001b[0m, in \u001b[0;36mRandomAffine._transform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, inpt: Any, params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    764\u001b[0m     fill \u001b[38;5;241m=\u001b[39m _get_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill, \u001b[38;5;28mtype\u001b[39m(inpt))\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[0;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     34\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/functional/_geometry.py:698\u001b[0m, in \u001b[0;36maffine_image\u001b[0;34m(image, angle, translate, scale, shear, interpolation, fill, center)\u001b[0m\n\u001b[1;32m    696\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(matrix, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    697\u001b[0m grid \u001b[38;5;241m=\u001b[39m _affine_grid(theta, w\u001b[38;5;241m=\u001b[39mwidth, h\u001b[38;5;241m=\u001b[39mheight, ow\u001b[38;5;241m=\u001b[39mwidth, oh\u001b[38;5;241m=\u001b[39mheight)\n\u001b[0;32m--> 698\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_unsquash:\n\u001b[1;32m    701\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(shape)\n",
      "File \u001b[0;32m~/miniforge3/envs/s2s/lib/python3.10/site-packages/torchvision/transforms/v2/functional/_geometry.py:588\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[0;34m(img, grid, mode, fill)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'bilinear'\u001b[39;00m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;66;03m# The following is mathematically equivalent to:\u001b[39;00m\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# img * mask + (1.0 - mask) * fill = img * mask - fill * mask + fill = mask * (img - fill) + fill\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         float_img \u001b[38;5;241m=\u001b[39m float_img\u001b[38;5;241m.\u001b[39msub_(fill_img)\u001b[38;5;241m.\u001b[39mmul_(mask)\u001b[38;5;241m.\u001b[39madd_(fill_img)\n\u001b[0;32m--> 588\u001b[0m img \u001b[38;5;241m=\u001b[39m float_img\u001b[38;5;241m.\u001b[39mround_()\u001b[38;5;241m.\u001b[39mto(img\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp \u001b[38;5;28;01melse\u001b[39;00m float_img\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline(\n",
    "    train_data=train_data,\n",
    "    eval_data=eval_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e41ad3-e0b7-4e87-a060-ec39de4bf212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.4 ms, sys: 11.8 ms, total: 63.2 ms\n",
      "Wall time: 61.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reconstructions = model.reconstruct(img_data_x[:20].to(device)).detach().cpu()\n",
    "reconstructions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e57f2b51-34f7-4bd6-8d81-171684e1bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APASc0tKBS4oxTTTaM4p2KUCpFTNSCImmtHiomXFRmininqM1aijzVxIMjpTJYcVQljxVcikpwqRDV2HFaMIBFEyjFZk64NUnplJT1NWY5MVeiuMAc1I9wCKoTPk1TY0ykpc04NipVlxT/O461E75qMmm0UUUuaXNJmkooIoooooooxX/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAFCUlEQVR4AY2XiZacOBAEQbTf8/9/r1tsRFaJhrFnbTXorMy6JDGz/3yfczu3beepxm5Kxs7xbsqsurrI7fv2Et+l53skIyjflNDYv8TonPuI7hZJH1ZK1TEGRVmnDnbvtZIZ7+WAYvWIb0i1i27Ntw0nZWKBw0ydittb8CJsklCmanxNjGUWUCXjcpPUuARYcpb3fOC3V6trtfobjUa4eYKDuJPSPWZTCMge1cGVtdRNokpxearNYKFhNQ2WBbq6IUZrZ++EpBlobgUXnFCjOedhqBtM28ifmcCs0qHt8kor3tdilvX/Y5prwqLqaiLM6IAz5irhpPiBbz0UivU+lxN3K7QA2U5hwcUaXPXu55i7mdOjCsgdvpHGFDCrgCV0IZBhnO2LSsr/1QbRBPYlMW5iR57NQGD43HZPHPAOg+JVdgg++6DgRTBihHl8m8uYqAul/iI6Xy66nEf1sgwtoCtsHjv69zddBeMFMuUNMUAGI5WURFCVoRvSjnnuB4cOBuHqi2zMOXUhSDgQlofN6XOQYeKnmL9JNKfLj0AwSAxCoXqCBhrztR8/2A/qpB7bnPuoy0t7DUYaCOyn2Gg/cEOgE7ghaG5v04kJHx8a4nHWKrE+/EIBWgo85s7CELcTC6zr0K28KiSxqgyRQsp9P3TJQwE+Da7oUgKxODoGrGiuOi1jjAO85TzHPo9JGAmFFiWuC04Ql/0uQD201GUHUIzzTarYSyxTiAPzEWg7DHp8Kse0MC/VdmjuOA5z0qaVVLDxxR0ffC1UfFDlImrIhm7hvwkhrRhoiGJfmwGBvchrpAbqBHFjSZAnqmHmN+L6aEFu3G5phrGkGLFM79xEryTB3REHgyy8UUnJddP3Rhw5OQESYf1BAgxBPIoFElusIQBAL8qp8r3KBzeBqMstivmOKQuFrwQSuVPuxZHrZP2cFIQ8htrT58QQl3Jx3Ac2pjad8+DMsf3ni7Ozc4h/eZQwtK9U3cp+CYtIj7Mae5bzth9vsvY+3tscbHQUYge+zTKKnVRk7uoiuGyAyRxydjj9GP6DM0j80WBxlbDUiWYyUfjcBysqis/B75hchlgOAxnh75jFkhBGaUzIfaBfTJVNb8/9r7Edc7KPuAKIYNnfFDEGRRQQxiC9ig7qwECBsOYTxp0BRlhIDD/lqWx5myCjBBzSRNKtsM/cmeYUlgUG13ipcLOjgar+eWw9yn2pIU1e8aI54kLnoO4DiVLIQLEZRwgIeu5RTCuwZqme0nUOg7nLpLXnxccLNYfXPUJEshmMBk/5X5iXA2ccWvMyzM3jB8l4lECQhY82ZsUQRAB5ezrmhAqa3GChVE9bX4Lq0ckyJHPpUvlUPHEjkzp8bWGMpKSivROUMLUgF0ITS6MfED+RC/2VwPHnDXfYClPgYP+HoKxQOyGSLafJgKlaEyg3PDJKPUpNsABF32sXrqB3Av8+kP9OkRFCkVvCto+JRsRRVZX7i6cJ77zmbJEsMdoQ3MbdXcjVOv0nPC5eIk83ANRK6W3ecHS/m/ouuHAxLYHeu2tIe8e7LQPr6/hPDIHWzn7Y4Xxxschheix6CB6lU/+YuwbQXOLRdK38pXNTmo/ejWcZ9zeGtW4WOjTY8lsiltizrW3Tc/4FBbR29OXPE/B1FPll9ee/tq9i34+vCKjQPxDah+8RtfLI1nKXmzv4f+G4y6y44fqPfHq/145edGBs3qccs+M/YMG0bvWe5Y8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(reconstructions[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dc04d9f-d2df-4f56-b690-b71239bd6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiir0enpJGr/wBoWalhnYzMCPY/Lj9ad/ZEx+5cWT/S6jH8yKP7E1A/dhV/9yVG/kaQ6Jqo5/s66I9ViJ/lUTaZfr96xuR9Ym/wqNrS5X71vKPqhqMxuvVGH1FNooopQSOhI+lSrd3K/duJR9HNSLqd+v3b25H0lb/GpBrOqL01K8H/AG3b/GqNFFFFFFFblzo1gkggh1aEXEagTJMNqhsDdtYZBAzj1OD7ZhGhF2Ro9QsjDJxFI0u3eemNvUHPqAPemnQbxLeV5QsU8aGT7M+RKyA8sBjoOvPYE9qgXSb1tPa+EP7gDdksAxXONwXOSMkDOMUtxo9/arA01s4887UUYLZ44IHIPI4PPNWP+Ed1AgbFhkYNtlVJVJh4z8/OFHB5J4xzVS/0+SwkjVpIpklXfHLCSVYZIODgdCCKhntp7aQR3EMkTkBgsilTg9Dg1FRUsVzPBcJcRSusyHKuDyKmGp3q3v2xbqVbnGPMVsEDGMDHQY7UQane2yzCG5kTzv8AWEHkn1z2PJ59zVUMQCASAevPWrlrq17ZQ+VbzbFBLKdikoT1KkjKngdMU+PXNRiRVFxuKElHdFd0zydrEEjnng1n0UUUUUUV/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACBklEQVR4AWNgGAWjITAaAqMhMBoCVAsBRphJjL6ifxj+fPsKBN+///j95x9MggANN4BBlIuBgZUbBDg4WBj+/vr5/ee3Hz+///jx4/evP3//4jIHYQCSCkZmNnYOdk4ODi42Tk42DhYmhv9/fv769v//t39AxAAkv/9l+PGH4ddfhr9YDUAyC8RkYmZhYedg42Rk4mJg4gKSjIxcTAwcTAzMTAxMxBiAZh6Cy8zIwILgjbJGQ2A0BEZDgOIQsHamqFRi4Q/6x/Xv6Acu7bf3gG5h+QMkmCQ/fcbtLrAShDSjjem6+DvCh1y+8e66rGontusUA5Ob+cfJoGKchf/rDyDF/fsXSL2gOe/uDwxi/gqLboK4MMBYfuww8z8zy4MXJNPfsxx4FzPvjQ/H5vy1VxkYJCPFH834y+rgdXf6XwY2R4srwr+WmgQc+a47EVzpsPz9DzKE0fXQT6hhKkLn/jAY+vy6u/mnjv/UDwpxp07mrr8Xzr01ctt5/sjfm19xJnP8WfOEvWDnBQYGAWeDY9uBGlnRA5BRmucW0AJ3ndN6Wx4wqCf8OLvjj6rvMceze4Ge4pZ5CPSTYtycLzYml68l7zrOqOGCbgDUNczWCjtfAtlyTA+BDtW3OXQZKgGibC047u56wyDuKfXt22EkceKZLMBqFAgYuUarFeIDbVTlaAgQCgEAB5iq7cEgAmoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97418f86-fc10-420e-863d-b214e9bd6935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiirsVtYvEpk1Dy3I5UwsQD9RT30omJpba8tLhVBJCybGA/3XAJ/DNZ9FFFFa8XhnU5LKO9McaW0g3LI0q4x9ASRWY0RFwYVZXO7aCDwfxNdLq4u77Tooo9ImDIwYvGFkWMBcFVKDO09cEnGPrWG0emGDKXN2JgudrQLtLemQ+ce+KpUUUVJDPNbvvhlkjb+8jEH9K0v7ZW5tVh1GGa7YNnzDcEN+oNUblrUOrWfnquPmEpBIPsRjP5CtTU7O3TSbRoNNuoZ9oMkjRttb5eTuyQcnkYAwPWsOiiiiiipI55olZY5ZEDDDBWIyKjooooooooooooooooor/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAABpUlEQVR4Ae2SPU/CUBSGTykUactXqR8BcdAIuhjjpoNEd2OikwvxP/krXHHUxcFFEieUoZhIqiJKWz4awBrAWiBpuS2Io7l36bnnnPe95z69AHhhApgAJoAJDAkQwwD5ri8CuNqS1Gh2kZop4TbF1lBrABC+ZMQPhbzYstZMO+cJhk3UfHIt+JTR7f6+iNAG66SeOMHMPiPkP53kOibnUr+SWlZOjsc0OUMciDjhSjglO44WEw3u0kteQdf7ZnvtjqohRhMZQDDJ3qoAiUNokp7ixSgOGwO3hw6EQsyNgpzmCjBvo5dBDNxHe+9yrapUCsZZqbhcUyp1zfE1Igx6Yo4jtcrLx5cxgCDTgThHdYuZHjKQkUAm0LNUMBqP+tt1SbzvH0x4GZDs9WBnYLRSTJh3Zc03Zgm75+xoALCagPZzSR3c3nWwBecP6BgIA0sLvRPRymKurieZ3TNuczoDQdB1VDiWKP0YqNdpyFrcp90QcyukjWYMA2t3jC017P7keAYmD3qbb72Wq4+/eMomlSWk+AU+fClbcniDCWACmAAm8M8IfAPurHAn4TFiFAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "214fb523-79b4-488a-b396-2e8d8550cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiitGHR5jEs926WduwyJJuCw/2V6t+Ax71uTT2jz2o0e5slsBGglivEjRiw++WBHOfqT79q5m88j7dcfZv+PfzG8r/dzx+lQUUUUqsUYMpwQcg0+aeW5maaeR5JGOWdzkn8ajooooooooooooooooooooooooooor/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAAvklEQVR4AWNgGAWjITAaAqMhMBoCoyGACAFGBBMXi0tW+M/DV/9xSBM0gMXR7M1jDrXXaz7iMIGQsG6pFFAJR2gEDoVMOMThwsJ60UA1P87IwUVQGSyoXHQen7ON2Pl/QFGOn+hSUD5eA7jNba636VpzPvz03+gxDgPwBKKYle6THc8ZGCRVRfmEnm79jN0EnAZIuChdOP4auyZiRHVb3XmIUYdTjagwTqlRidEQGA2B0RAYDYHREBgNgcEdAgCMbiDRw8GMSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(img_data_x[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2350712f-198e-40b5-a965-4cbe9b70964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.57 ms, sys: 12 ms, total: 16.6 ms\n",
      "Wall time: 15.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model(dict(data=img_data_x[:20].to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7216293-0188-40d9-b31e-3934ad3a61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = out.z.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4d87065-51d1-4eeb-aca6-8f3b2fd56c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7201786"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(z[16] - z[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2359181-5de9-4f5c-acef-59b41d551d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5b021c-3660-4db7-a400-f6449044cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4249d68-cb5e-47ac-b172-510acb1b814c",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "014d61c5-4abb-440b-bb3e-efd9e8ff3269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n",
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd58ef2d-abe2-4fb4-8cb2-8cd1967b53eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# parent_directory = os.path.abspath('..')\n",
    "# sys.path.append(parent_directory)\n",
    "\n",
    "from benchmark_VAE.src.pythae.models import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "473eb3de-587c-405d-b1d5-1692173de516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from benchmark_VAE.src.pythae.models import AutoModel\n",
    "\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4181f88d-380b-4aee-bac2-57de0cac7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_training = sorted(os.listdir('./out/VQVAE_training_2023-10-23_21-16-23/'))[-1]\n",
    "trained_model = AutoModel.load_from_folder('../out/DisentangledBetaVAE_training_2023-11-23_22-33-39/final_model').to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d93f313-b1ef-447d-b4b5-1fec982ebcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/benchmark_VAE\n",
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000c2353-3345-43a6-aa9f-2d09b8c7c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bb7107-c27d-4f61-ad44-7c6ec281cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from benchmark_VAE.src.pythae.data.datasets import BaseDataset, DatasetOutput\n",
    "from torchvision.transforms import GaussianBlur\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1515526-6371-4a66-a745-bdde3843d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 112, 112])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iirdtp1zdDMacepq0NBuD1kQVIPD8n8U6j6ChtAbHyzgn3FQvod0v3SjfjVd9MvE6wsfpzUDW8yfeicfVajII6iiiiiir2lWourwBvuqMmtDUdWaCQ21qAipwTisxtSvG6zt+FRm9uW6zyf99Ui3dwpyJpP++qnTVrxP+WufqKsJr1yPvIjfpU66+D/rLf8AI1R1C8ju2BjQr9ao0UUUVvaIgitZrhv84rElcyTO56sSaZRRRRRRRRRRRXQSH7P4fAXqyj9a5+iiiiiiiiiiiiuguPm8PKfRVrn6KKKKKKKKKKKK6HTpIb3TTZOwV8YFY95Yy2chV1OOxqtRRRRRRRRRRRTkdo2DKSCO4rdtNShvYhbXgGegaqOoaVJaHenzRHoRWdRRRRRRRRRRRR0PFa+n6sYx5FyN8R457VPc6LHcHzbSVQrdjUSeGNQl/wBWgce2aRvDOpIwVo0BP+1S3HhjULeISMqkHsDVE6ZeD/lifzFNOnXY/wCWD002V0OsEn/fNRPG8Zw6Mp9xTaKKKKciNIwVFJJ7Cuh0+xltIxNczmNBztzU0/i+4h/d2p+UdyBWdN4l1KZtxkUH2WmN4i1GRdryhh6EU0a5dDqqH8KeNfnHWJDTx4gk7wL+dW9VRLzS1u1j2NgE1zdFFKqlmCjqa0bfRLuZgSoVD/FmtIvY6PHhcST1i3moT3jkux29lFVaKKKVVLEADJNbVjpKRJ9ovCFUchTUOpar9oXyIRthHFZVFFKrFWDDqK6qyu7m50FkjGXCkfKOa5xrW6ZizQyEnuVNM+y3A/5Yyf8AfJpPs8w/5Yyf98mgW8x6RP8A98mpFsbpukD/AJVMmkXrkDysfUitSK1tdJi824IebsKyb7UZb1zuOE7KKp0UUUVesNUmsAQgyp7E1b/4SB+8C/8AfVL/AMJAe9uP++qX+3x3t/8Ax6j+3x2t/wBaY2vy/wAMKj6mom1y7PTYv0FUJp5J33SMWNR0UUUUUUUUUUUUUUUUUUUUUUUUUUUUUV//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('./datasets/crop_640/1/00011_614a_416c.png'))\n",
    "img = np.array(Image.open('../datasets/2.png').convert(\"RGB\"))[:,:,0]\n",
    "img = torch.from_numpy(img).to(device)\n",
    "# img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "img = img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(112,112), mode='bilinear',antialias=True)\n",
    "\n",
    "blur = GaussianBlur(5, sigma=3)\n",
    "img = blur(img)\n",
    "\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77960a46-d76c-4abe-b5da-007f7e4b48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 112, 112])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iirdtp1xdDKJgercVaGgznrJGPzp40B/4px+C0raCcfLOM+61C+h3S/dKN+OKgfS7xOsJP0Oage2nT70Tj6rURBHUUUUUUVe0q2Fzd4b7qjJrQ1HVmt5Db2oChOCcVmHU7xv+W7fhioze3TdZ5P++qRby5U5E8n/AH1U6ateJ/y13fUVYTXbgfejRv0qZdfU/fgP4GqV/eR3TZRSv1qjRRRRW9oiCK1lnbv/ACFYkzmWZ3PViTTKKKKKKKKKKKK6CQ/Z9AAXqUH61z9FFFFFFFFFFFFdBcfNoCn/AGF/pXP0UUUUUUUUUUUV0OnSw3unGzdgH24FY95Yy2chV1OOxqtRRRRRRRRRRRTkdo2DISCK3bTUYb2L7PeAZ6Bqo6hpclqd6fNEehFZ1FFFFFFFFFFFAODkVr6fq2weRc/PGeOanudGjnPm2sqhW7Go08MX8vMShh6801vDWoowVlQH/epbjwzf28QkYI3sDVI6XeD/AJYn8xTTp14P+WDU02N0OtvJ/wB81C8bxnDoyn3GKbRRRRTkRpGCopJPYV0On2UtpGJricxqOduamn8XTw/u7U5UdyBWdN4l1GZtxdAfZaY/iLUJF2vIrD0Ipo1u5HVIz+Bp416bvEh/E08a+/eBf++qt6qiXmmLdLHsOAa5uiilVSzBR1NaNvol1MQSoVD3zWkXstHjwuJJqxrzUJ7xyXYheyiqlFFFKqlmAUZJrastKSJPtF4QqjkKah1LVPPXyIRiIcVlUUUqsVYMOorqrK7ubnQ2SMAuFYfKOa5x7W7ZizQyknuVNN+yXA/5YSf98mk+zTj/AJYyf98mgW85PEMn/fJp62F23SB/xGKmTSLxyB5W36kVqRW1tpMXmzkPL2FZN9qMt45ycJ2FU6KKKKvWOpy2IIQbge2at/2+3/PuP++qX+3/AFt//HqX+3l/59z/AN9Uf28va3P/AH1Uba/J/DAo+pqNtcuj0CL9BVCaeSd90jFjUdFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFf//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAHDElEQVR4Ae1a2aKbOAw1ttkhvfM+//93nXbCDjbMkQkJCQ6B3jBPUXsTltjHR7KELMPYR96sAWd7fw6E4x/rIcOwveHdL1cBCQEiuBD0hwMCHAatuq5tldJ/gLsC6HhBGAaCEzPGph/im8gNQ9/rDrgdcPUOvlM/d7TNiQySOPb4MNz95F6TAyNcpYBLwEO/7Obxyl1vs5uOHydpKNlNaSPU+IlWt4a4NBBh4BrgdUXLGcjsUIZJmoQOhkzaMv/RKXWLcwf2nOl5QjfAfd+WZVXrWV/3h3ZAGadp6jMatILOek2C73F6ci5dz3NdKTGJQHUki29oXzAHU4rvBYQ+k2goyyKvOnB6mBOaNVCpw6V0XcIFX05ooAihGbYiVoZOmMSR/P0rK57rBupVpnviS8BSmgltbLAXUERRwOufv8puHPRKe+CyloDhriPhoVH9SjMrQzfyhrr4J9swy6exDFp3hEuRiAbxVKyAgcdUn5crzZ71t4plGnFLUx5gGH31fKZZ2my+ZAMUIa6q6g8IboC1AXoB7NBi6h8hNsDABWBNc+AAsQByhFCmDzIhswBK0mhXrfjSd4hbAH0fwekoE1oYOmTCvqK4dYQsGfJQkAmPcQpmYegGHCasDzKhBZBMODQUkA+RhUodimvDYSZcMhRkwqPiGnS2YMh9ENQHxTUroMTzzDzbDjGhhSE4Izk7Bs3GENfgEUc5hcWGJvN9kXl9h/5i0piU8EDARU5DmTXji3F8h9Rd20XPJsU7kOEC0KR4/ydDRh7xvzIkj8Ba4ShZ9EwqRf58FN4y0hiVWi6/awRLt9AcjwvvsvZ6F8ytn6XuWiU8P6Hk+xBZ9tuWHffSrwg8j5CFSllTShGlnRDlIbn3ErArUALyvoSQeXvAQ8MCmEOTif9DSJEdkLstAVl71lqdghT1ruz9KwwLIFO5VvoUJkAUxbszcBsg0yXKMioJCTF/c4ZqBWR9jQqaTjwyZP5eQ9oBkXpT9SkNTuDI37rOeALIWJcR4mjI8o2GfArIdIG6pI4jOKQo3mfI54BUOIEkPkcxLW/eFQNWAEdDqtQnj8zfZcg1QGNINRpS8vI9haJ1QDIkJA5JrcVbgvkLQBjSeGRAMaB4hyFfAaJCRB6Z+PBImdXfX+S8BEQFxcSAMHGjU9WaMnQ/mDIxcnSUhV3JtGo3q3sDIAVzBLoocGOlsXi8CKE60vVd0aBUXdLeBdWq6d+abAFkfQlAFVFpmw1U60almw+67Xruhr7sKtTGMRRaV6Jgik8j17O7eu0mQGNI1YUuUlYZhnHooZKDWlXPzDZRj+KzktNOBmoghqEhC/y6qqr6xnkboDFk10Qe9+IkDgVojP1P+qWzaTfBHEylfQzQk0538+GtgDBkk3nRSTqCtWQr2vBSCl8lw06QMtMXySztXdwEexm+5zjDLGhsBmR902lRe7wet/MwM1vU77GUhKC0jv/4wLylD0MXnzSPA5Sz85tOtwMyN0rSNBB919RV3bbddVON+r8IUK9Ch5hhgd/30fmq082A3Adc7LKuyLP8fv8Ek8TiCkQUw/jxdzSI0KsmPW8FdKM0TUCvzs/5tqB6ccg897gTBjsBJ3ptmYHervimtBAsuC2ONjG80NNNlmU7FwDQpiv01YKMbQDkAawXuawtz9j92kUPEy0NPd3M8unXgG6cnBJf6DrfTc/xaKL11dzqrwCv9ApYr9lHD21PaSSqPM9vewTzuDDN3Nu3M1qP6xpwO63HZJiesK2LpnPDrwKKIMYQJay3nx7zaFvX66vsTI+SqzwBxN4j9pXdII4DritYr9r8hB27dmimxW5HlrhbK9ht6LhxFPp4NQGP8wZtip3WYyKE+UJOfvSQRNsBKSp5qeRiaCuElt2pPkx/SoIB6swey/VPAKEXEbmClf+S9SyR8moTy4HxhsTTUM0y7XoCiEDoYGO2KX+eH4doQbi/xAPMlli0xTmzVAnsgENXtM5fCm8d/C530jPekAYOTDH3huuY7IBMqUp/Bc7Q7i5kwBsQmHpS59wbXgHivuoQ4oXY5w7kDadYKlLnnTdsADR7F8K9JQfXNrYDpBj0mk8Q0TsHDdT54A3XNk9Uivt9ywR3v0xyO6Z85sFunquTXUcYiTQRq1YszvG2Ap5+iEvZU09aA+zdyHd/U4JLUCaznr7pdAAcgSBzueZNOFaVzRs2MGR1SUmQN7GhJvNjOA6uTH9TWjo0CIQWb9gC2BZIoi8J7+X3JvJOqDgx55d7RhF9VxbF6mPluUrxjMALXnLq/jrE+cF4E59QMF700cj/a+SP8588Hs/H+HCP+37ge0j1TL5HH8RoMhcdXWAUBKsdrORohr2QFUC0vAeZQdMh9sLxUsv41tILlM/tjwY+Gvho4KOBjwY+Gvho4FgN/Ad/wLu439zqTwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('./datasets/crop_640/1/00011_614a_416c.png'))\n",
    "img = np.array(Image.open('../datasets/2.png').convert(\"RGB\"))[:,:,0]\n",
    "img = torch.from_numpy(img).to(device)\n",
    "# img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "img = img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(112,112), mode='bilinear',antialias=True)\n",
    "\n",
    "blur = GaussianBlur(5, sigma=5)\n",
    "img = blur(img)\n",
    "\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159f5a61-3305-42cf-9881-e09a0ed76b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 112, 112])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('./datasets/crop_640/1/00011_614a_416c.png'))\n",
    "img = np.array(Image.open('../datasets/2.png').convert(\"RGB\"))[:,:,0]\n",
    "img = torch.from_numpy(img).to(device)\n",
    "# img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "img = img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(112,112), mode='bilinear',antialias=True)\n",
    "\n",
    "# blur = GaussianBlur(3, sigma=1)\n",
    "# img = blur(img)\n",
    "\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74a26e19-7545-4f5c-a3ab-7bc8e3d39fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trained_model(dict(data=img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c70e2c8-8207-477b-8e27-edfaeec68727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['recon_loss', 'reg_loss', 'loss', 'recon_x', 'z'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e532a5db-51ba-430a-b77f-efb7feed6484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(out.recon_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "920eccf8-4bb1-405a-9a89-2c81693686d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7259, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d03a5c2e-f615-451f-ae3b-f89f306f8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 112, 112])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiipEgll/wBXE7f7qk1YXSdQf7tnOf8AgBqUaDqrdLGb8qlXw1q7f8ubD6kVP/wiGtf8+o/77FH/AAiGtf8APqP++xTX8JayiljajHs4qs+garH96xl/AZqpJZXUP+st5V+qGoKVVLuqjqTgV1F34W0+wZEutbhSTYGePb8y57VW/wCKatO91eMP+Ag0h8Q20PFnpFtGOxcbjUT+KdTYYjeKIf8ATOMCq7a/qrdb6X86hbVtQf715Mf+Bmoje3bdbmY/8DNJ9suf+fib/vs0fbLn/n4m/wC+zR9suf8An4m/77NTR6tqEX3LyYf8DNbvhvW9Qutbt7W4n86GQkMsig5GDXPXyhdQuVUYAlYAfjUmkw+fq9pEejSr/OrfieUy+I70n+F9o/AVkUUUUUUUUUVv+D0B10SkcQxPIfwFYk8nm3Ekn95i35mrugf8h+x/67LTvEP/ACMN9/11NZlFFFFFFFFFdH4bzBpmsXv9yDYD7mucrR0D/kP2P/XZad4h/wCRhvv+uprMooooooooorpB/ofgRj0a8uMfULXN1e0aUQ61ZyN0Eq5/Op/EsZj8RXwPeTI/GsxEaRtqKWPoBmtO28N6vdLujspAvq3y/wA6Ze6DqenpvuLR1T+8OR+lZtFFFFFFdJ4m/wBF0/SdOH/LKDzHHu1c3To3MciOOqkGuu1zRrjV9cilhAWKW3SR5W4VRjkk1VuNattGT7HoqIzL/rLp1yXPt6Csa41fULp9015Mx/3iP5VPp/iDUdOk3RztIh+9HIdyt+BrSuLWy8QxPc6ZCLe9Rd0tsDw3qVrmiCpIIwR1FJRRRVzSbdLrVbWGSRY0aQBmY8AZrX8Y213/AG5NPJC32fhY5AMqVA9a5ytXRtGOpGSeaQQWUPMsrdvYe9dJ4t1UT+G9Kj04tHY7TGQfvOR3JrhqKKsWN5LYXkVzAxV42yMd/atfxXbRLfQ31uoWG8iEoA6A96wKKKKK1tP8RahYL5QkE0HeKUblNXt/h7V+ZA2mXB6lfmjP+FR6/qVqsUek6Wx+wwnJfvK3qafxc+BD3a2ufyBrnKKKK6XXlMfhvQ45BiTy2bB64rmqKKKKKKK6PwtdW8jXGj3hCwXq7Vc/wP2NYt/ZTadfS2k67ZI2wff3qtTo43lcJGpZ2OAAMk10UOlWeiwrdayd855js1PP/AvSsjU9Tn1S7M8xwANqIOir2AqlRRRRRRRSqxVgynBByCK6NtX03WokGsJJHdIoUXMQzuA/vCmLp3hsgE6vOD6eVTn1bTtHjMejRtJORg3Uo5H+6O1YE00txK0szs7sclmOSajooooooooooooooooooooooooooooooooooooooooooooooooor//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('../datasets/crop_640/1/00014_614a_6c3f.png').resize((size,size)))\n",
    "img = np.array(Image.open('../datasets/crop_640/1/00019_614a_1c43.png').resize((size,size)))\n",
    "img = torch.from_numpy(img).to(device)\n",
    "img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(112,112), mode='bilinear')\n",
    "\n",
    "blur = GaussianBlur(3, sigma=1)\n",
    "img = blur(img)\n",
    "\n",
    "# img = torch.nn.functional.interpolate(img, size=(112,112))\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7025430b-0b3b-4ccc-970b-07fe742c5c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 ms, sys: 14 µs, total: 3.75 ms\n",
      "Wall time: 3.21 ms\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAMUYoxS4oxSYoxS4pMUYpMUuKMUlPAoxSgUEUlLRSgUYpDTcUUtJTwKXbRTeTS4pMUvNHNFHWkxRikNJUooJzTSaKM0UZozRRiiikpMVJiijrQRikxQabS0UUpNJSYoxzUtIQaTNHeimmkpcUYoFBopcUhzUg6048io+c0uOaaetKBmlK0gGaXFBGKQiigUtOHvS5oC8Uu0+lKEJ7Uojx0pChpu3HNKBupGU0mMUhBJoC0oTJoZuachBqUYpRwadnPFAGDSnGKQxZFNEeOtBTn2pjLio+adR3x2qEGnq2KeH5p28d6FbBqQv60bwcYp3mgACkL8UjScc1EXyKZnmgmkBqEMadmjfzTt3NODUpbijccU3fil8z3oL5puadmmFs0dKizRmilBp26lDUFjTSTSZpc0bqXdmkpS3FRUuaM0ZpaXIozSdqKM0ZpcijPFNzSUUUUUUUUUUUUUV//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reconstructions = trained_model.reconstruct(img.to(device)).detach().cpu()\n",
    "to_pil_image(reconstructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95936c86-b2fb-4cf0-9b84-45c5729454ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 ms, sys: 3.98 ms, total: 5.33 ms\n",
      "Wall time: 4.52 ms\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiijJxjPFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFPWGR0Z1QlVGWIHSmUUYz0pzIyHDKVPuMU2iiiiiiiinpLJGrKjsoYYYA9aZV+x1FLKC4X7LFLNIAEmcnMfXOO3PH5UyLVb2AKIpyoX7uAOKjub24vHDzyb2AxnA6VEXzGE2qMHOQOTTKKKKKKKKKDjPHSrn9mXJ0sagIyYN+wkdjVTY23dtO31xSUuCRnHApKKKKKKKKKK29L1K4k06TShcGIOd0JGAN3cE9s1vW+t3mg6S+k65E0m5PMgVwGK8/wAq42eRJcy9JGbLDt+FDWlzHaJdNE6wSHasmOCfTNQU7YxQvj5QcZptFFFFFOjZVYFkDj0JrZspdDuCsNzbTW7MNvmo+4BvUg1t6joGj6NoczySSyX6uFUuNv5CqV1rukanptrHf2cj30aiNrhWx8vb61j/ANmNd6i9tpe+6ABYFV5IHWkuNVvJNJi0mQgW0EhdU24IbnOT+JrPo56UVYv7U2WoXFqWDeTKybh0ODjNV6KKKKK27a5Gu3Nvb6tqMwwdolf58D8TWveeEdFjBa28T2xxwVlXHPsQea1vDL6d4JQ61LcC6d1MSrGARzXDa1dxX+tXt5ACsc8zShSMY3HOKhs1tGlP2uWSNAONi7iTWpDYaNewkjU2trgcBZIsq/vnPFdBZ/D+2u4Nyaj5jrjJjUFG+hrjtWRk1i9RjllncE/8CNRvZulmtzkFC23iq4BJwBzSlSrFWBBHBBpKKKOnSinmaRo1jLsUXoueBTKKK1LHxDqunQeTa3kkcfZeuPpWfPM9xPJNKd0kjFmPqTUkN5NBGUjYAE56UJcHzFkPDhgd461u61LoU1mt1ppc30kgMolJGOOSO3WuaoooooooooqWKB5jhSg92cKP1qNhtYjIOO4NJRRRRRRRRRRRRRRRRRRRRRRRRRRRRRX/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reconstructions = model.reconstruct(img.to(device)).detach().cpu()\n",
    "to_pil_image(reconstructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08a9f635-226b-4dbb-b086-a832b8790b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = trained_model.embed(img.to(device)).detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dd82b68-2a45-4ce5-be87-ff8ecf4c948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = trained_model.encoder(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4c7bb6-d719-44f3-a7c9-ab6bb7132a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6fc608c-286f-4912-bfbe-2bcfdb433ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_str = z[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa528bd4-d3f9-4094-b92a-d9cb05264110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c4fc91f-b35b-4a36-ad4e-795a9c45fe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.3195,   0.3602,  -1.6743,  -8.1568,  -3.0431,  -0.6087,  -3.6286,\n",
       "           7.7889,  -6.0310,  -4.7175,   3.9854,  -7.9331,  -3.3360,   5.1176,\n",
       "           0.5529,  -6.0310,   5.5030,   0.2637,  -3.1402,  -8.1568, -15.7352,\n",
       "          -4.2202,   3.1337,   5.5030,  -4.6173,   3.4171,   3.3233,  -9.5880,\n",
       "           0.3602,   1.3202,  -0.0247,  -2.4535,  -5.1172,   4.7383,   4.2678,\n",
       "           1.0328,  -0.5114,  -0.8025,   5.1176,  -3.0431,  -4.9182,   0.1670,\n",
       "          -5.6213,  -7.8218,  -0.0247,  -2.7499,  -1.8674,   0.1670,   1.1280,\n",
       "         -10.8565,   8.5477,   1.0328,  -4.6173,  -2.0588,  -4.8190,   1.3202,\n",
       "          -0.6087,  -0.4141,  -9.5880,  -5.4190,   2.9419,   4.2678,  -4.8190,\n",
       "           5.7937,  -9.3362,  -3.8261,   2.8450,  -3.1402,  -5.7237,  -8.1568,\n",
       "           0.9383, -10.1184,  -6.1339,  -7.0730,  -2.3550,   2.2762,   3.0375,\n",
       "           2.8450,  -0.9958,  -7.2844,  -1.2877,  -5.0181,   8.8966,  -0.4141,\n",
       "           0.4553,   7.2703,  -0.8025,   1.4163,   0.6500,   3.8920,  -0.0247,\n",
       "           4.4542,   7.1688,   5.4056,  -6.2381,  -1.6743,  -3.8261,  -0.1206,\n",
       "           1.4163,  -5.4190,   0.5529,   2.0842,  -3.3360,   6.9671,   1.4163,\n",
       "          -4.1229,  -1.6743,   3.9854,  -8.4965,   2.5604,   0.1670,   5.1176,\n",
       "          -6.9673,  -2.0588,   3.6052,  -1.2877,   0.1670,   4.2678,   0.7473,\n",
       "           2.2762,  -2.4535,  -7.6023,  -3.4333,  -9.5880,   2.1796,   2.8450,\n",
       "          -7.9331,  -2.0588]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07ddf13e-6f1b-44d0-bfd6-b31427479a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-4.319532871246338,0.3602290451526642,-1.6743308305740356,-8.156848907470703,-3.043107748031616,-0.6086670756340027,-3.628629446029663,7.788941383361816,-6.031032085418701,-4.717513084411621,3.98541522026062,-7.9331278800964355,-3.335972785949707,5.117574214935303,0.5528723001480103,-6.031032085418701,5.502973556518555,0.2637450397014618,-3.1402313709259033,-8.156848907470703,-15.735175132751465,-4.220191478729248,3.1337242126464844,5.502973556518555,-4.617330551147461,3.4171180725097656,3.323286533355713,-9.587973594665527,0.3602290451526642,1.3202335834503174,-0.024736313149333,-2.4535439014434814,-5.117249965667725,4.738316535949707,4.267836093902588,1.032843828201294,-0.5113756060600281,-0.8025444746017456,5.117574214935303,-3.043107748031616,-4.9181928634643555,0.16701947152614594,-5.621335983276367,-7.821844100952148,-0.02473631501197815,-2.749936819076538,-1.8673763275146484,0.16701947152614594,1.1280473470687866,-10.85649585723877,8.547654151916504,1.032843828201294,-4.617330551147461,-2.058750629425049,-4.819037437438965,1.3202335834503174,-0.6086670756340027,-0.41412094235420227,-9.587973594665527,-5.419010162353516,2.9418787956237793,4.267836093902588,-4.819037437438965,5.793713569641113,-9.336204528808594,-3.826099157333374,2.8450253009796143,-3.1402313709259033,-5.723686218261719,-8.156848907470703,0.9383002519607544,-10.118432998657227,-6.1339263916015625,-7.073002338409424,-2.3549981117248535,2.2761764526367188,3.0374786853790283,2.8450253009796143,-0.995751142501831,-7.284363269805908,-1.2876983880996704,-5.018096446990967,8.896622657775879,-0.41412094235420227,0.4552600383758545,7.270308971405029,-0.8025444746017456,1.4163368940353394,0.6500109434127808,3.891983985900879,-0.024736313149333,4.454248428344727,7.168756484985352,5.405595302581787,-6.238136291503906,-1.6743308305740356,-3.826099157333374,-0.12060324847698212,1.4163368940353394,-5.419010162353516,0.5528723001480103,2.084198236465454,-3.335972785949707,6.9670610427856445,1.4163368940353394,-4.122880935668945,-1.6743308305740356,3.98541522026062,-8.496535301208496,2.5604054927825928,0.16701947152614594,5.117574214935303,-6.967281818389893,-2.058750629425049,3.6052417755126953,-1.2876983880996704,0.16701947152614594,4.267836093902588,0.7472715377807617,2.2761764526367188,-2.4535439014434814,-7.602266788482666,-3.433321714401245,-9.587973594665527,2.1796419620513916,2.8450253009796143,-7.9331278800964355,-2.058750629425049]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(z_str, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74fcf0e1-f2f6-4eef-924e-239c7534018e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiir32Sx/sI3n9of8TAXPl/YvJP+q258zzM468bcZ71RoooooooooopQvPPHr61u/wDCOxt4Pk15Lidyt0YPLFv8qgBTln3cEluBjsea0/CXg3T9d0fVNT1LxHYaSlkBtiuTlpOCScA7voAGJPGK49sE/KMCkooooooooop8jF5WkwF3EsAOAPpXsvw98K6ndJqmieIIUXw5YX6Xd7dSykKZIwSIwDkEMGBbocY5zgV5RrjRHXL9bbi2+0P5YAwNoJAOPXFZ1FFFFFFFFFFGa7HXPHOoX9hDZ6YJtPsfKX7SsUpH2ibaAztjjkrkCuPZmdizMWY8kk9aSiiiiiiiiilRGkcIilmY4AAySavy6VJZaxNp2oOLZ4JjDM+NwQg4OMdelXdc+zaRLLpWjatcXdhPHBLcM8XlB5ApOMZJIBY9e/rgE4VFFFFFFFFFLg12OjeIbvwf4itJZdOtIljUloJ4vM/duOhyc57joefQ4qHxNPdalZtql3GIYbmYPYKsKJ5kXzqSSoycFAOSefrmsvw5rFro2si+v9Kt9WjEbr9nuSdpZlIDH6E55z+BwRkE5JIAAPYdqSiiiiiiitDT7ETRS3Ul5HapCrMjHlncDIUD39Tx9elUWZnOWYscYyTU99qF5qdx9ovbmS4m2hN8jZOAMAVA0juqKzsyoNqgnO0ZJwPTkk/jTaKKKKKKKKKMkAjPBoooo44oooooooooooooooooooooor//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAD4ElEQVR4Ae2XXUgUURTH77nzuV9au+ZqmaF9SSGWFkIG0QdIRAUVUfSFENJTRC9B4IMvQUHYW71Eb9FDRQ89RUFQYBQlLKbRB0WoWbJZuunOzu5MM46jsy6z49zdSYg7LzP33nPO/9zfvefODEL0ogQoAUqAEqAEKAFKgBKgBCgBSoASoAQoAUqAEqAEKIGFIjD4DpNLE7ji94kgQkCu6dbTx5Vrav9QEFApARe308qyB2Cy2v+gQT5FMk9o9EEVmasbL6bOJFkZL+V/K16S5KMNdUv6Ykf1vYmF1+NXzpX4vNTTqoAV1vbsaQxoKkJnRlFkc7JuZR2R6nOKcEhNS9++hjMpBFiMjqkqn3GrNF/7gA/0Imc4ruLh0w4BlYVw2fGD8/XOtXOcoTKpIhUh/1ocLG/+nGLKJEi/uZcbqGg922bOMO5AqhV3HKslXT0jJccZxrXpGZeyHIHvfG2ksNVjzXB295HZgVuw/L4Q7Znt8OTJzGhpQIPRkJSeGfUnkoo5Ik1PR24XGah6yauPpamOpGeCiDU2yYb94tY+Tn7U55hi/lSc3TP+qX1asky4G0RPbgwazfxR84yaS2Rvokr6Pg086G8ZBqlbURgmM7Nx7b1sR5wFUUp3/iPu+vKu8+P3n0i2jVXcgfqRx5d41nkFnFQdI5gHDZfsu5xSss05p+gk46bgkhOhHHdzLGegGB0cEyhK/GxGeTKTM0EeIXHm5CZVd+GHy0NjcfPgyUkNCqmVnGhGB//ims2IR91Ml0eB7cLOe73tArjpB/ZixI09ua2+LVlu9YW7cg95EIunI6YtmgUjlvx4P7DX4ubhY28ZAB+qLF+z06ggxwwdcsn/tsBCK46Mc8JYAphfOIO0Yiv0j8JeENeP+ZYek+81K4GJ3ypa9EkBEGTFO8FwtKan7XDy9u6N8h3tW7hfQwXc8962QhVtkOPWU6tOVq94O9S1HdiqaSPxpjJRZ+NQWDcg3CJifhGz/uzFKPKfMXdKyeSZmdObUGHOGmJxQg+k7Y1uBOk/wkiClZCwuOnVVHgIhVBh391aTWcnquh6mNO/Pf3hgTSwseFxjPnYtNVgtjVJy4Sl+VrfVJiL7qtGqhx/MxS5vi4mGCCL8QayCBrhOB+rSkhR2zePAqiSokQOrY8lCgU5y8IiqHfCDn8Toyur4U0t+n8hQh+u3vrkUSlo0XEYpsnWHDdzMe+6ujeXdTG9UVi4qI1XKhEInupnLdCGI5OjCLz9ebAW/unR29XJgt8/DnysG2QlM5LwdnpzkoHg4izCc4b//6aVPvlsXTCsIFehnpQAJUAJUAJFJfAXl0vaAJKnD/4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(reconstructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10972170-4f15-4074-bf50-5a168692633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABwAHABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiituDwnqsmkT6rcQfYrKOLzI5bvMQuOcbYsj5z9KorplxJbLMjwOD/AJ13j/gJOalttHu30mbWWgH2CCRYy8h2rI5P3F7k4yTjoPTiumtfH66Z4GsNF0eyWw1OO5Z7u/jVQ1xHnKqWxnHOCDnhR6kDh6KKKKKK0H0efZ+5khuXVWaSO3feYwvJJI4IweoJ6Gqk1tPbpE80EkazJvjLoQHXJGRnqMgjPtWrFq2m2Zgms9HVrqOIIxvJRNEX2kM4j2jnJBAYsBjkGoLrxDql9bxwXd21xFHnYsyh8E5yeR15/l6VnAF3AA5Y4AFdV4o1qSLT7TwpZ3fnaTp58xGKpuaRwGbJXPAJIAz9a565069sYbW4ubWWKG6UyQSMuFlUHBKnvzVSiiiiiilBK8gkU+W4mmVFlmkkVMhAzEhc+npUdFFHeutsb1fEvh6HQ9U1VoH0pJDpMQtt/mtI2XjZ8jaMgEEggDPsK5Kiiiiitjw5YaZeamra3eSWmlRKzXEsJUyn5TtVFP3mLYHQ4zk8Csy58g3U32USC33nyhKQX2543Y4zjrioqKKKK0dItrK7mnjvr9LJBAzxyPGz5dcEKAvQnBAJ4/nWdRRRRU0cSi5RLgtGhI3kDJA74FKtsRdRwybkDkYO3kqehA4zWve+GLlJLL7FJBdreW6zxJG+JOSV2lGwS2Qchcj0JrIu7O6sJzBeW01vKOSkqFG/I1BRRRU1pGkt5BHK8ccbyKrPISFUE4JJAJwPYH6VDRRQAScDrUksLQSFJMbxjIBz2z2pCVd3baEzkhV6D25oaWRypZ2JUAKSeg9qv6XfWkF4JdTtpL2JY3VI/MxglGC9QeAxB/CtDVPEEWuQ2FtLptlZJa2n2cSWkI3zOBkM5J6lgMnsCevSsW8sLvT3RLu2lgMiCRPMQrvU9GX1B9RVeiipbeNZbqKN/M2O4VvLXc2CewyMn2zTZW3Ss3HJzx0q1Y2VvdzKlxqdrZIVLGSdZWA5xjCIxz36dqS6tLe3uxCt9HMgYq8kakgYPUetacU/h3T7DUE+zTanftIFs5pCYoY05y7KDkv0AGcc5OcYOE7b2LYAz6U2iilycYycdcV0LeJbrVfDNr4bureCRbebzLa5WHM6/KR5ecj5Scfl3wKyrjT7rS2ia+s2UTRF4xKCMg5AYYx0P4ZHOeRVKitrw1oP9uXs5muEtbCzhNxd3L5xGgIHHqxJAC9zWLRRRRRRRRT45DGWICkkY5Gce4962ofE0ksSW2s2kOq2yRiKPziUliUZxskXkYz0bcPam2UXhy7uGjuZr7T0AyszETBuehVVBXjHPPI6c8TiTwhFZXCPbazcXTO5hkS4jjRFx8gYFCSc53dOgxVe41zUtUs4tKtoI4LNFUm1sodokKry74+Z2wCcsTjJxgcVi0UUUUUUUUUUUU5HKOGGMj1AI/I02iiiiiiiiiiiiiv/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=112x112>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(reconstructions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39448cc-59d1-44f4-8884-4076fd9adbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e9b1d4-db55-4987-a879-ecba4b16d846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (decoder): Decoder_ResNet_VQVAE_CELEBA(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvTranspose2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (2): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Encoder_ResNet_VQVAE_CELEBA(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (2-3): 2 x Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (conv_block): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (2): ReLU()\n",
       "            (3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_qantized): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (quantizer): QuantizerEMA()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d8938-c987-4cb0-b4b5-f93af095a7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9380983-cea9-4540-9059-a720e8cde5d6",
   "metadata": {},
   "source": [
    "## Wek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "207a315c-1b1a-4561-8e5e-16aca6a6950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonosc import udp_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2391d512-e4ca-4d46-ad55-41fd824afdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip=\"192.168.0.13\"\n",
    "port=6448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c2c8b4b-e79e-4970-b232-a8f6a0701923",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = udp_client.SimpleUDPClient(ip, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac6506a7-e354-4077-aee3-168a25fb2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.send_message(\"/wek/inputs\", [1.,2.,3.,4.,5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae3be5-4ad9-460e-a7d9-f99c0e6274da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
