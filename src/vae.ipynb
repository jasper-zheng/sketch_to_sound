{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94468b07-186d-4b54-9fd0-a4bcbdf3140b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==2.1.2\n",
      "  Using cached pytorch_lightning-2.1.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (0.10.0)\n",
      "Requirement already satisfied: requests in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.9.0)\n",
      "Requirement already satisfied: setuptools in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning==2.1.2) (68.2.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12.0->pytorch-lightning==2.1.2) (0.41.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2023.7.22)\n",
      "Using cached pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.5.6\n",
      "    Uninstalling pytorch-lightning-1.5.6:\n",
      "      Successfully uninstalled pytorch-lightning-1.5.6\n",
      "Successfully installed pytorch-lightning-2.1.2\n",
      "Requirement already satisfied: torch in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (1.13.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: torchvision in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (0.14.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torchaudio in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (0.13.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: numpy in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1\n",
      "    Uninstalling torchvision-0.14.1:\n",
      "      Successfully uninstalled torchvision-0.14.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.1\n",
      "    Uninstalling torchaudio-0.13.1:\n",
      "      Successfully uninstalled torchaudio-0.13.1\n",
      "Successfully installed torch-2.1.1 torchaudio-2.1.1 torchvision-0.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning==2.1.2\n",
    "!pip install --upgrade torch torchvision torchaudio\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5399fdf6-459f-4109-bd5a-72579cf3b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc11c40-0ee1-4cba-8875-f7e48e985a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PyTorch-VAE'...\n",
      "remote: Enumerating objects: 859, done.\u001b[K\n",
      "remote: Total 859 (delta 0), reused 0 (delta 0), pack-reused 859\u001b[K\n",
      "Receiving objects: 100% (859/859), 46.47 MiB | 531.00 KiB/s, done.\n",
      "Resolving deltas: 100% (619/619), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AntixK/PyTorch-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75357d-cfb3-4796-804d-e34094864504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7380916-61f0-4b9f-8f8a-95a22584b2bc",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc9b7d8-1b20-4295-9efe-cbeea04d0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa73ea2e-0b41-48b1-91d7-e1360840362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from models import *\n",
    "from experiment import VAEXperiment\n",
    "import torch.backends.cudnn as cudnn\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "# from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from dataset import VAEDataset\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e98a824-50be-4dc0-998a-52ebb07dff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# config_file = './configs/bhvae.yaml'\n",
    "config_file = './configs/dfc_vae.yaml'\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "# tb_logger =  TensorBoardLogger(save_dir=config['logging_params']['save_dir'],\n",
    "#                                name=config['model_params']['name'],)\n",
    "logger = CSVLogger(save_dir=config['logging_params']['save_dir'], name=config['model_params']['name'])\n",
    "# seed_everything(config['exp_params']['manual_seed'], True)\n",
    "\n",
    "model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "experiment = VAEXperiment(model,\n",
    "                          config['exp_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb41854a-e173-40b9-bd98-dec94b2a4d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (decoder_input): Linear(in_features=32, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d2cfc5-a849-4efb-8e28-50393e78bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index 0\n",
      "processing index 500\n",
      "processing index 1000\n",
      "processing index 1500\n",
      "processing index 2000\n",
      "collected data (2217, 1, 64, 64)\n",
      "collected label (0,)\n",
      "torch.Size([2217, 1, 64, 64])\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "path = \"/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/datasets/crop_640/1\"\n",
    "path = os.path.join(path,'')\n",
    "size = 64\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "\n",
    "for i,f in enumerate(os.listdir(path)):\n",
    "  ext = os.path.splitext(f)[1]\n",
    "  filename = os.path.splitext(f)[0]\n",
    "  if ext.lower() not in valid_images:\n",
    "      continue\n",
    "  img = np.array(Image.open(os.path.join(path,f)))\n",
    "  img = torch.from_numpy(img)\n",
    "  img = torch.nn.functional.interpolate(img.unsqueeze(0).unsqueeze(0), size=(size,size), mode='bilinear',antialias=True)\n",
    "  \n",
    "  imgs.append(img[0].numpy())\n",
    "\n",
    "  if i%500==0:\n",
    "    print(f'processing index {i}')\n",
    "\n",
    "img_data_x = np.array(imgs)\n",
    "img_data_y = np.array(labels)\n",
    "np.random.shuffle(img_data_x)\n",
    "print(f'collected data {img_data_x.shape}\\ncollected label {img_data_y.shape}')\n",
    "\n",
    "img_data_x = torch.from_numpy(img_data_x)\n",
    "\n",
    "img_data_x = 1-img_data_x/255.\n",
    "\n",
    "print(img_data_x.shape)\n",
    "print(img_data_x.max())\n",
    "print(img_data_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b485ee-9483-4fc5-b680-46b756674d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VAEDataset(data_train= img_data_x[:2000],\n",
    "                  data_val= img_data_x[2000:],\n",
    "                  train_batch_size= 64,\n",
    "                  val_batch_size= 64,\n",
    "                  patch_size= 64, \n",
    "                  num_workers= 4, \n",
    "                  pin_memory=1)\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ef59dd-a669-49c7-9834-afcaedcd4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(data.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb30f25-682b-46e4-bb5a-774c0e1e3840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APP7jQbfTrVjbKTIB5iMe+OorQYjxBpSruAcJ8p9fasyFpdb099MkXZqdjloz/fA7VBazprts1hcII7mIEMDxurltS02bTbgxyKdv8LetUqKK9WnuQxjd1whbI/HisWzlOka9Nps2RFId0Z+tOvIpba7TUrcst7bviRT/GvrVTxFApeLXtOO3fgyoOxpp1S1vbNYtQTdBKPklHWNv8K5rUNPlsJBu+aJ+Y3HRhVOivUXAvdAwh+eMEqR6Vz+tTf2po9pqKHbe2h8uQDqcdDWqkjavpkd0rjz2jw2PUVkxy+faSDbh0JEkf8AOskRLFK9qxzBPzGfQ1TmupUtnsZ8sEPyZ/hqjRXf+FrzzNJUM3Kv5bA+hrNkU2epXlsw+RvmA9fWnaXcnTXK5zErhh/umoNenNnqTXlmMQz/AHh71mxXK3yvC+EbO6M+h9KqX9yLmRW2bXVdrn1IqpRXQ6E4t5ruEyYCqHGO5FaHibcDFfQ9WQNn2NUNHkGoQSWzMBMEO3PcVl3l/NNEtvIMCM4PvVEEg5FFFFbUKrFrkkakFXUjj6VsBlu/D8Ic5KM0Df0rkg0lrcHYxV0OMio2YuxZjknkmkooorUeP7HrUZByhYEH2qcymJ72DdjDeYoz3rImlM0rSNjJ64qOiiiitCaQT6dFJu/exNiqLyPI5d2JY96bRRRRRX//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil_image(a[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470872c-486a-482e-a415-a7134cfad3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71905b3-1135-4710-a434-68036d062e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ProgressBar\n",
    "\n",
    "class LitProgressBar(ProgressBar):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # don't forget this :)\n",
    "        self.enable = True\n",
    "\n",
    "    def disable(self):\n",
    "        self.enable = False\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)  # don't forget this :)\n",
    "        # percent = (batch_idx / self.total_train_batches) * 100\n",
    "        # sys.stdout.flush()\n",
    "        # sys.stdout.write(f'{percent:.01f} percent complete \\r')\n",
    "        pass\n",
    "\n",
    "bar = LitProgressBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7b6c29-f474-421c-bb87-8e196b48f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "runner = Trainer(logger=logger,\n",
    "                 callbacks=[\n",
    "                     # LearningRateMonitor(),\n",
    "                     bar,\n",
    "                     ModelCheckpoint(save_top_k=3, \n",
    "                                     every_n_epochs = 3000,\n",
    "                                     dirpath =os.path.join(logger.log_dir , \"checkpoints\"), \n",
    "                                     monitor= \"val_loss\",\n",
    "                                     save_last= True),\n",
    "                 ],\n",
    "                 # strategy=DDPPlugin(find_unused_parameters=False),\n",
    "                 # strategy=\"ddp_notebook\", \n",
    "                 log_every_n_steps = 16,\n",
    "                 accelerator=\"gpu\", \n",
    "                 devices=1,\n",
    "                 **config['trainer_params'])\n",
    "\n",
    "\n",
    "Path(f\"{logger.log_dir}/Samples\").mkdir(exist_ok=True, parents=True)\n",
    "Path(f\"{logger.log_dir}/Reconstructions\").mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156239a9-f96b-400b-8182-fb701642c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3966d7a8-7344-405a-a813-1015f13c9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory logs/DFCVAE/version_9 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | DFCVAE | 147 M \n",
      "---------------------------------\n",
      "3.3 M     Trainable params\n",
      "143 M     Non-trainable params\n",
      "147 M     Total params\n",
      "588.099   Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10000` reached.\n"
     ]
    }
   ],
   "source": [
    "runner.fit(experiment, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9face131-77b4-4e9e-8a66-5c57d9e515c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5c3e4-e8b8-4df2-abcb-91a6ef6f3bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f7cc9ed-657e-4d02-8fea-c7c4a470e5fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99094acc-ef72-42aa-9ea9-45baabc555f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/BetaVAE/my_exp_name/version_0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ee5a71-7720-41c5-976a-489faf708623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4918c466-64c3-4ef6-a912-b7790e99497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PyTorchVAE'\n",
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "%cd PyTorchVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9da3f3ec-812d-4ba5-917f-eb325d6edb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiirdrpt1eKzxR4iX70rkIi/VjxVgQaVZ/wCvuJL2Qf8ALO3+RPxdhk/gv40o1mZGC2FrbWmTgGKPc/8A302Wz9CKXX3zfRxyFWuooglzIoA3yZJOcdSMhSe+3NZVFWbOwuL+UpAmQo3O7HaqD1YngCrZfTdP4iX+0LgfxuCsKn2Xq344Hsap3d9c3zA3EzOF4VeiqPQKOAPpVetTTMWVtLqrDLxt5dsD/wA9SM7v+Ajn6lazCSSSTknqTSVbsbe3l8yW7n8qCLBKrgu5PQKP69B+QL7zU3uYhbQxi3s0OVgQ8E/3mP8AE3ufwxVGiitPV/8AR0tdOHH2ePdIP+mj/M35Dav/AAGsyiiiiir+jQxzanG0y7oYQ00g9VQFiPxxj8aqTzSXNxJPK26SRi7H1JOTUdFFFFFaWnnZpWqSL/rPLSP6KXGT+gH41m0UUUUUVqaMjXAvrRBukntiI17sysrAD3+U1mOjRuyOpVlOCCMEGkooooooo60UV//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACpUlEQVR4AWNgGAUjMAQYGdE8jc5Hk0blsktoqLPuvPofWZRoA5gElLVlf966zuJ/dfM/JBNYkNh4mDw6lgJPr2x995eB4Vnx3i9IKokxgFnOQv353tvfIdq4vvxC0s9A2AB+fVOWs7vewT1ud5YUA1gVzeXvb3zwB2GnrOoWBAfIwusCHmOTX2c2fEbWwOy3B4WPzwAhS737K58hhzjQJH3208jm4XGBmL3KlVlvURUzMHB7rviNKoYjHYg6Kp86hepWsL4AzhXw0EQ1CIUnElLtxoMiAuXI1fGjC2NxgbCD5tkjWGxnYGDNOnES3QCMWBB01D4/+SO6Mgjf7O9Z7BIIUWarhgABBBeVxVUrgyoA4qG6QCiUZ/ZTTEVQEc2XWOSQDWAyCji+5ydO/Yxmx7HEAJIB3EEK8+/i1M7AICJ8E4sswgD5mId9X7GogAsZ3ITmR7gIiAEzgNnGefNZtGSLopCBxXAVqgCEBzWAL4Rn6kts8ggxuX+PERwEC2KAbPSlPSi5HKEAzjI7ByyOcACVOn0sKRJVMVetEKoAlAdyAYfn2qtYJZEFNV++R+aisBk5UbhYOYyZBljFGZiAwv+xRQ+acmGsiQCoCGQAMcDwBg5biDSAxQCtJINbSqQBcv+ewLWgMog0QO8yrkRAnAFMKjdQ7UXwiDNAkP0FQgsqizgDlJ/gTOjEGaCB0wfEpQM2WdwFDVEuEP/1DtXjSDyiDFC7i7uoIcoAmYdIVqIxiTLgM57sSpQBb4XQrEXiEmXAO2EkHWhM4gwQwF3iEWXAZw5WNHsRXKIM+P6fC6EDjUWUAb+/86FpQ3CJMoDhvSBCBxqLOAPe4o4G4gx4bSIPrQPR7GdgwB0/yEq57I1ur8bSOEBWQ4DNijsYCegclR4KIQAArniLvm7cw5cAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('./datasets/crop_640/1/00011_614a_416c.png'))\n",
    "img = np.array(Image.open('../../datasets/3.png').convert(\"RGB\"))[:,:,0]\n",
    "img = torch.from_numpy(img).to(device)\n",
    "# img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "img = img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(64,64), mode='bilinear',antialias=True)\n",
    "\n",
    "# blur = GaussianBlur(3, sigma=1)\n",
    "# img = blur(img)\n",
    "\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50224623-9a7b-4608-9b2b-c57481dd06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e094e349-9c90-490f-9f37-9c2abad1046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, log_var = trained_model.encode(img.to(device))\n",
    "z = trained_model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21a2c686-335c-4048-a1e9-3b3ec81589db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5161, -0.3246,  1.7510, -1.1232,  2.1553, -0.9393, -0.9148,  0.8923,\n",
       "         -1.3707,  0.5278, -0.8792,  0.6021, -0.6998, -0.8677,  1.4106, -2.9050,\n",
       "         -0.3442,  0.6099,  0.0412, -0.0357,  0.0749, -0.4612, -2.3958,  1.1111,\n",
       "         -0.0031,  1.8033,  0.7100,  1.2481,  0.2133,  1.0154,  1.6087,  1.2706]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c072e356-6510-476f-bcee-29b9c0353dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAM4NFJS0VNBazXLhIoyxPpUTKVYqQQR60lFFFXbTS7i7+YARxDrI5AUfnWj9l0WxyLieS6k7CIhR+eas2GoWbXsVsti4iZgABOcj3yDj9KytfMR1mcQj5QcHnOTjk1m0Vfg0i5mUO+2GM87pGwCKsBNMsOZHa6lHQIcL+ODVS81Ga7OCSsY+6gJwKqZrXs/wDQNOe+b/WSfJD7dCTWQzFmLMSSe5pKnt5YoZN7pvI6A9M0XF5PcuWkkY57ZNQUU5FLOFAyScCtLWG8pbazBP7mMFhn+IgZrLooooorQ0eNXvPMkBMcQ8w/hzVS5ma4uHlYkljmoqKKKKK1LH93pN7LnlsKPzBrLooopKKWr+nyK0U9q5wsi/Lz/EOn8qoEYOD2ooopKKWgEg5FB55opK//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][0], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da3a775-6dbc-4927-ada9-8fc33f5c914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img_data_x[2100:2110].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84c40296-afe5-469d-a334-1ed82499ac45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiilpdjbd2Dj1ptFLSqjPnapOOuKsGzdIPMkBXPKg9x60tpa+bcosgKx5yx6cd66GbS7BfLndXFo6DZ84J6deD7Hj1qza6el7YT2ksBhTAa2JfliBnOc9/yrjZYnhlaORSrKcEGmUtb2iKp0+8bZvCqSyg844wfpwaSd2+27bxXMGwbASew6io7Gzma9Uyo32fb1dsAjHX6VY/tS2s2khdXuoWAUIzcYA68GnjxQkWRDZ/LtAUSSFtuO4/wrEv76TULtriUAO2M4+lVaKtWV/cafMZbeQqxGD6EfSrz689wc3dvHMQMDkgD8M1TutTubrKtIVjIA2AnAAqnRRRRRRRRRRRRRRRRRRRX/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAE40lEQVR4Ac1WWXPbNhAGQEKXZYuWZSuW66Mat2mauq1fMtPpTKc/v099ycTOJO400zaJbR2WRFEkRQLoLkBKFBs5svxSQiSOXex+++0SFCGE0EfcDLbD/vyd2sT17DjVS9egZ1SBCtwsufU83aaoVgU3Mx2tm8q1FCZrXggPAT64QSBpWwOCcTvHzFJbq/Z5zHNT645W9fxpvTU4mAM1bDyYgzkSw8bcYHaUpzory4/nFtcZPYqDBMo6frN7kAlzLevzMefnWWv5MQPreC9v2n3qOm86nWfl6Rh7M4Y6yFd33l9GDiKDyGxHfKtd+mRCTymCZBtMZ5X4qVgZeEh5wJ7oE2qOEE6xnMUMHpTMbz3SyvqR0QMExsvcLsUTB/SQHopHIJoCNWuzZEzgBIxjM73RyVgFyQycYgicEFngTp9NIy3L6IILJqlaaChWDNckZXa5OgqksGj94Mno7UDEhMlkB6ESsqLAmWmwyzTokhFVglW6NocQbLsjnUIIgCQ0lBMl4bb1d0AjgEgRLIC3JCzgjMrD6Q9vui1O+PvvA//0J+WOcd3og5hJG1Vn/jBYtFKemJHlbJ821cB/TnstcrFVa397OZpjhgglfpmAS6gvzScmgJG9VsXGNChiRcfFt71vrL7c7/zWZ8SttvALlmQMeNIcgKaJGTpATZksiCIOKImbt7+7vfj4unPZjYQXhyfeJuiibWwJB2BPJ4owrmKLbquqzalvE8k27Z2eaJ9fbf85HtcPO0cbH55+F08gk7PMQT6SvKINyzqYeuq0NHhXigJejZnbYnfjFyf9zsAbF3+p3AxJY6PTeQXsJ/UFWDQHaAW43/r6jJebjVqhzqeEFopRWQ5FlVz5RwdUchmw2uFNfPpsr6jV4YF/DmwTDYYUl4pDoWLvJbOpKEZDF7IvneDjbeXAaXDntVvfjfZIOL4TCBeZQA4Y0o05gwC2hs7zpr/BXNL48mlQgCqSrfaQ0cDaevFz+fzc2W7tqwv1RKA+esfcAQLNKVWKWR73QufvSTRqHHZ3Y7Br1YKv6p6K/Pdhk/nXo253PPpjkGQAK10S21Q2vjGU8GtP2HfSUuO+DVVLLN452rkVx4NXYdWXcfk6EixUQDzmDesH2LSTylYkZrQdDSe1gmTFbtETEKHl78Qfrgpvggm/sWAjExbEj+GbBw7S8wCsskF5a39E9krVqgpDtrNx+OzorBK1mO9TAUA5QDb1hawhD/gEDhADwor9v34sVMRR+Z+PzI2i9sn0pvnuamy7EB9EKAxXwDxGoDHgE95G/XajxWAk7V97teLECvvE+SK4bcmLYMrgZEBn2qM+XJK3EZbgXUAZJgKfVJ2eqQ3vJadDtlmXl1UxnoBfI0edxSvZp/nUnBLF+Q4nu5s9p8TkdeW1F1GoWu3vP6dWggLfBXMhAOBRwPnAtq2GcN0Ijg7cveh2cYa7EgQogOOKWEISDuzaofaNqzOM+ZHmYMEiwjEJguMlxbagkZ0YBf1lSr8MuF3/IONo6P6WOvusp6xXDXFxAd/q+z3dJ0W8+l40unyWhWvG+AF8AIKsLo7x/0HW6HLXyyX3Rfh52aPczzjALKyTCcPH/4KDddOQcgD9wxnAHWkdLM/wahL4nK/w5i2riKQO1mUBIervgsloWg+r93iOGAYfUQ3/AqGMGK9/fOkTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c304e1-487c-420c-95ec-85161b4df5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APD9E0mTW9Uiso5Fi3ctI/RB6n9B9SKoEYYj0NJW7oEG6C4b+K5lhsk/4G+5j+SY/wCBVmalcfatUu7j/nrM7/mSaq0VZutPurOC2muIti3KF4skZK5xnHb8a3fCh8rMq8M15bxk/wCz87kfmi/lXM9TRXS6N+5s9Of+7Nc3R+kcYK/qDXNUVpaPBH5st9coGtrNfMZW6SP/AAJ+J6+wNTa9NI4sI5nLzC3EkpP96Ri//oLLV7w78tgz+lwX/wC+IJT/AFrmaK6YfuNKHrDpRP8AwKWbH/oLVzNFbs9swmsPD8XEjSK1wf8Apq+Bg/7oIH13Vn6vdLeavdTx8RtIRGPRBwo/ICtnRvl8O3Uv9zz/ANYgv/s1czRXTax+4sLxOh321qP+2cWW/wDHttczWpo0aRyS6jMoaGyUOFPR5D9xfz5Pspp+kSP9pvdTlYs8EDybj1Mj/Ip+uWz+FZFdNp3y+B9Uk/29g/Fov6A1zNXNKtRfara2zHCPIA59F6sfwGTWjrU73VhBPsIFzcT3bYHADMFH/oBrCrW1X/QbW30leHj/AH1z7ysPu/8AAVwPqWpG/wBF8MovR724LH/cjGB+bM3/AHzWVXT6Rf6XH4SvrO9dmna5SSO3UEeaMdN3YZxnvxWnrWjeHbZ44TdLbWtvdzQvLEPMllICHGM/dXJGf55NQySaBHpmsX2mW3ktDHDDA7SMSzyoVkABPQAN7/nitq50O7HhCzsm220E9rBukkzgyPJlRgcnG1gP94+9c5Potnol6L0TG5trWINuYcTT7mVVUf3cru5/hHvXLySSTzPJIxeSRizE9STW34h0+7thAGgdbW1jS2DnoX5Zv/H9/Pt7Vg0UEknJOSafGyiRPMBMe4FlB6itTUfEeo6hqct59okTdcCeOMNxGRwmP90cCna7rKaklla2yNHa2kCRgN1eTaN7n3JH5AVmWlx9kvILkRpIYpFfY/3Wwc4PtXUtqunPaXCa7vuru/zdyyxNkxNtIiRQCAD8xJzkAYGM1zd3PZyoqWtl5G0/faUuzD36D8gKqUUUUUUUV//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAFZklEQVR4Ae1WW2wUVRj+d3ZnZ2bv1+5SC8WlLYWlK5RQgWCCESUFlBhFDH2QJ6MYffCZF8ODNtEHTXw00QcNISRqyi1iuZhUMERDoYW2kCJsLyy0sLduu7M3z2VunZluH3zU8zB7zn/+8833/9//n1mAeuPQHuGYp54DAFNvm4nddYuFeh7LAPidE4FM+V8AxKYL4Zn65+UQVh4WTBzjQ9DwyMSuNdEccO++7NBa6Zxdc6ceQNiL3ShAKzNeNAKE4SHjmzXaqWXFZ114QgF2XK1WjY6NyRLHZ4x2YgkcmFrAEwLgf3YQakbHhilwl+aNdmxxHxx4QAQmAJvGC5WS0REpEMhWjHZksbyV/ItTGFi2DFirJgyCM7CUiqtil8CTx9iYgY2f4kvGN7HOp0uJwLzWn3e7nygATJEzEcHB5CGSwk6G0Rq6AiufKgwsUONEgxN4F0TGZ1qI1lfPzcP62yRqHIK9WhZMkh1I13guawQGiAt/AtM2RrYwgLVWtZswQFXsFkmmdSC2fadE8LmSCgBbqTrmdE5oiQCCGWNuATorNwFWp2ifYwZc2ZRB6LG5ilx3H2rx+C36ShJCGVxGBlZXGhrMRNiaHkVht9AUkDpwzANrLESBzUH4sTEyYddpFFfINq0yYGrgNDLwLhRNe/H5x+PoaGxSqhwcAjrNG2UMpqtmKgovncGNi+4aOkgOKoyDVJVkoz9hcxUpAbb5rgZAKNhYqokWAfWRiYoSgSjI2cEM7KKdkSLSICAVI480azqlBKDlnpx1DMCWhLK8Vk5YvbPQOKUspYlEANYPyzskiQVnEZXG4sHbcxB5uNgGIBHgm7ASZGAAAJcxh26xaHfNkl31IRNoXCB3Ad6gAO6c6iTNApmKp6bHlQjAhhGlR5YEQCKEM7rMyAQscdRN0qAA3qy8Vn5RG0T1KZAJBDz3FT+JgREAMdCLwL14FhchQNukWvkSgCEHjPeJQYRNOSn3iRsKAZpEk0p2ODJ6Eey7z9DU8atRP8uDMGDthkpumpvTi9A5J51rKmiuWgJgUskbRmo6ERQCWhGlOuAMHzZm7bBeBIUAEx+U+aNfwkAo6Ss54JjQiaASCEr3MUUhAM6C/svYOjmvE0EhAG1J7e0jAWg4kWnHENhd6Y51il0lAM9pI6AhSK1gVdy55lHw1No/3qdYVALCSuk+pnuEAQKwWGHD+yyy2T3AuRuLqBNy2/rILnbUEFiVX9SjNrztyvvfLp3qCQkl4D7y/LSXHbxTgWg18OM6BtWuFZWPSgASw7Se8UE0yDtsrkPJ5r23J4ru+OtcbOd31RdQtzVGRksot9w7hwEc+3+R+9faPkQOyg8C4NszetG18WbJ/cGRA7+7Tty3N6BuizhuNE/4t3cnnrHA7pRyhYWRwNqBQ3gqpi6zsYEs03PtuhdOJiEwngPeLxY6i+/5Oo/uskZ29soEIDG2+IONAX4dzJVY8QK/5fhFtsbWkIAnAaLQtCPu+CqeTRUtB/uV29Wy8WxT94N+tfBwCOJkFrixkckTP1eL4lwBnH//AdDavplLnL+1ZiA40xk8r5AOBkOH773iVNY0iWiZ+zqf/l7qyewXWYAu25Hp66eF6Ei08OZxtfQ6ol3fXMlrrjocAh5lhSRA5QkAv/GHCx3X513nUivWjg1RH/zcyX+bCoO7qiRCBlBd6CyaPQ9Iy/xZ62bfp2qnCKHPU7Bl/dHxL4V4Bzd8Gf1H1J+U1vGraToLtPTOqD5ibxJcB6799sbBlunBhUUlqTqRWcsKybD1mF23tf9DW09fd0BnXXLp13u29oZhe2xJ/2U3+E+2LetT14FLqF1f1/H/zf9UBv4BE2LRijYZDKAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[1][5], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed3924f-40c2-414b-9076-3eb7f8cb4e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APBrW3NzLsX+6T+VQ0VesYFltLtznMabhj6iqFLSUuCOorS0cD7VIT0ETGs00Vr6cDHo9/J/eXaPzBrIoq7plus12DIMxINz844FTzXEF3MwdNqbQI8H0pNJ4W8k7LAfzyKzKK13PleHYx3kc/lxWRR3rVjItdMI/wCWkwLHnovHWs+EgyDeeMVdsjs0y/b1CqPzzWbRWtqAMek2KdipbH1ArJqxZRrLdxq5+TOW+lWrtt1qZuQHIVR7AVmg4Nadqh/sa8YZ+8uKzKfGu+VF9SBWrrgMbW0XOxYUK59No5rIxV1U+ywo7/elGVGe3rS3mVsbVSeCCwHt61Qre0Lypo54ZT+7dGyM46YOf0pJLPS45iZZpFQqCgyCTx14P6U22l0eGchlndSMAkjj36/pWzqlla3iR3TzfI9uohXcOcL9eOlc/b2QgJnvFKxqMopP3+/5VTkma5ug7nqQMegq1qClrS0k5xsAA9sDn86zakhneCTfGcHGKjLE9TRmrtvfskkYn3SRIMbM9qdqN/8Aa3AUERhQFBbPQVUhYCZC33cjNbOyEyQids2rRgLhhkY5z1rHuAgnYRg7M8ZNQ0UUUUtKXYjGTj0zSV//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][5], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6323df68-1e08-4bde-9208-901766884505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7651, -0.3429,  0.2855,  ...,  2.7808, -0.6138, -0.6194],\n",
       "        [ 0.7270,  0.2237, -0.3485,  ...,  0.3516, -0.2341, -0.3200],\n",
       "        [-0.1425,  0.0745,  0.0337,  ..., -1.3222,  0.2490, -0.1188],\n",
       "        ...,\n",
       "        [-1.0782,  0.2654,  0.0919,  ..., -1.7245, -1.7932, -0.3616],\n",
       "        [ 0.2611, -0.1742,  0.1069,  ...,  0.2260, -1.2800, -0.2895],\n",
       "        [ 1.0433,  0.1376,  0.0130,  ...,  1.9821, -1.2415, -0.2458]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14725a8f-0d6d-4fe4-90ae-84384797e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 ms, sys: 771 µs, total: 3.76 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu, log_var = model.encode(img_data_x[2100:2110].to(device))\n",
    "z = model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d75b2f0-14e5-4c6c-9b0f-c1b1cf13d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.039333"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.linalg.norm(z[1]-z[5])\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb0fa3e2-fd66-45ea-9f68-61029bf560aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = vae_models[config['model_params']['name']](**config['model_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3af0a7a3-7b24-40f9-8fc4-312a6cacefd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DFCVAE', 'in_channels': 1, 'latent_dim': 32}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "319ac148-a0de-4f75-babe-d34d3479245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dfe6f28-d15f-4852-9b26-5d478e3d0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE/logs/DFCVAE/version_6/checkpoints/last.ckpt'\n",
    "checkpoint = torch.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8519a59-cc41-4f31-82e9-45f3d91bed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9dd9d4c1-37af-4178-9b32-51577cec0fad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.0.1.weight', 'model.encoder.0.1.bias', 'model.encoder.0.1.running_mean', 'model.encoder.0.1.running_var', 'model.encoder.0.1.num_batches_tracked', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.1.1.weight', 'model.encoder.1.1.bias', 'model.encoder.1.1.running_mean', 'model.encoder.1.1.running_var', 'model.encoder.1.1.num_batches_tracked', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.2.1.weight', 'model.encoder.2.1.bias', 'model.encoder.2.1.running_mean', 'model.encoder.2.1.running_var', 'model.encoder.2.1.num_batches_tracked', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.3.1.weight', 'model.encoder.3.1.bias', 'model.encoder.3.1.running_mean', 'model.encoder.3.1.running_var', 'model.encoder.3.1.num_batches_tracked', 'model.encoder.4.0.weight', 'model.encoder.4.0.bias', 'model.encoder.4.1.weight', 'model.encoder.4.1.bias', 'model.encoder.4.1.running_mean', 'model.encoder.4.1.running_var', 'model.encoder.4.1.num_batches_tracked', 'model.fc_mu.weight', 'model.fc_mu.bias', 'model.fc_var.weight', 'model.fc_var.bias', 'model.decoder_input.weight', 'model.decoder_input.bias', 'model.decoder.0.0.weight', 'model.decoder.0.0.bias', 'model.decoder.0.1.weight', 'model.decoder.0.1.bias', 'model.decoder.0.1.running_mean', 'model.decoder.0.1.running_var', 'model.decoder.0.1.num_batches_tracked', 'model.decoder.1.0.weight', 'model.decoder.1.0.bias', 'model.decoder.1.1.weight', 'model.decoder.1.1.bias', 'model.decoder.1.1.running_mean', 'model.decoder.1.1.running_var', 'model.decoder.1.1.num_batches_tracked', 'model.decoder.2.0.weight', 'model.decoder.2.0.bias', 'model.decoder.2.1.weight', 'model.decoder.2.1.bias', 'model.decoder.2.1.running_mean', 'model.decoder.2.1.running_var', 'model.decoder.2.1.num_batches_tracked', 'model.decoder.3.0.weight', 'model.decoder.3.0.bias', 'model.decoder.3.1.weight', 'model.decoder.3.1.bias', 'model.decoder.3.1.running_mean', 'model.decoder.3.1.running_var', 'model.decoder.3.1.num_batches_tracked', 'model.final_layer.0.weight', 'model.final_layer.0.bias', 'model.final_layer.1.weight', 'model.final_layer.1.bias', 'model.final_layer.1.running_mean', 'model.final_layer.1.running_var', 'model.final_layer.1.num_batches_tracked', 'model.final_layer.3.weight', 'model.final_layer.3.bias', 'model.feature_network.features.0.weight', 'model.feature_network.features.0.bias', 'model.feature_network.features.1.weight', 'model.feature_network.features.1.bias', 'model.feature_network.features.1.running_mean', 'model.feature_network.features.1.running_var', 'model.feature_network.features.1.num_batches_tracked', 'model.feature_network.features.3.weight', 'model.feature_network.features.3.bias', 'model.feature_network.features.4.weight', 'model.feature_network.features.4.bias', 'model.feature_network.features.4.running_mean', 'model.feature_network.features.4.running_var', 'model.feature_network.features.4.num_batches_tracked', 'model.feature_network.features.7.weight', 'model.feature_network.features.7.bias', 'model.feature_network.features.8.weight', 'model.feature_network.features.8.bias', 'model.feature_network.features.8.running_mean', 'model.feature_network.features.8.running_var', 'model.feature_network.features.8.num_batches_tracked', 'model.feature_network.features.10.weight', 'model.feature_network.features.10.bias', 'model.feature_network.features.11.weight', 'model.feature_network.features.11.bias', 'model.feature_network.features.11.running_mean', 'model.feature_network.features.11.running_var', 'model.feature_network.features.11.num_batches_tracked', 'model.feature_network.features.14.weight', 'model.feature_network.features.14.bias', 'model.feature_network.features.15.weight', 'model.feature_network.features.15.bias', 'model.feature_network.features.15.running_mean', 'model.feature_network.features.15.running_var', 'model.feature_network.features.15.num_batches_tracked', 'model.feature_network.features.17.weight', 'model.feature_network.features.17.bias', 'model.feature_network.features.18.weight', 'model.feature_network.features.18.bias', 'model.feature_network.features.18.running_mean', 'model.feature_network.features.18.running_var', 'model.feature_network.features.18.num_batches_tracked', 'model.feature_network.features.20.weight', 'model.feature_network.features.20.bias', 'model.feature_network.features.21.weight', 'model.feature_network.features.21.bias', 'model.feature_network.features.21.running_mean', 'model.feature_network.features.21.running_var', 'model.feature_network.features.21.num_batches_tracked', 'model.feature_network.features.23.weight', 'model.feature_network.features.23.bias', 'model.feature_network.features.24.weight', 'model.feature_network.features.24.bias', 'model.feature_network.features.24.running_mean', 'model.feature_network.features.24.running_var', 'model.feature_network.features.24.num_batches_tracked', 'model.feature_network.features.27.weight', 'model.feature_network.features.27.bias', 'model.feature_network.features.28.weight', 'model.feature_network.features.28.bias', 'model.feature_network.features.28.running_mean', 'model.feature_network.features.28.running_var', 'model.feature_network.features.28.num_batches_tracked', 'model.feature_network.features.30.weight', 'model.feature_network.features.30.bias', 'model.feature_network.features.31.weight', 'model.feature_network.features.31.bias', 'model.feature_network.features.31.running_mean', 'model.feature_network.features.31.running_var', 'model.feature_network.features.31.num_batches_tracked', 'model.feature_network.features.33.weight', 'model.feature_network.features.33.bias', 'model.feature_network.features.34.weight', 'model.feature_network.features.34.bias', 'model.feature_network.features.34.running_mean', 'model.feature_network.features.34.running_var', 'model.feature_network.features.34.num_batches_tracked', 'model.feature_network.features.36.weight', 'model.feature_network.features.36.bias', 'model.feature_network.features.37.weight', 'model.feature_network.features.37.bias', 'model.feature_network.features.37.running_mean', 'model.feature_network.features.37.running_var', 'model.feature_network.features.37.num_batches_tracked', 'model.feature_network.features.40.weight', 'model.feature_network.features.40.bias', 'model.feature_network.features.41.weight', 'model.feature_network.features.41.bias', 'model.feature_network.features.41.running_mean', 'model.feature_network.features.41.running_var', 'model.feature_network.features.41.num_batches_tracked', 'model.feature_network.features.43.weight', 'model.feature_network.features.43.bias', 'model.feature_network.features.44.weight', 'model.feature_network.features.44.bias', 'model.feature_network.features.44.running_mean', 'model.feature_network.features.44.running_var', 'model.feature_network.features.44.num_batches_tracked', 'model.feature_network.features.46.weight', 'model.feature_network.features.46.bias', 'model.feature_network.features.47.weight', 'model.feature_network.features.47.bias', 'model.feature_network.features.47.running_mean', 'model.feature_network.features.47.running_var', 'model.feature_network.features.47.num_batches_tracked', 'model.feature_network.features.49.weight', 'model.feature_network.features.49.bias', 'model.feature_network.features.50.weight', 'model.feature_network.features.50.bias', 'model.feature_network.features.50.running_mean', 'model.feature_network.features.50.running_var', 'model.feature_network.features.50.num_batches_tracked', 'model.feature_network.classifier.0.weight', 'model.feature_network.classifier.0.bias', 'model.feature_network.classifier.3.weight', 'model.feature_network.classifier.3.bias', 'model.feature_network.classifier.6.weight', 'model.feature_network.classifier.6.bias'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee2e3d71-94b9-4cb6-b101-0f2ea0d0a5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoder.0.0.weight'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'model.encoder.0.0.weight'\n",
    "a = a.split('model.')\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa0042cf-c495-4653-bdbf-0016526191e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.0.0.weight\n",
      "model.encoder.0.0.bias\n",
      "model.encoder.0.1.weight\n",
      "model.encoder.0.1.bias\n",
      "model.encoder.0.1.running_mean\n",
      "model.encoder.0.1.running_var\n",
      "model.encoder.0.1.num_batches_tracked\n",
      "model.encoder.1.0.weight\n",
      "model.encoder.1.0.bias\n",
      "model.encoder.1.1.weight\n",
      "model.encoder.1.1.bias\n",
      "model.encoder.1.1.running_mean\n",
      "model.encoder.1.1.running_var\n",
      "model.encoder.1.1.num_batches_tracked\n",
      "model.encoder.2.0.weight\n",
      "model.encoder.2.0.bias\n",
      "model.encoder.2.1.weight\n",
      "model.encoder.2.1.bias\n",
      "model.encoder.2.1.running_mean\n",
      "model.encoder.2.1.running_var\n",
      "model.encoder.2.1.num_batches_tracked\n",
      "model.encoder.3.0.weight\n",
      "model.encoder.3.0.bias\n",
      "model.encoder.3.1.weight\n",
      "model.encoder.3.1.bias\n",
      "model.encoder.3.1.running_mean\n",
      "model.encoder.3.1.running_var\n",
      "model.encoder.3.1.num_batches_tracked\n",
      "model.encoder.4.0.weight\n",
      "model.encoder.4.0.bias\n",
      "model.encoder.4.1.weight\n",
      "model.encoder.4.1.bias\n",
      "model.encoder.4.1.running_mean\n",
      "model.encoder.4.1.running_var\n",
      "model.encoder.4.1.num_batches_tracked\n",
      "model.fc_mu.weight\n",
      "model.fc_mu.bias\n",
      "model.fc_var.weight\n",
      "model.fc_var.bias\n",
      "model.decoder_input.weight\n",
      "model.decoder_input.bias\n",
      "model.decoder.0.0.weight\n",
      "model.decoder.0.0.bias\n",
      "model.decoder.0.1.weight\n",
      "model.decoder.0.1.bias\n",
      "model.decoder.0.1.running_mean\n",
      "model.decoder.0.1.running_var\n",
      "model.decoder.0.1.num_batches_tracked\n",
      "model.decoder.1.0.weight\n",
      "model.decoder.1.0.bias\n",
      "model.decoder.1.1.weight\n",
      "model.decoder.1.1.bias\n",
      "model.decoder.1.1.running_mean\n",
      "model.decoder.1.1.running_var\n",
      "model.decoder.1.1.num_batches_tracked\n",
      "model.decoder.2.0.weight\n",
      "model.decoder.2.0.bias\n",
      "model.decoder.2.1.weight\n",
      "model.decoder.2.1.bias\n",
      "model.decoder.2.1.running_mean\n",
      "model.decoder.2.1.running_var\n",
      "model.decoder.2.1.num_batches_tracked\n",
      "model.decoder.3.0.weight\n",
      "model.decoder.3.0.bias\n",
      "model.decoder.3.1.weight\n",
      "model.decoder.3.1.bias\n",
      "model.decoder.3.1.running_mean\n",
      "model.decoder.3.1.running_var\n",
      "model.decoder.3.1.num_batches_tracked\n",
      "model.final_layer.0.weight\n",
      "model.final_layer.0.bias\n",
      "model.final_layer.1.weight\n",
      "model.final_layer.1.bias\n",
      "model.final_layer.1.running_mean\n",
      "model.final_layer.1.running_var\n",
      "model.final_layer.1.num_batches_tracked\n",
      "model.final_layer.3.weight\n",
      "model.final_layer.3.bias\n",
      "model.feature_network.features.0.weight\n",
      "model.feature_network.features.0.bias\n",
      "model.feature_network.features.1.weight\n",
      "model.feature_network.features.1.bias\n",
      "model.feature_network.features.1.running_mean\n",
      "model.feature_network.features.1.running_var\n",
      "model.feature_network.features.1.num_batches_tracked\n",
      "model.feature_network.features.3.weight\n",
      "model.feature_network.features.3.bias\n",
      "model.feature_network.features.4.weight\n",
      "model.feature_network.features.4.bias\n",
      "model.feature_network.features.4.running_mean\n",
      "model.feature_network.features.4.running_var\n",
      "model.feature_network.features.4.num_batches_tracked\n",
      "model.feature_network.features.7.weight\n",
      "model.feature_network.features.7.bias\n",
      "model.feature_network.features.8.weight\n",
      "model.feature_network.features.8.bias\n",
      "model.feature_network.features.8.running_mean\n",
      "model.feature_network.features.8.running_var\n",
      "model.feature_network.features.8.num_batches_tracked\n",
      "model.feature_network.features.10.weight\n",
      "model.feature_network.features.10.bias\n",
      "model.feature_network.features.11.weight\n",
      "model.feature_network.features.11.bias\n",
      "model.feature_network.features.11.running_mean\n",
      "model.feature_network.features.11.running_var\n",
      "model.feature_network.features.11.num_batches_tracked\n",
      "model.feature_network.features.14.weight\n",
      "model.feature_network.features.14.bias\n",
      "model.feature_network.features.15.weight\n",
      "model.feature_network.features.15.bias\n",
      "model.feature_network.features.15.running_mean\n",
      "model.feature_network.features.15.running_var\n",
      "model.feature_network.features.15.num_batches_tracked\n",
      "model.feature_network.features.17.weight\n",
      "model.feature_network.features.17.bias\n",
      "model.feature_network.features.18.weight\n",
      "model.feature_network.features.18.bias\n",
      "model.feature_network.features.18.running_mean\n",
      "model.feature_network.features.18.running_var\n",
      "model.feature_network.features.18.num_batches_tracked\n",
      "model.feature_network.features.20.weight\n",
      "model.feature_network.features.20.bias\n",
      "model.feature_network.features.21.weight\n",
      "model.feature_network.features.21.bias\n",
      "model.feature_network.features.21.running_mean\n",
      "model.feature_network.features.21.running_var\n",
      "model.feature_network.features.21.num_batches_tracked\n",
      "model.feature_network.features.23.weight\n",
      "model.feature_network.features.23.bias\n",
      "model.feature_network.features.24.weight\n",
      "model.feature_network.features.24.bias\n",
      "model.feature_network.features.24.running_mean\n",
      "model.feature_network.features.24.running_var\n",
      "model.feature_network.features.24.num_batches_tracked\n",
      "model.feature_network.features.27.weight\n",
      "model.feature_network.features.27.bias\n",
      "model.feature_network.features.28.weight\n",
      "model.feature_network.features.28.bias\n",
      "model.feature_network.features.28.running_mean\n",
      "model.feature_network.features.28.running_var\n",
      "model.feature_network.features.28.num_batches_tracked\n",
      "model.feature_network.features.30.weight\n",
      "model.feature_network.features.30.bias\n",
      "model.feature_network.features.31.weight\n",
      "model.feature_network.features.31.bias\n",
      "model.feature_network.features.31.running_mean\n",
      "model.feature_network.features.31.running_var\n",
      "model.feature_network.features.31.num_batches_tracked\n",
      "model.feature_network.features.33.weight\n",
      "model.feature_network.features.33.bias\n",
      "model.feature_network.features.34.weight\n",
      "model.feature_network.features.34.bias\n",
      "model.feature_network.features.34.running_mean\n",
      "model.feature_network.features.34.running_var\n",
      "model.feature_network.features.34.num_batches_tracked\n",
      "model.feature_network.features.36.weight\n",
      "model.feature_network.features.36.bias\n",
      "model.feature_network.features.37.weight\n",
      "model.feature_network.features.37.bias\n",
      "model.feature_network.features.37.running_mean\n",
      "model.feature_network.features.37.running_var\n",
      "model.feature_network.features.37.num_batches_tracked\n",
      "model.feature_network.features.40.weight\n",
      "model.feature_network.features.40.bias\n",
      "model.feature_network.features.41.weight\n",
      "model.feature_network.features.41.bias\n",
      "model.feature_network.features.41.running_mean\n",
      "model.feature_network.features.41.running_var\n",
      "model.feature_network.features.41.num_batches_tracked\n",
      "model.feature_network.features.43.weight\n",
      "model.feature_network.features.43.bias\n",
      "model.feature_network.features.44.weight\n",
      "model.feature_network.features.44.bias\n",
      "model.feature_network.features.44.running_mean\n",
      "model.feature_network.features.44.running_var\n",
      "model.feature_network.features.44.num_batches_tracked\n",
      "model.feature_network.features.46.weight\n",
      "model.feature_network.features.46.bias\n",
      "model.feature_network.features.47.weight\n",
      "model.feature_network.features.47.bias\n",
      "model.feature_network.features.47.running_mean\n",
      "model.feature_network.features.47.running_var\n",
      "model.feature_network.features.47.num_batches_tracked\n",
      "model.feature_network.features.49.weight\n",
      "model.feature_network.features.49.bias\n",
      "model.feature_network.features.50.weight\n",
      "model.feature_network.features.50.bias\n",
      "model.feature_network.features.50.running_mean\n",
      "model.feature_network.features.50.running_var\n",
      "model.feature_network.features.50.num_batches_tracked\n",
      "model.feature_network.classifier.0.weight\n",
      "model.feature_network.classifier.0.bias\n",
      "model.feature_network.classifier.3.weight\n",
      "model.feature_network.classifier.3.bias\n",
      "model.feature_network.classifier.6.weight\n",
      "model.feature_network.classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "keys = list(checkpoint['state_dict'].items())\n",
    "for k in keys:\n",
    "    print(k[0])\n",
    "    checkpoint['state_dict'][k[0].split('model.')[1]] = checkpoint['state_dict'][k[0]]\n",
    "    del checkpoint['state_dict'][k[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47d0b5d0-fe01-42fe-a3b9-51971d334943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc161767-098e-47cc-a0b3-bd012123ac7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=64, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=64, bias=True)\n",
       "  (decoder_input): Linear(in_features=64, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trained_model.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.to(device)\n",
    "# - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b6d273c-c9e0-4851-bb19-fc2479b61192",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trained_model(img_data_x[2100:2110].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8583a5eb-b4c1-4a3c-a957-44c91bb6ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiilKkDJBpKKKUAmtGHSXZQ00gi3JvUHksMZzUdpY+beRRzkpG3O49xjNdCLe1doxcQhbMoBEufmbC53HB9qfe2sU1lIzrtjaNfsy7uSAuc/oa45lKnDAg+9JRW3ZRK1lHKihlAYSrnnoMH6cVK8UkV75lyG8ryVVMn7w2gg/Sm6dbvPfo84JRlAQE4yAOv0q3eajDbXjNcbpwEVEi3DAAA5OOn0qkfELyTs00XmRlAgjZjgAf56Vn6hftfziRkVMADA+mKp0VYtLyazmEkTYPcHoa0H1+a4c/aY0kTYE2cgDH41FJrdyQwjCxgqFGOoA9PSs0ksckkn3pKKKKKKKKKKKKKKKKKKK//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAEV0lEQVR4Ac1XbVPiSBCembwRgoKAeKcIrlq7dVt1ZdX9/79wtd9uz3JvrxRckRcFQkKSSdLXM0MELE6P8OXSJhmT7qeffrqTKCGE0B12huEYL/ZcOIQwChiKO0JtC4FpZWaMzLdhPAaKY36TEPnSv0Tlz64iX4ByL3ZjsJMGogViDnL3QHUwd+kvgfkZiMidNFhw2I2BEvKlnFyL3Ri8qcF79N6dg/ee1G3mICOz4f3xHyZxyYSAeAWt2psaqJ5kyf+1Q6t4r9aCsIinDBMzxgx9LbvyVi6v4WWYpC5ADKpRqjtOmRgSYc2bUmAphY0mHME4KRLfmyaVq7Qf+n0ar/kTqgMqs9kIULyjnwYmN0Ln0O7qxTTWEXNhYkVAV9+FjIH4REj+GscSQUtO4WP3Wv9wVfyrPnqsn3F3jLSUtzqzDE+dMZ4BgGMy7C8Qo177Nf4y4fv1WRu+gdFqJCLFwgQOQQYrhndZYV61aszvJhED+/AivPb3q3O36t0kjeqYFmbCJ810ww5leKq2FOXW91rsTH60bO/Iv3YL1XIv7HzjJcsc1HxBDEi6YCE1kGh4AdFSYtJPQGJ36rP9aYFG9GH+U7lEhmfP0aejstf5zYkTDMbe4UEaA6rQZDyWbp7U+l/JMI1OPmoT9jh9Kl8Efxr92Ug/fro27vViQ9cAUsiYCw2QPUquGQdBfUjMYPAMup8UreHctP2wfTYaOEWfn7eeJ/v2g3bZ+mM4IrDIL+dAsMfm6XGlRxzqzW9dDcKSN+zMNXB/Phx96etWeL739ZpX7YJ1kLgaSYUSIooAWww8g1LTccPDIk8DBvFBfRZGjGrN8x+um5qlqw93YAeu/cula7Xkx0T9aUIJTqJEItSoAA8ZVMcJIVplUJglTK/UJxU7NGsVemP17r3otjwORn1XKijyr8wBgWjW0nhInJTrthYy3Wf6gfZUbT7wM6c7NoZzbsadOzNMAuQvpxV1WD4LQKYW+Xw/YnsFMEqTohsCmMVBiw67B2nnHiebAuexNhNphexIXGqAXVBzRYjtn7D0rnB67Di3gReX7ePEb1iPl/POI6Si5ITgyAjaYhMnMQm6mAMxGsB/mOM66yfHzvdbw414tTb4+3TmecGNJ/qOWSkeRfvxZ2nZs4BjGD2Ujuhnv2IM2uw+3Wty3j730m48S0Sn1OTho4ogS5MTrzjJO42LUqH8O5S1Hj/Uhk6D9n+M9ESSlbzXDos4IYhERFrUapai9tP3crMY9tq9CTUfx8mrnMvsi9USFBGN1GDWFMyjvcC3enMr5eL1sHTZsMLurCABMzhJNaoxPUpilTtjmPmtneXrawkrXtS4oWbZoMrflw4bVmtfJhWNpWBrs1AB+pZhvg2w21x6C/39ezJ9XgoqDjUQVeQxFbdNtZt98+RexuzUghcNlnjbrf5HGuSdA9WUHeZAKba5t9tcFTh5ZxEjVf27qCDfB/kZqP+4VQ3b1L3i+w/5Wzggxj9ijwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55632a16-1a60-48b3-986d-c20318fe2ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiinCKQxmQIxQHBbHA/Gm0UUu0lSwBwOprYh0iGTQ3unkkW5KPOg42eWrKnPfJYkD/d96raRp8eoXTieVoraJN8sijJAyAAB6kkCunn0iCTULvRGSOO0t5oPs86IA7b2AwT1LMpJx0ynHFPtEhv/DT+dJJB9vumtbeGIgJbxxqHZivfkpk8HjNcLRRWpHk+F7gJnAvI/Mx/uPt/9mrT1Mi28H6W4yHvotmMYwkcjk/mzA/8BqrolpJfaRqcUbCMRmKeWU9EjUsCT+LA474rc8R6xpbzrK8d4LmaRLl4FKps2oFjBbkg4y2AON+M8VSuvGMEyXCppgVLhTujEm1ISww5jwMjdk5JJJBx2BrnLq6inVVis4LdV/55liT9SxNVqKsWl9cWRfyHAEgw6sgZW7jIIIq4usvchotVEt3CTuUB9rRnGPlOCAMAAjGOB6UyTWbvfH9lb7JFEcxxQEgL2ye7H3NUJJHmlaWV2eRzuZmOST6k02iiiiiiiiiiiiiiiiiiv//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACoklEQVR4AWNgGAWjITAaAqMhMBoCwygEGIn3C7OS4otLGMqZMEQwBLhshEBifFEBrJFcGLIsGCLoApJRPHoz/jEohJ1dqfv2D7osAzYXMLIiKZOJPtgjKcfAHblj7z+7C7+QZCBMbC5ws1l0G6pQQtd09W2Gs5YPfW5dZnCPlGHfie4GLC7gdtgTDvY1AwNPqoM5UMUZLTGD3f953C5OkA1EdwIWAzTeHn5gBFFn9nrbHX9Ghh9/JF59YpCSuv1kmzq6BnQ+UKPhyX/sEIeyWB/6/Jybl0Hn5TdgdLPKnf6v+uwfmhOQDWDS4APKskje4VS5DlamzHT7598vwkxWh1+IijN8fnGNyfQUmn6UWBBJ5QRK87O8Vf70GqzO6vjvD7ysTEK89z6ft2fW+6AmzXsH3QDkWBC79xIoLfb+l9lZsEOZpHczfBZkeK39+DvDwQqhrw2xf87+YGDjF3n5DmEMsgF8H0DizL+4VTeDFTAx/WD4/knkq+4VBg4DjW8trO+cTzvLCv95fRyHATyfQfq+caq/ewM24O8vTgZmNjYVzeu++p9agoKUbzfpPTn68gvYeWAVQALZBX/BKfA3p/mZ/2Dp/x+EHlu82VokZHxl4dP/H9i2v2M4D9MHp5ENeKcMEv4gLrsaKn1f9b/+HK4XDS9ABl6FCqJRyNH4VpwZKPvl15O3UEU3PF1XfQvd8xziIDSdUC6yAS/YZICicmqfoRrY9cQevrH7cxy7TqgoSoHiKbORScv9lMmk5yBZmZDXx33+8c+CpAlcpqAYwBEg+v/t8YfWGkt+MLDam+248I9P8R44anBpZ2BAMQDIBbme0VV8HV/Q9/XvcWtDyKAZAJFgcrX6s+vMX4QqklmMMoIk6xnVMBoCoyEwGgJDPwQAQffOj8PrEHYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[1][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c20aed5c-8906-4156-bdc6-349c2c3e9c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 ms, sys: 12.9 ms, total: 16.4 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu, log_var = trained_model.encode(img_data_x[2100:2110].to(device))\n",
    "z = trained_model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6546cb5-eba8-4e82-8e25-05669c7cc780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "075c8d24-2223-4c0c-a4f1-89146a0e759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1256a393-291e-4798-8e3f-e42991fb5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyTorchVAE.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1b86d9f-d72e-43a7-9b79-447fc9f12fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PyTorchVAE/models' -> './models'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints' -> './models/.ipynb_checkpoints'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/vanilla_vae-checkpoint.py' -> './models/.ipynb_checkpoints/vanilla_vae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/base-checkpoint.py' -> './models/.ipynb_checkpoints/base-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/__init__-checkpoint.py' -> './models/.ipynb_checkpoints/__init__-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/beta_vae-checkpoint.py' -> './models/.ipynb_checkpoints/beta_vae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/dfcvae-checkpoint.py' -> './models/.ipynb_checkpoints/dfcvae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/dfcvae_app-checkpoint.py' -> './models/.ipynb_checkpoints/dfcvae_app-checkpoint.py'\n",
      "'PyTorchVAE/models/dfcvae_app.py' -> './models/dfcvae_app.py'\n",
      "'PyTorchVAE/models/__init__.py' -> './models/__init__.py'\n",
      "'PyTorchVAE/models/base.py' -> './models/base.py'\n",
      "'PyTorchVAE/models/beta_vae.py' -> './models/beta_vae.py'\n",
      "'PyTorchVAE/models/betatc_vae.py' -> './models/betatc_vae.py'\n",
      "'PyTorchVAE/models/cat_vae.py' -> './models/cat_vae.py'\n",
      "'PyTorchVAE/models/cvae.py' -> './models/cvae.py'\n",
      "'PyTorchVAE/models/dfcvae.py' -> './models/dfcvae.py'\n",
      "'PyTorchVAE/models/dip_vae.py' -> './models/dip_vae.py'\n",
      "'PyTorchVAE/models/fvae.py' -> './models/fvae.py'\n",
      "'PyTorchVAE/models/gamma_vae.py' -> './models/gamma_vae.py'\n",
      "'PyTorchVAE/models/hvae.py' -> './models/hvae.py'\n",
      "'PyTorchVAE/models/info_vae.py' -> './models/info_vae.py'\n",
      "'PyTorchVAE/models/iwae.py' -> './models/iwae.py'\n",
      "'PyTorchVAE/models/joint_vae.py' -> './models/joint_vae.py'\n",
      "'PyTorchVAE/models/logcosh_vae.py' -> './models/logcosh_vae.py'\n",
      "'PyTorchVAE/models/lvae.py' -> './models/lvae.py'\n",
      "'PyTorchVAE/models/miwae.py' -> './models/miwae.py'\n",
      "'PyTorchVAE/models/mssim_vae.py' -> './models/mssim_vae.py'\n",
      "'PyTorchVAE/models/swae.py' -> './models/swae.py'\n",
      "'PyTorchVAE/models/twostage_vae.py' -> './models/twostage_vae.py'\n",
      "'PyTorchVAE/models/types_.py' -> './models/types_.py'\n",
      "'PyTorchVAE/models/vampvae.py' -> './models/vampvae.py'\n",
      "'PyTorchVAE/models/vanilla_vae.py' -> './models/vanilla_vae.py'\n",
      "'PyTorchVAE/models/vq_vae.py' -> './models/vq_vae.py'\n",
      "'PyTorchVAE/models/wae_mmd.py' -> './models/wae_mmd.py'\n",
      "'PyTorchVAE/models/__pycache__' -> './models/__pycache__'\n",
      "'PyTorchVAE/models/__pycache__/__init__.cpython-310.pyc' -> './models/__pycache__/__init__.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/base.cpython-310.pyc' -> './models/__pycache__/base.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/types_.cpython-310.pyc' -> './models/__pycache__/types_.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/dfcvae.cpython-310.pyc' -> './models/__pycache__/dfcvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/gamma_vae.cpython-310.pyc' -> './models/__pycache__/gamma_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/wae_mmd.cpython-310.pyc' -> './models/__pycache__/wae_mmd.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/cvae.cpython-310.pyc' -> './models/__pycache__/cvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/hvae.cpython-310.pyc' -> './models/__pycache__/hvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vampvae.cpython-310.pyc' -> './models/__pycache__/vampvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/iwae.cpython-310.pyc' -> './models/__pycache__/iwae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/mssim_vae.cpython-310.pyc' -> './models/__pycache__/mssim_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/fvae.cpython-310.pyc' -> './models/__pycache__/fvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/cat_vae.cpython-310.pyc' -> './models/__pycache__/cat_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/joint_vae.cpython-310.pyc' -> './models/__pycache__/joint_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/info_vae.cpython-310.pyc' -> './models/__pycache__/info_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/lvae.cpython-310.pyc' -> './models/__pycache__/lvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/logcosh_vae.cpython-310.pyc' -> './models/__pycache__/logcosh_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/swae.cpython-310.pyc' -> './models/__pycache__/swae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/miwae.cpython-310.pyc' -> './models/__pycache__/miwae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vq_vae.cpython-310.pyc' -> './models/__pycache__/vq_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/betatc_vae.cpython-310.pyc' -> './models/__pycache__/betatc_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/dip_vae.cpython-310.pyc' -> './models/__pycache__/dip_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vanilla_vae.cpython-310.pyc' -> './models/__pycache__/vanilla_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/beta_vae.cpython-310.pyc' -> './models/__pycache__/beta_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/dfcvae-Copy1.py' -> './models/dfcvae-Copy1.py'\n"
     ]
    }
   ],
   "source": [
    "!cp -av PyTorchVAE/models ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0fdda-83e6-41f7-8dbf-778ff7b4acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
