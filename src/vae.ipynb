{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94468b07-186d-4b54-9fd0-a4bcbdf3140b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==2.1.2\n",
      "  Using cached pytorch_lightning-2.1.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (0.10.0)\n",
      "Requirement already satisfied: requests in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.9.0)\n",
      "Requirement already satisfied: setuptools in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning==2.1.2) (68.2.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12.0->pytorch-lightning==2.1.2) (0.41.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2023.7.22)\n",
      "Using cached pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.5.6\n",
      "    Uninstalling pytorch-lightning-1.5.6:\n",
      "      Successfully uninstalled pytorch-lightning-1.5.6\n",
      "Successfully installed pytorch-lightning-2.1.2\n",
      "Requirement already satisfied: torch in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (1.13.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: torchvision in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (0.14.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torchaudio in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (0.13.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: numpy in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.14.1\n",
      "    Uninstalling torchvision-0.14.1:\n",
      "      Successfully uninstalled torchvision-0.14.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.13.1\n",
      "    Uninstalling torchaudio-0.13.1:\n",
      "      Successfully uninstalled torchaudio-0.13.1\n",
      "Successfully installed torch-2.1.1 torchaudio-2.1.1 torchvision-0.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning==2.1.2\n",
    "!pip install --upgrade torch torchvision torchaudio\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5399fdf6-459f-4109-bd5a-72579cf3b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc11c40-0ee1-4cba-8875-f7e48e985a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PyTorch-VAE'...\n",
      "remote: Enumerating objects: 859, done.\u001b[K\n",
      "remote: Total 859 (delta 0), reused 0 (delta 0), pack-reused 859\u001b[K\n",
      "Receiving objects: 100% (859/859), 46.47 MiB | 531.00 KiB/s, done.\n",
      "Resolving deltas: 100% (619/619), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AntixK/PyTorch-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75357d-cfb3-4796-804d-e34094864504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98fb5c-b70d-4f95-83a1-522920e22391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc9b7d8-1b20-4295-9efe-cbeea04d0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa73ea2e-0b41-48b1-91d7-e1360840362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from models import *\n",
    "from experiment import VAEXperiment\n",
    "import torch.backends.cudnn as cudnn\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "# from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from dataset import VAEDataset\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e98a824-50be-4dc0-998a-52ebb07dff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# config_file = './configs/bhvae.yaml'\n",
    "config_file = './configs/dfc_vae.yaml'\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "# tb_logger =  TensorBoardLogger(save_dir=config['logging_params']['save_dir'],\n",
    "#                                name=config['model_params']['name'],)\n",
    "logger = CSVLogger(save_dir=config['logging_params']['save_dir'], name=config['model_params']['name'])\n",
    "# seed_everything(config['exp_params']['manual_seed'], True)\n",
    "\n",
    "model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "experiment = VAEXperiment(model,\n",
    "                          config['exp_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb41854a-e173-40b9-bd98-dec94b2a4d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (decoder_input): Linear(in_features=128, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dcd138-0471-4ca2-a5dc-92adf70f4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d2cfc5-a849-4efb-8e28-50393e78bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index 0\n",
      "processing index 500\n",
      "processing index 1000\n",
      "processing index 1500\n",
      "processing index 2000\n",
      "collected data (2217, 1, 64, 64)\n",
      "collected label (0,)\n",
      "torch.Size([2217, 1, 64, 64])\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# _Read Images to Array from Folder\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "path = \"/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/datasets/crop_640/1\"\n",
    "path = os.path.join(path,'')\n",
    "size = 64\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "\n",
    "for i,f in enumerate(os.listdir(path)):\n",
    "  ext = os.path.splitext(f)[1]\n",
    "  filename = os.path.splitext(f)[0]\n",
    "  if ext.lower() not in valid_images:\n",
    "      continue\n",
    "  img = np.array(Image.open(os.path.join(path,f)))\n",
    "  img = torch.from_numpy(img)\n",
    "  img = torch.nn.functional.interpolate(img.unsqueeze(0).unsqueeze(0), size=(size,size), mode='bilinear',antialias=True)\n",
    "  \n",
    "  imgs.append(img[0].numpy())\n",
    "\n",
    "  if i%500==0:\n",
    "    print(f'processing index {i}')\n",
    "\n",
    "img_data_x = np.array(imgs)\n",
    "img_data_y = np.array(labels)\n",
    "np.random.shuffle(img_data_x)\n",
    "print(f'collected data {img_data_x.shape}\\ncollected label {img_data_y.shape}')\n",
    "\n",
    "img_data_x = torch.from_numpy(img_data_x)\n",
    "\n",
    "img_data_x = 1-img_data_x/255.\n",
    "\n",
    "print(img_data_x.shape)\n",
    "print(img_data_x.max())\n",
    "print(img_data_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b485ee-9483-4fc5-b680-46b756674d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VAEDataset(data_train= img_data_x[:2000],\n",
    "                  data_val= img_data_x[2000:],\n",
    "                  train_batch_size= 64,\n",
    "                  val_batch_size= 64,\n",
    "                  patch_size= 64, \n",
    "                  num_workers= 4, \n",
    "                  pin_memory=1)\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1542c87-03c1-4631-b4d1-3f590323c287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef59dd-a669-49c7-9834-afcaedcd4dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71905b3-1135-4710-a434-68036d062e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ProgressBar\n",
    "\n",
    "class LitProgressBar(ProgressBar):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # don't forget this :)\n",
    "        self.enable = True\n",
    "\n",
    "    def disable(self):\n",
    "        self.enable = False\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)  # don't forget this :)\n",
    "        # percent = (batch_idx / self.total_train_batches) * 100\n",
    "        # sys.stdout.flush()\n",
    "        # sys.stdout.write(f'{percent:.01f} percent complete \\r')\n",
    "        pass\n",
    "\n",
    "bar = LitProgressBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7b6c29-f474-421c-bb87-8e196b48f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "runner = Trainer(logger=logger,\n",
    "                 callbacks=[\n",
    "                     # LearningRateMonitor(),\n",
    "                     bar,\n",
    "                     ModelCheckpoint(save_top_k=2, \n",
    "                                     every_n_epochs = 16,\n",
    "                                     dirpath =os.path.join(logger.log_dir , \"checkpoints\"), \n",
    "                                     monitor= \"val_loss\",\n",
    "                                     save_last= True),\n",
    "                 ],\n",
    "                 # strategy=DDPPlugin(find_unused_parameters=False),\n",
    "                 # strategy=\"ddp_notebook\", \n",
    "                 log_every_n_steps = 16,\n",
    "                 accelerator=\"gpu\", \n",
    "                 devices=1,\n",
    "                 **config['trainer_params'])\n",
    "\n",
    "\n",
    "Path(f\"{logger.log_dir}/Samples\").mkdir(exist_ok=True, parents=True)\n",
    "Path(f\"{logger.log_dir}/Reconstructions\").mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156239a9-f96b-400b-8182-fb701642c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3966d7a8-7344-405a-a813-1015f13c9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory logs/DFCVAE/version_2 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | DFCVAE | 147 M \n",
      "---------------------------------\n",
      "3.3 M     Trainable params\n",
      "143 M     Non-trainable params\n",
      "147 M     Total params\n",
      "588.099   Total estimated model params size (MB)\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "runner.fit(experiment, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3567554a-45f8-46a2-84ff-e3ab720f938d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (decoder_input): Linear(in_features=128, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9face131-77b4-4e9e-8a66-5c57d9e515c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7946084e-6f92-485b-828c-f41596195e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99094acc-ef72-42aa-9ea9-45baabc555f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/BetaVAE/my_exp_name/version_0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ee5a71-7720-41c5-976a-489faf708623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4918c466-64c3-4ef6-a912-b7790e99497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "%cd PyTorchVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9da3f3ec-812d-4ba5-917f-eb325d6edb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiirdrpt1eKzxR4iX70rkIi/VjxVgQaVZ/wCvuJL2Qf8ALO3+RPxdhk/gv40o1mZGC2FrbWmTgGKPc/8A302Wz9CKXX3zfRxyFWuooglzIoA3yZJOcdSMhSe+3NZVFWbOwuL+UpAmQo3O7HaqD1YngCrZfTdP4iX+0LgfxuCsKn2Xq344Hsap3d9c3zA3EzOF4VeiqPQKOAPpVetTTMWVtLqrDLxt5dsD/wA9SM7v+Ajn6lazCSSSTknqTSVbsbe3l8yW7n8qCLBKrgu5PQKP69B+QL7zU3uYhbQxi3s0OVgQ8E/3mP8AE3ufwxVGiitPV/8AR0tdOHH2ePdIP+mj/M35Dav/AAGsyiiiiir+jQxzanG0y7oYQ00g9VQFiPxxj8aqTzSXNxJPK26SRi7H1JOTUdFFFFFaWnnZpWqSL/rPLSP6KXGT+gH41m0UUUUUVqaMjXAvrRBukntiI17sysrAD3+U1mOjRuyOpVlOCCMEGkooooooo60UV//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACpUlEQVR4AWNgGAUjMAQYGdE8jc5Hk0blsktoqLPuvPofWZRoA5gElLVlf966zuJ/dfM/JBNYkNh4mDw6lgJPr2x995eB4Vnx3i9IKokxgFnOQv353tvfIdq4vvxC0s9A2AB+fVOWs7vewT1ud5YUA1gVzeXvb3zwB2GnrOoWBAfIwusCHmOTX2c2fEbWwOy3B4WPzwAhS737K58hhzjQJH3208jm4XGBmL3KlVlvURUzMHB7rviNKoYjHYg6Kp86hepWsL4AzhXw0EQ1CIUnElLtxoMiAuXI1fGjC2NxgbCD5tkjWGxnYGDNOnES3QCMWBB01D4/+SO6Mgjf7O9Z7BIIUWarhgABBBeVxVUrgyoA4qG6QCiUZ/ZTTEVQEc2XWOSQDWAyCji+5ydO/Yxmx7HEAJIB3EEK8+/i1M7AICJ8E4sswgD5mId9X7GogAsZ3ITmR7gIiAEzgNnGefNZtGSLopCBxXAVqgCEBzWAL4Rn6kts8ggxuX+PERwEC2KAbPSlPSi5HKEAzjI7ByyOcACVOn0sKRJVMVetEKoAlAdyAYfn2qtYJZEFNV++R+aisBk5UbhYOYyZBljFGZiAwv+xRQ+acmGsiQCoCGQAMcDwBg5biDSAxQCtJINbSqQBcv+ewLWgMog0QO8yrkRAnAFMKjdQ7UXwiDNAkP0FQgsqizgDlJ/gTOjEGaCB0wfEpQM2WdwFDVEuEP/1DtXjSDyiDFC7i7uoIcoAmYdIVqIxiTLgM57sSpQBb4XQrEXiEmXAO2EkHWhM4gwQwF3iEWXAZw5WNHsRXKIM+P6fC6EDjUWUAb+/86FpQ3CJMoDhvSBCBxqLOAPe4o4G4gx4bSIPrQPR7GdgwB0/yEq57I1ur8bSOEBWQ4DNijsYCegclR4KIQAArniLvm7cw5cAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = np.array(Image.open('./datasets/crop_640/1/00011_614a_416c.png'))\n",
    "img = np.array(Image.open('../../datasets/3.png').convert(\"RGB\"))[:,:,0]\n",
    "img = torch.from_numpy(img).to(device)\n",
    "# img = 1-img.unsqueeze(0).unsqueeze(0)/255.\n",
    "img = img.unsqueeze(0).unsqueeze(0)/255.\n",
    "\n",
    "\n",
    "\n",
    "img = torch.nn.functional.interpolate(img, size=(64,64), mode='bilinear',antialias=True)\n",
    "\n",
    "# blur = GaussianBlur(3, sigma=1)\n",
    "# img = blur(img)\n",
    "\n",
    "print(img.shape)\n",
    "to_pil_image(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50224623-9a7b-4608-9b2b-c57481dd06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e094e349-9c90-490f-9f37-9c2abad1046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, log_var = trained_model.encode(img.to(device))\n",
    "z = trained_model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21a2c686-335c-4048-a1e9-3b3ec81589db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5161, -0.3246,  1.7510, -1.1232,  2.1553, -0.9393, -0.9148,  0.8923,\n",
       "         -1.3707,  0.5278, -0.8792,  0.6021, -0.6998, -0.8677,  1.4106, -2.9050,\n",
       "         -0.3442,  0.6099,  0.0412, -0.0357,  0.0749, -0.4612, -2.3958,  1.1111,\n",
       "         -0.0031,  1.8033,  0.7100,  1.2481,  0.2133,  1.0154,  1.6087,  1.2706]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c072e356-6510-476f-bcee-29b9c0353dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAKKKKKKXBB5pKKKKsQWU9wNyIdo6seAPxNWRb2FvzPO0zf3YRgfmf6U6Ga2a5jWKBvmYAbmz6dqqXpBvJNpyAcD8Kr0VJFDJM+2NCx9qvLFZ2Qzcfv5u0aHCj6nvVe6v5rk4ZtqdkXhRVWtC0xa2z3TffOViHvxzVAnJyetJVqJLZBunZn/wBhO/40sl85UxxARRn+FOKqZopQMkCrmosFkSBT8sagfjgZqlRRRRRVrTo/Nv4Vxn5s4+lQzuXndicktUdFFFFFaGkA+fLIPvRxMw+oxWfRRRRRRWlpJ/4+lBwzQkL+YNZvSiiiiiipre4e2kLoeSMYqGiiv//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][0], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da3a775-6dbc-4927-ada9-8fc33f5c914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img_data_x[2100:2110].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84c40296-afe5-469d-a334-1ed82499ac45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAe9SRxM0qp0ZjgA1KLdkmVGPzscKP6/SpktBG4WZyHc4Qf1yeMfjThZCCVRPJjccKcHH1yeMfjTzp3kzIs0uBIcIx6fXJ4I/Gop9MuLaZEl43/AHGPQ+4PQj3zVOSJ4n2OCG960LPTyLq3M44lb5Bjr0554xz1qeOE2+oo0uXeQkR46AcYbJ4x7+lPt7f7PcrJMvmSykiEH8MNzxj39KekEdtIHn3STSn936KOMMSeMe9NjjgtZF+0M8pc/LzwOmDkjGPxq3C9pYyJHcNJOkjYU7uF6YPI2ke9TxXVrZTJDO0k1vK5C7myE6c9NpHuKpX9nFDlGZpIHLeS27JXGO/Qg+vsa2bOGDTWtmuNz/aT+57CMELgnPy7cZ5zT7axttOvbdrgvMLhyIfROmCSRt247596l+zWul3ELzFp3uGPkE/dQcYOT8u3Hf8AGspvIsrlWnLzPM37sn7qjjB5GMY7/jWaHS1uQs26USN8jZ4HTB54IpkDrFOIZSZI3b5GzwMYwfQim2zC2u1glUyKz4Tnp0weeMVYDfZ45beUlkdiY+fu4AwfTBrftb+005rdJw83m4KKThY+FxnPy4x3/GpbPUrXT7qFZy83nSHywzfKnTBOfl247/jTGvraylRZ2klWaQ+XlvlToAeflK47/jWMJYLSYLO0kiSMdhzwvTByRtIx71UZIraVY5mZo3Y+W2eF6c56EfjUUMYtLlEmBdXJ8th0HTByeCKmtoVt71XmBd5GxEo7dMNzxj39Ko3E4SaUMdxZu3YADFaiPDE8c0uZAyjYvZMAdzxjj1qkmpR20u4Dz2znLHIHTpmpbLUYfMEUxLozZUk/cPHPPUVC7fZJzFMGdCflOenTBHYim28yxuIJd8iE8c9OnPpitK0ijtJES4DzAt+7APC9MHJG3H41TubqC0d/LfzpiSNw6IMDGM/zrFzz60u9sYycfWm0AkEEdatRXrJH5bosi9g3b6VEtw6NleP1oFzMucSNz71FnNFFFFFFFFFFFFFJS0UV/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7c304e1-487c-420c-95ec-85161b4df5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+p7WzuL12S3jLlV3NyAFHqSeB1qz/AGNdj7z2i/713EP/AGakj0a+m1VNNjh33L4KhGDAgjcGyOMYOc1qroWlWcrQahq8Ml2SFWG3LBVJ/vyFSB9MfUioYdOs5r1rN9PvreT503tOGCuFJAPyDPI9axlt52jWRYZCjNtVgpwT6A+tRdDg10eiXV9qepJaxQWq2vWeNbVSuzvnAyT2HOckYNQa68NjLNpdlEYovNLzZOSWz8qZ7qo4z3OT6Vnabp82qahDZw/fkPUjIUDkk/QAmuv1aUWun6dYaI7LdzQPDeXRYBnjQ4AyDhVHIOP7vU4rHt7dI4vMtLW28hDtbUb4Eqzd9ing/TDGuuttRng0lrpZZL3VbbZGr3J2QRRuGIaSPpgbfl3c8jjoKyf+Eh855l0a5eK+EZaQsuYZlVSxSJT/AKscHAxz6jpVR2tPEmkebLHFa6m9ykMLtnbKcEkbuvdfvZ69RXWeHfENtBa6hpukWttbBYxJLdW0rINxOwL5h5OAxbd03DpgZqGLRdT1KLULXXtR06809YJGtrrzY2m3hdyMpXLHOOR05PtWUPD8nhjSSVmvP7R1GMx74rJm8iLPIznIZjx6gAjvVy78J6nDpGji2fTlg+zBp2u5DFuzI7AOGAwoyDjv3zxWdPpotJhd3Vy2uXgQeUumgPDAPTPQEdgFIFY/iO7njtLOw+zfZEeMXM8QBy8jFipctyxCkdfU9Kh8K2E8+rRXuVis7RvNuJn+6EUbmUepKg8U+wvYbnxHo9raQmGyivUMaOdzMWdcsx9TgdOBitfQdNGv2j6NBDNa6WZ0d9SZRjcMjL5653cKDke/Nbt5e6FDLbyR6ln7Uq2lkUhOyCAEKX2tj5iVHzEnoeOBXIarrpGrTLaacsEqHyVNwTK6hflAwflzx6dc81Pr+qRaney6dqN1Mhs5WjgmA3oAFVCCo6DKZyPU8VkJoGoSXEKW0f2lJXCJNbfOpJPtyD7HBrqmtL5tVupdWZ49HL+Ultcy7DLGPlUqGPGAAdwH0B6Vj+KL8Wl1No1iQlrD8jFRgsODtx2weo5JI5J4xmaQBYTRavNxHbShok7yyKchR7DjJ/qa6e0utW1Swm1bVbhLLTEQw2wwI4wzfK3lp1YhS3TPJFcfqV79uvWlVPLhUBIY/wC4g4Ufl+ua0WurG8ltdQuLtoruMKJkEJcyMvRuoHIAzz1B9al1tNJtNXuGWC8uFlbzkZ5BGpVxuHQEngjvTtB1r7Nrdp9k02CMGVQ3lo0j4z1G4nJHXp2q5/ZeoWWr3N1en7XqNuSI41wyxuOFZ2+6qjqBnsOAKxGtLKBzJqGoedKTlorX94Sfdz8o+o3VUvbxryYMVEcaDbFEvRF9B/j3NLfajd6lMJbuZpGUbVB4VF9FA4A9hVWirkWr6jBGscV9crGowEEh2gfSnvrWovE8ZunCuMMVAUsPQkcke1Q3OoXl4iJc3U0qRgKiu5IUAYGBVaiiiiiiiiiiiiiiiiiv/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[1][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed3924f-40c2-414b-9076-3eb7f8cb4e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAKKKKKKKKKKSiiilooooopKWiipJbeSLBdCAehI61HRRRRRRWrpl2h/wBFuSDC5x8x+6eOee1Je6ctvcGMlkJ+6H/Dv0I561SltJoWCyLtJ6Z7/Q1EUKtgjB96lFnIQpyoDdMnFH2SQMAwC56EnA/PpU/9lzYXLoCxwu44z9D0P51BLZzQPslUoe2e9QqxVgQeRyK3bHUbe6gWzvR8pPyPuACHj14x/Kq13bvZyeVKZDGfuhu30PQj6VnNwcHP403cR3P50u44+8fzqSKZ1+TJZSfuk8VbnYxWwSQli5ymT0Ax+hrNoBIq5b6pdWy7UcMn92Qbh+Rqb+0YJAPOskb12sRTTPpx/wCXaX/vuk+0WAIItHP1ekOogHMdtCrepGf51UkmeVy7sWY9zTKKKKKKKK//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][5], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6323df68-1e08-4bde-9208-901766884505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7651, -0.3429,  0.2855,  ...,  2.7808, -0.6138, -0.6194],\n",
       "        [ 0.7270,  0.2237, -0.3485,  ...,  0.3516, -0.2341, -0.3200],\n",
       "        [-0.1425,  0.0745,  0.0337,  ..., -1.3222,  0.2490, -0.1188],\n",
       "        ...,\n",
       "        [-1.0782,  0.2654,  0.0919,  ..., -1.7245, -1.7932, -0.3616],\n",
       "        [ 0.2611, -0.1742,  0.1069,  ...,  0.2260, -1.2800, -0.2895],\n",
       "        [ 1.0433,  0.1376,  0.0130,  ...,  1.9821, -1.2415, -0.2458]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14725a8f-0d6d-4fe4-90ae-84384797e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 ms, sys: 771 µs, total: 3.76 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu, log_var = model.encode(img_data_x[2100:2110].to(device))\n",
    "z = model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d75b2f0-14e5-4c6c-9b0f-c1b1cf13d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.039333"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.linalg.norm(z[1]-z[5])\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb0fa3e2-fd66-45ea-9f68-61029bf560aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = vae_models[config['model_params']['name']](**config['model_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3af0a7a3-7b24-40f9-8fc4-312a6cacefd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DFCVAE', 'in_channels': 1, 'latent_dim': 32}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "319ac148-a0de-4f75-babe-d34d3479245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dfe6f28-d15f-4852-9b26-5d478e3d0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorch-VAE/logs/DFCVAE/version_2/checkpoints/last.ckpt'\n",
    "checkpoint = torch.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e8519a59-cc41-4f31-82e9-45f3d91bed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9dd9d4c1-37af-4178-9b32-51577cec0fad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.0.1.weight', 'model.encoder.0.1.bias', 'model.encoder.0.1.running_mean', 'model.encoder.0.1.running_var', 'model.encoder.0.1.num_batches_tracked', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.1.1.weight', 'model.encoder.1.1.bias', 'model.encoder.1.1.running_mean', 'model.encoder.1.1.running_var', 'model.encoder.1.1.num_batches_tracked', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.2.1.weight', 'model.encoder.2.1.bias', 'model.encoder.2.1.running_mean', 'model.encoder.2.1.running_var', 'model.encoder.2.1.num_batches_tracked', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.3.1.weight', 'model.encoder.3.1.bias', 'model.encoder.3.1.running_mean', 'model.encoder.3.1.running_var', 'model.encoder.3.1.num_batches_tracked', 'model.encoder.4.0.weight', 'model.encoder.4.0.bias', 'model.encoder.4.1.weight', 'model.encoder.4.1.bias', 'model.encoder.4.1.running_mean', 'model.encoder.4.1.running_var', 'model.encoder.4.1.num_batches_tracked', 'model.fc_mu.weight', 'model.fc_mu.bias', 'model.fc_var.weight', 'model.fc_var.bias', 'model.decoder_input.weight', 'model.decoder_input.bias', 'model.decoder.0.0.weight', 'model.decoder.0.0.bias', 'model.decoder.0.1.weight', 'model.decoder.0.1.bias', 'model.decoder.0.1.running_mean', 'model.decoder.0.1.running_var', 'model.decoder.0.1.num_batches_tracked', 'model.decoder.1.0.weight', 'model.decoder.1.0.bias', 'model.decoder.1.1.weight', 'model.decoder.1.1.bias', 'model.decoder.1.1.running_mean', 'model.decoder.1.1.running_var', 'model.decoder.1.1.num_batches_tracked', 'model.decoder.2.0.weight', 'model.decoder.2.0.bias', 'model.decoder.2.1.weight', 'model.decoder.2.1.bias', 'model.decoder.2.1.running_mean', 'model.decoder.2.1.running_var', 'model.decoder.2.1.num_batches_tracked', 'model.decoder.3.0.weight', 'model.decoder.3.0.bias', 'model.decoder.3.1.weight', 'model.decoder.3.1.bias', 'model.decoder.3.1.running_mean', 'model.decoder.3.1.running_var', 'model.decoder.3.1.num_batches_tracked', 'model.final_layer.0.weight', 'model.final_layer.0.bias', 'model.final_layer.1.weight', 'model.final_layer.1.bias', 'model.final_layer.1.running_mean', 'model.final_layer.1.running_var', 'model.final_layer.1.num_batches_tracked', 'model.final_layer.3.weight', 'model.final_layer.3.bias', 'model.feature_network.features.0.weight', 'model.feature_network.features.0.bias', 'model.feature_network.features.1.weight', 'model.feature_network.features.1.bias', 'model.feature_network.features.1.running_mean', 'model.feature_network.features.1.running_var', 'model.feature_network.features.1.num_batches_tracked', 'model.feature_network.features.3.weight', 'model.feature_network.features.3.bias', 'model.feature_network.features.4.weight', 'model.feature_network.features.4.bias', 'model.feature_network.features.4.running_mean', 'model.feature_network.features.4.running_var', 'model.feature_network.features.4.num_batches_tracked', 'model.feature_network.features.7.weight', 'model.feature_network.features.7.bias', 'model.feature_network.features.8.weight', 'model.feature_network.features.8.bias', 'model.feature_network.features.8.running_mean', 'model.feature_network.features.8.running_var', 'model.feature_network.features.8.num_batches_tracked', 'model.feature_network.features.10.weight', 'model.feature_network.features.10.bias', 'model.feature_network.features.11.weight', 'model.feature_network.features.11.bias', 'model.feature_network.features.11.running_mean', 'model.feature_network.features.11.running_var', 'model.feature_network.features.11.num_batches_tracked', 'model.feature_network.features.14.weight', 'model.feature_network.features.14.bias', 'model.feature_network.features.15.weight', 'model.feature_network.features.15.bias', 'model.feature_network.features.15.running_mean', 'model.feature_network.features.15.running_var', 'model.feature_network.features.15.num_batches_tracked', 'model.feature_network.features.17.weight', 'model.feature_network.features.17.bias', 'model.feature_network.features.18.weight', 'model.feature_network.features.18.bias', 'model.feature_network.features.18.running_mean', 'model.feature_network.features.18.running_var', 'model.feature_network.features.18.num_batches_tracked', 'model.feature_network.features.20.weight', 'model.feature_network.features.20.bias', 'model.feature_network.features.21.weight', 'model.feature_network.features.21.bias', 'model.feature_network.features.21.running_mean', 'model.feature_network.features.21.running_var', 'model.feature_network.features.21.num_batches_tracked', 'model.feature_network.features.23.weight', 'model.feature_network.features.23.bias', 'model.feature_network.features.24.weight', 'model.feature_network.features.24.bias', 'model.feature_network.features.24.running_mean', 'model.feature_network.features.24.running_var', 'model.feature_network.features.24.num_batches_tracked', 'model.feature_network.features.27.weight', 'model.feature_network.features.27.bias', 'model.feature_network.features.28.weight', 'model.feature_network.features.28.bias', 'model.feature_network.features.28.running_mean', 'model.feature_network.features.28.running_var', 'model.feature_network.features.28.num_batches_tracked', 'model.feature_network.features.30.weight', 'model.feature_network.features.30.bias', 'model.feature_network.features.31.weight', 'model.feature_network.features.31.bias', 'model.feature_network.features.31.running_mean', 'model.feature_network.features.31.running_var', 'model.feature_network.features.31.num_batches_tracked', 'model.feature_network.features.33.weight', 'model.feature_network.features.33.bias', 'model.feature_network.features.34.weight', 'model.feature_network.features.34.bias', 'model.feature_network.features.34.running_mean', 'model.feature_network.features.34.running_var', 'model.feature_network.features.34.num_batches_tracked', 'model.feature_network.features.36.weight', 'model.feature_network.features.36.bias', 'model.feature_network.features.37.weight', 'model.feature_network.features.37.bias', 'model.feature_network.features.37.running_mean', 'model.feature_network.features.37.running_var', 'model.feature_network.features.37.num_batches_tracked', 'model.feature_network.features.40.weight', 'model.feature_network.features.40.bias', 'model.feature_network.features.41.weight', 'model.feature_network.features.41.bias', 'model.feature_network.features.41.running_mean', 'model.feature_network.features.41.running_var', 'model.feature_network.features.41.num_batches_tracked', 'model.feature_network.features.43.weight', 'model.feature_network.features.43.bias', 'model.feature_network.features.44.weight', 'model.feature_network.features.44.bias', 'model.feature_network.features.44.running_mean', 'model.feature_network.features.44.running_var', 'model.feature_network.features.44.num_batches_tracked', 'model.feature_network.features.46.weight', 'model.feature_network.features.46.bias', 'model.feature_network.features.47.weight', 'model.feature_network.features.47.bias', 'model.feature_network.features.47.running_mean', 'model.feature_network.features.47.running_var', 'model.feature_network.features.47.num_batches_tracked', 'model.feature_network.features.49.weight', 'model.feature_network.features.49.bias', 'model.feature_network.features.50.weight', 'model.feature_network.features.50.bias', 'model.feature_network.features.50.running_mean', 'model.feature_network.features.50.running_var', 'model.feature_network.features.50.num_batches_tracked', 'model.feature_network.classifier.0.weight', 'model.feature_network.classifier.0.bias', 'model.feature_network.classifier.3.weight', 'model.feature_network.classifier.3.bias', 'model.feature_network.classifier.6.weight', 'model.feature_network.classifier.6.bias'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee2e3d71-94b9-4cb6-b101-0f2ea0d0a5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoder.0.0.weight'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'model.encoder.0.0.weight'\n",
    "a = a.split('model.')\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa0042cf-c495-4653-bdbf-0016526191e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.0.0.weight\n",
      "model.encoder.0.0.bias\n",
      "model.encoder.0.1.weight\n",
      "model.encoder.0.1.bias\n",
      "model.encoder.0.1.running_mean\n",
      "model.encoder.0.1.running_var\n",
      "model.encoder.0.1.num_batches_tracked\n",
      "model.encoder.1.0.weight\n",
      "model.encoder.1.0.bias\n",
      "model.encoder.1.1.weight\n",
      "model.encoder.1.1.bias\n",
      "model.encoder.1.1.running_mean\n",
      "model.encoder.1.1.running_var\n",
      "model.encoder.1.1.num_batches_tracked\n",
      "model.encoder.2.0.weight\n",
      "model.encoder.2.0.bias\n",
      "model.encoder.2.1.weight\n",
      "model.encoder.2.1.bias\n",
      "model.encoder.2.1.running_mean\n",
      "model.encoder.2.1.running_var\n",
      "model.encoder.2.1.num_batches_tracked\n",
      "model.encoder.3.0.weight\n",
      "model.encoder.3.0.bias\n",
      "model.encoder.3.1.weight\n",
      "model.encoder.3.1.bias\n",
      "model.encoder.3.1.running_mean\n",
      "model.encoder.3.1.running_var\n",
      "model.encoder.3.1.num_batches_tracked\n",
      "model.encoder.4.0.weight\n",
      "model.encoder.4.0.bias\n",
      "model.encoder.4.1.weight\n",
      "model.encoder.4.1.bias\n",
      "model.encoder.4.1.running_mean\n",
      "model.encoder.4.1.running_var\n",
      "model.encoder.4.1.num_batches_tracked\n",
      "model.fc_mu.weight\n",
      "model.fc_mu.bias\n",
      "model.fc_var.weight\n",
      "model.fc_var.bias\n",
      "model.decoder_input.weight\n",
      "model.decoder_input.bias\n",
      "model.decoder.0.0.weight\n",
      "model.decoder.0.0.bias\n",
      "model.decoder.0.1.weight\n",
      "model.decoder.0.1.bias\n",
      "model.decoder.0.1.running_mean\n",
      "model.decoder.0.1.running_var\n",
      "model.decoder.0.1.num_batches_tracked\n",
      "model.decoder.1.0.weight\n",
      "model.decoder.1.0.bias\n",
      "model.decoder.1.1.weight\n",
      "model.decoder.1.1.bias\n",
      "model.decoder.1.1.running_mean\n",
      "model.decoder.1.1.running_var\n",
      "model.decoder.1.1.num_batches_tracked\n",
      "model.decoder.2.0.weight\n",
      "model.decoder.2.0.bias\n",
      "model.decoder.2.1.weight\n",
      "model.decoder.2.1.bias\n",
      "model.decoder.2.1.running_mean\n",
      "model.decoder.2.1.running_var\n",
      "model.decoder.2.1.num_batches_tracked\n",
      "model.decoder.3.0.weight\n",
      "model.decoder.3.0.bias\n",
      "model.decoder.3.1.weight\n",
      "model.decoder.3.1.bias\n",
      "model.decoder.3.1.running_mean\n",
      "model.decoder.3.1.running_var\n",
      "model.decoder.3.1.num_batches_tracked\n",
      "model.final_layer.0.weight\n",
      "model.final_layer.0.bias\n",
      "model.final_layer.1.weight\n",
      "model.final_layer.1.bias\n",
      "model.final_layer.1.running_mean\n",
      "model.final_layer.1.running_var\n",
      "model.final_layer.1.num_batches_tracked\n",
      "model.final_layer.3.weight\n",
      "model.final_layer.3.bias\n",
      "model.feature_network.features.0.weight\n",
      "model.feature_network.features.0.bias\n",
      "model.feature_network.features.1.weight\n",
      "model.feature_network.features.1.bias\n",
      "model.feature_network.features.1.running_mean\n",
      "model.feature_network.features.1.running_var\n",
      "model.feature_network.features.1.num_batches_tracked\n",
      "model.feature_network.features.3.weight\n",
      "model.feature_network.features.3.bias\n",
      "model.feature_network.features.4.weight\n",
      "model.feature_network.features.4.bias\n",
      "model.feature_network.features.4.running_mean\n",
      "model.feature_network.features.4.running_var\n",
      "model.feature_network.features.4.num_batches_tracked\n",
      "model.feature_network.features.7.weight\n",
      "model.feature_network.features.7.bias\n",
      "model.feature_network.features.8.weight\n",
      "model.feature_network.features.8.bias\n",
      "model.feature_network.features.8.running_mean\n",
      "model.feature_network.features.8.running_var\n",
      "model.feature_network.features.8.num_batches_tracked\n",
      "model.feature_network.features.10.weight\n",
      "model.feature_network.features.10.bias\n",
      "model.feature_network.features.11.weight\n",
      "model.feature_network.features.11.bias\n",
      "model.feature_network.features.11.running_mean\n",
      "model.feature_network.features.11.running_var\n",
      "model.feature_network.features.11.num_batches_tracked\n",
      "model.feature_network.features.14.weight\n",
      "model.feature_network.features.14.bias\n",
      "model.feature_network.features.15.weight\n",
      "model.feature_network.features.15.bias\n",
      "model.feature_network.features.15.running_mean\n",
      "model.feature_network.features.15.running_var\n",
      "model.feature_network.features.15.num_batches_tracked\n",
      "model.feature_network.features.17.weight\n",
      "model.feature_network.features.17.bias\n",
      "model.feature_network.features.18.weight\n",
      "model.feature_network.features.18.bias\n",
      "model.feature_network.features.18.running_mean\n",
      "model.feature_network.features.18.running_var\n",
      "model.feature_network.features.18.num_batches_tracked\n",
      "model.feature_network.features.20.weight\n",
      "model.feature_network.features.20.bias\n",
      "model.feature_network.features.21.weight\n",
      "model.feature_network.features.21.bias\n",
      "model.feature_network.features.21.running_mean\n",
      "model.feature_network.features.21.running_var\n",
      "model.feature_network.features.21.num_batches_tracked\n",
      "model.feature_network.features.23.weight\n",
      "model.feature_network.features.23.bias\n",
      "model.feature_network.features.24.weight\n",
      "model.feature_network.features.24.bias\n",
      "model.feature_network.features.24.running_mean\n",
      "model.feature_network.features.24.running_var\n",
      "model.feature_network.features.24.num_batches_tracked\n",
      "model.feature_network.features.27.weight\n",
      "model.feature_network.features.27.bias\n",
      "model.feature_network.features.28.weight\n",
      "model.feature_network.features.28.bias\n",
      "model.feature_network.features.28.running_mean\n",
      "model.feature_network.features.28.running_var\n",
      "model.feature_network.features.28.num_batches_tracked\n",
      "model.feature_network.features.30.weight\n",
      "model.feature_network.features.30.bias\n",
      "model.feature_network.features.31.weight\n",
      "model.feature_network.features.31.bias\n",
      "model.feature_network.features.31.running_mean\n",
      "model.feature_network.features.31.running_var\n",
      "model.feature_network.features.31.num_batches_tracked\n",
      "model.feature_network.features.33.weight\n",
      "model.feature_network.features.33.bias\n",
      "model.feature_network.features.34.weight\n",
      "model.feature_network.features.34.bias\n",
      "model.feature_network.features.34.running_mean\n",
      "model.feature_network.features.34.running_var\n",
      "model.feature_network.features.34.num_batches_tracked\n",
      "model.feature_network.features.36.weight\n",
      "model.feature_network.features.36.bias\n",
      "model.feature_network.features.37.weight\n",
      "model.feature_network.features.37.bias\n",
      "model.feature_network.features.37.running_mean\n",
      "model.feature_network.features.37.running_var\n",
      "model.feature_network.features.37.num_batches_tracked\n",
      "model.feature_network.features.40.weight\n",
      "model.feature_network.features.40.bias\n",
      "model.feature_network.features.41.weight\n",
      "model.feature_network.features.41.bias\n",
      "model.feature_network.features.41.running_mean\n",
      "model.feature_network.features.41.running_var\n",
      "model.feature_network.features.41.num_batches_tracked\n",
      "model.feature_network.features.43.weight\n",
      "model.feature_network.features.43.bias\n",
      "model.feature_network.features.44.weight\n",
      "model.feature_network.features.44.bias\n",
      "model.feature_network.features.44.running_mean\n",
      "model.feature_network.features.44.running_var\n",
      "model.feature_network.features.44.num_batches_tracked\n",
      "model.feature_network.features.46.weight\n",
      "model.feature_network.features.46.bias\n",
      "model.feature_network.features.47.weight\n",
      "model.feature_network.features.47.bias\n",
      "model.feature_network.features.47.running_mean\n",
      "model.feature_network.features.47.running_var\n",
      "model.feature_network.features.47.num_batches_tracked\n",
      "model.feature_network.features.49.weight\n",
      "model.feature_network.features.49.bias\n",
      "model.feature_network.features.50.weight\n",
      "model.feature_network.features.50.bias\n",
      "model.feature_network.features.50.running_mean\n",
      "model.feature_network.features.50.running_var\n",
      "model.feature_network.features.50.num_batches_tracked\n",
      "model.feature_network.classifier.0.weight\n",
      "model.feature_network.classifier.0.bias\n",
      "model.feature_network.classifier.3.weight\n",
      "model.feature_network.classifier.3.bias\n",
      "model.feature_network.classifier.6.weight\n",
      "model.feature_network.classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "keys = list(checkpoint['state_dict'].items())\n",
    "for k in keys:\n",
    "    print(k[0])\n",
    "    checkpoint['state_dict'][k[0].split('model.')[1]] = checkpoint['state_dict'][k[0]]\n",
    "    del checkpoint['state_dict'][k[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47d0b5d0-fe01-42fe-a3b9-51971d334943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc161767-098e-47cc-a0b3-bd012123ac7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (decoder_input): Linear(in_features=32, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trained_model.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.to(device)\n",
    "# - or -\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b6d273c-c9e0-4851-bb19-fc2479b61192",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trained_model(img_data_x[2100:2110].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8583a5eb-b4c1-4a3c-a957-44c91bb6ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APBYYmkmRB1Y4FXlgjgfbIxaVzhADwOnJzxUkVvHA6iVi8shwg7DpgnPGKcsEdsQJ2LPKcR4/hHGDzxilS1itivnSlmkOEx0HTByRjFOFlFbsguJmYyn92QOB0wckYx+NOk0qO1dBNMxMp/dkDgehyRjHvmqFxYvayYlYkN91sHBHqD0Iq7a2wtJIXm+aSb/AFOOi9ME54xRDB9mu4zMA8kzfuieg6YbnjHvVi3t/ss8bzASTTMfJz0HTDc8Y96sQW8Nm6SXGZZ5mzEGHCjjDHIxj3NSQQ21m0T3DNNNM2YgfuqOME7hjGO9SRLZ2RjNwzTyzNmPJ+VRxg/MMYx3qBbi1s3Vbh5JjK2FO7hBxg8jBFU5Y44kaKV3ljkJMZ3ZAxjv0INbVvDbaeLbzyzyXJ/dcYEYwMHn5duO+fen29nBp11bm4ZpnuHPk/3U6YJyNu3Hf8a0oLK10xrdp9001058jP3YxwAST8u3Hf8AGqLi1sJ43uGeaa4f91n7qDjB5+XGO/41Uje2spUactPNO37rd91emDyMYx3/ABqgs8VtKFmLTSSsdhJ4Xpg88YqhG6Q3ASUGQu3ynP3emDzxipUXyI5I5cv5hJQemAMH05ro7W4tdMjgFwHmebBjUnCpwMZz8uMVPbahZ6dLGZ2kuJJmzGrHCoOME5+XGO/40Ra5a2UsazPJO00h2Et8sfQDr8uMd/xrNa+trab98zzSSufLy3yp0weflxjvWaLiK1mHmlpJJG+Q54Xpg88EVUGy3kzKS7ufkI6Dpg5PGKSFI7WQPN+8lc/ux6dMHJ4pXH2aNzPlpJeVHPAGMH8avrqFnaQrudp5CBtUnhMAevFY82oMzlgzM5P3mbOPpTtPukSYLKcgnhifunjn6VMQ9rMUkRmycqfT3B6Go4omR8OsjsemRjHvk8Vbt7L7K4affIx5RQOB75Py/rSbrWycyTSfaZ8/KB0X8TxWVNceY7McsW7k9KrZooBwc1Yiv7mEYjmYD0PIp51O8Ix5zVCbmZs5lc56/MaiyTRRRRRRRRRRRRRRRRRX/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[0][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55632a16-1a60-48b3-986d-c20318fe2ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+p7WzuL12S3jLlV3NyAFHqSeB1qz/AGNdj7z2i/713EP/AGakj0a+m1VNNjh33L4KhGDAgjcGyOMYOc1qroWlWcrQahq8Ml2SFWG3LBVJ/vyFSB9MfUioYdOs5r1rN9PvreT503tOGCuFJAPyDPI9axlt52jWRYZCjNtVgpwT6A+tRdDg10eiXV9qepJaxQWq2vWeNbVSuzvnAyT2HOckYNQa68NjLNpdlEYovNLzZOSWz8qZ7qo4z3OT6Vnabp82qahDZw/fkPUjIUDkk/QAmuv1aUWun6dYaI7LdzQPDeXRYBnjQ4AyDhVHIOP7vU4rHt7dI4vMtLW28hDtbUb4Eqzd9ing/TDGuuttRng0lrpZZL3VbbZGr3J2QRRuGIaSPpgbfl3c8jjoKyf+Eh855l0a5eK+EZaQsuYZlVSxSJT/AKscHAxz6jpVR2tPEmkebLHFa6m9ykMLtnbKcEkbuvdfvZ69RXWeHfENtBa6hpukWttbBYxJLdW0rINxOwL5h5OAxbd03DpgZqGLRdT1KLULXXtR06809YJGtrrzY2m3hdyMpXLHOOR05PtWUPD8nhjSSVmvP7R1GMx74rJm8iLPIznIZjx6gAjvVy78J6nDpGji2fTlg+zBp2u5DFuzI7AOGAwoyDjv3zxWdPpotJhd3Vy2uXgQeUumgPDAPTPQEdgFIFY/iO7njtLOw+zfZEeMXM8QBy8jFipctyxCkdfU9Kh8K2E8+rRXuVis7RvNuJn+6EUbmUepKg8U+wvYbnxHo9raQmGyivUMaOdzMWdcsx9TgdOBitfQdNGv2j6NBDNa6WZ0d9SZRjcMjL5653cKDke/Nbt5e6FDLbyR6ln7Uq2lkUhOyCAEKX2tj5iVHzEnoeOBXIarrpGrTLaacsEqHyVNwTK6hflAwflzx6dc81Pr+qRaney6dqN1Mhs5WjgmA3oAFVCCo6DKZyPU8VkJoGoSXEKW0f2lJXCJNbfOpJPtyD7HBrqmtL5tVupdWZ49HL+Ultcy7DLGPlUqGPGAAdwH0B6Vj+KL8Wl1No1iQlrD8jFRgsODtx2weo5JI5J4xmaQBYTRavNxHbShok7yyKchR7DjJ/qa6e0utW1Swm1bVbhLLTEQw2wwI4wzfK3lp1YhS3TPJFcfqV79uvWlVPLhUBIY/wC4g4Ufl+ua0WurG8ltdQuLtoruMKJkEJcyMvRuoHIAzz1B9al1tNJtNXuGWC8uFlbzkZ5BGpVxuHQEngjvTtB1r7Nrdp9k02CMGVQ3lo0j4z1G4nJHXp2q5/ZeoWWr3N1en7XqNuSI41wyxuOFZ2+6qjqBnsOAKxGtLKBzJqGoedKTlorX94Sfdz8o+o3VUvbxryYMVEcaDbFEvRF9B/j3NLfajd6lMJbuZpGUbVB4VF9FA4A9hVWirkWr6jBGscV9crGowEEh2gfSnvrWovE8ZunCuMMVAUsPQkcke1Q3OoXl4iJc3U0qRgKiu5IUAYGBVaiiiiiiiiiiiiiiiiiv/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.clamp(out[1][2], min=0, max=1)\n",
    "to_pil_image(o.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c20aed5c-8906-4156-bdc6-349c2c3e9c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 ms, sys: 12.9 ms, total: 16.4 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu, log_var = trained_model.encode(img_data_x[2100:2110].to(device))\n",
    "z = trained_model.reparameterize(mu, log_var).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6546cb5-eba8-4e82-8e25-05669c7cc780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "075c8d24-2223-4c0c-a4f1-89146a0e759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1256a393-291e-4798-8e3f-e42991fb5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyTorchVAE.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1b86d9f-d72e-43a7-9b79-447fc9f12fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PyTorchVAE/models' -> './models'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints' -> './models/.ipynb_checkpoints'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/vanilla_vae-checkpoint.py' -> './models/.ipynb_checkpoints/vanilla_vae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/base-checkpoint.py' -> './models/.ipynb_checkpoints/base-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/__init__-checkpoint.py' -> './models/.ipynb_checkpoints/__init__-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/beta_vae-checkpoint.py' -> './models/.ipynb_checkpoints/beta_vae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/dfcvae-checkpoint.py' -> './models/.ipynb_checkpoints/dfcvae-checkpoint.py'\n",
      "'PyTorchVAE/models/.ipynb_checkpoints/dfcvae_app-checkpoint.py' -> './models/.ipynb_checkpoints/dfcvae_app-checkpoint.py'\n",
      "'PyTorchVAE/models/dfcvae_app.py' -> './models/dfcvae_app.py'\n",
      "'PyTorchVAE/models/__init__.py' -> './models/__init__.py'\n",
      "'PyTorchVAE/models/base.py' -> './models/base.py'\n",
      "'PyTorchVAE/models/beta_vae.py' -> './models/beta_vae.py'\n",
      "'PyTorchVAE/models/betatc_vae.py' -> './models/betatc_vae.py'\n",
      "'PyTorchVAE/models/cat_vae.py' -> './models/cat_vae.py'\n",
      "'PyTorchVAE/models/cvae.py' -> './models/cvae.py'\n",
      "'PyTorchVAE/models/dfcvae.py' -> './models/dfcvae.py'\n",
      "'PyTorchVAE/models/dip_vae.py' -> './models/dip_vae.py'\n",
      "'PyTorchVAE/models/fvae.py' -> './models/fvae.py'\n",
      "'PyTorchVAE/models/gamma_vae.py' -> './models/gamma_vae.py'\n",
      "'PyTorchVAE/models/hvae.py' -> './models/hvae.py'\n",
      "'PyTorchVAE/models/info_vae.py' -> './models/info_vae.py'\n",
      "'PyTorchVAE/models/iwae.py' -> './models/iwae.py'\n",
      "'PyTorchVAE/models/joint_vae.py' -> './models/joint_vae.py'\n",
      "'PyTorchVAE/models/logcosh_vae.py' -> './models/logcosh_vae.py'\n",
      "'PyTorchVAE/models/lvae.py' -> './models/lvae.py'\n",
      "'PyTorchVAE/models/miwae.py' -> './models/miwae.py'\n",
      "'PyTorchVAE/models/mssim_vae.py' -> './models/mssim_vae.py'\n",
      "'PyTorchVAE/models/swae.py' -> './models/swae.py'\n",
      "'PyTorchVAE/models/twostage_vae.py' -> './models/twostage_vae.py'\n",
      "'PyTorchVAE/models/types_.py' -> './models/types_.py'\n",
      "'PyTorchVAE/models/vampvae.py' -> './models/vampvae.py'\n",
      "'PyTorchVAE/models/vanilla_vae.py' -> './models/vanilla_vae.py'\n",
      "'PyTorchVAE/models/vq_vae.py' -> './models/vq_vae.py'\n",
      "'PyTorchVAE/models/wae_mmd.py' -> './models/wae_mmd.py'\n",
      "'PyTorchVAE/models/__pycache__' -> './models/__pycache__'\n",
      "'PyTorchVAE/models/__pycache__/__init__.cpython-310.pyc' -> './models/__pycache__/__init__.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/base.cpython-310.pyc' -> './models/__pycache__/base.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/types_.cpython-310.pyc' -> './models/__pycache__/types_.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/dfcvae.cpython-310.pyc' -> './models/__pycache__/dfcvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/gamma_vae.cpython-310.pyc' -> './models/__pycache__/gamma_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/wae_mmd.cpython-310.pyc' -> './models/__pycache__/wae_mmd.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/cvae.cpython-310.pyc' -> './models/__pycache__/cvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/hvae.cpython-310.pyc' -> './models/__pycache__/hvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vampvae.cpython-310.pyc' -> './models/__pycache__/vampvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/iwae.cpython-310.pyc' -> './models/__pycache__/iwae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/mssim_vae.cpython-310.pyc' -> './models/__pycache__/mssim_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/fvae.cpython-310.pyc' -> './models/__pycache__/fvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/cat_vae.cpython-310.pyc' -> './models/__pycache__/cat_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/joint_vae.cpython-310.pyc' -> './models/__pycache__/joint_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/info_vae.cpython-310.pyc' -> './models/__pycache__/info_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/lvae.cpython-310.pyc' -> './models/__pycache__/lvae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/logcosh_vae.cpython-310.pyc' -> './models/__pycache__/logcosh_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/swae.cpython-310.pyc' -> './models/__pycache__/swae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/miwae.cpython-310.pyc' -> './models/__pycache__/miwae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vq_vae.cpython-310.pyc' -> './models/__pycache__/vq_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/betatc_vae.cpython-310.pyc' -> './models/__pycache__/betatc_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/dip_vae.cpython-310.pyc' -> './models/__pycache__/dip_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/vanilla_vae.cpython-310.pyc' -> './models/__pycache__/vanilla_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/__pycache__/beta_vae.cpython-310.pyc' -> './models/__pycache__/beta_vae.cpython-310.pyc'\n",
      "'PyTorchVAE/models/dfcvae-Copy1.py' -> './models/dfcvae-Copy1.py'\n"
     ]
    }
   ],
   "source": [
    "!cp -av PyTorchVAE/models ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0fdda-83e6-41f7-8dbf-778ff7b4acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
