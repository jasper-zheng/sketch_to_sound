{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa3bb88-e7a7-44ac-a117-9851c7bc2af5",
   "metadata": {},
   "source": [
    "# Shape-To: Explore Visual Sketches as Musical Controller\n",
    "\n",
    "Training notebook for the deep feature consistent variational autoencoder (DFC VAE)  \n",
    "\n",
    "The codebase uses [PyTorch-VAE](https://github.com/AntixK/PyTorch-VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94468b07-186d-4b54-9fd0-a4bcbdf3140b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning==2.1.2\n",
    "!pip install --upgrade torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc11c40-0ee1-4cba-8875-f7e48e985a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PyTorch-VAE'...\n",
      "remote: Enumerating objects: 859, done.\u001b[K\n",
      "remote: Total 859 (delta 0), reused 0 (delta 0), pack-reused 859\u001b[K\n",
      "Receiving objects: 100% (859/859), 46.47 MiB | 531.00 KiB/s, done.\n",
      "Resolving deltas: 100% (619/619), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AntixK/PyTorch-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7380916-61f0-4b9f-8f8a-95a22584b2bc",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc9b7d8-1b20-4295-9efe-cbeea04d0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/web_app/PyTorchVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa73ea2e-0b41-48b1-91d7-e1360840362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/src/PyTorchVAE\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from models import *\n",
    "from experiment import VAEXperiment\n",
    "import torch.backends.cudnn as cudnn\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "# from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from dataset import VAEDataset\n",
    "# from pytorch_lightning.plugins import DDPPlugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e98a824-50be-4dc0-998a-52ebb07dff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# config_file = './configs/bhvae.yaml'\n",
    "config_file = './configs/dfc_vae.yaml'\n",
    "\n",
    "with open(config_file, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "# tb_logger =  TensorBoardLogger(save_dir=config['logging_params']['save_dir'],\n",
    "#                                name=config['model_params']['name'],)\n",
    "logger = CSVLogger(save_dir=config['logging_params']['save_dir'], name=config['model_params']['name'])\n",
    "# seed_everything(config['exp_params']['manual_seed'], True)\n",
    "\n",
    "model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "experiment = VAEXperiment(model,\n",
    "                          config['exp_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb41854a-e173-40b9-bd98-dec94b2a4d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DFCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (decoder_input): Linear(in_features=32, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       "  (feature_network): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d2cfc5-a849-4efb-8e28-50393e78bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing index 0\n",
      "processing index 500\n",
      "processing index 1000\n",
      "processing index 1500\n",
      "processing index 2000\n",
      "collected data (2217, 1, 64, 64)\n",
      "collected label (0,)\n",
      "torch.Size([2217, 1, 64, 64])\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "\n",
    "path = \"/home/jasper/Documents/PhD/Y0/vae_sketch_to_sound/datasets/crop_640/1\"\n",
    "path = os.path.join(path,'')\n",
    "size = 64\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "\n",
    "for i,f in enumerate(os.listdir(path)):\n",
    "  ext = os.path.splitext(f)[1]\n",
    "  filename = os.path.splitext(f)[0]\n",
    "  if ext.lower() not in valid_images:\n",
    "      continue\n",
    "  img = np.array(Image.open(os.path.join(path,f)))\n",
    "  img = torch.from_numpy(img)\n",
    "  img = torch.nn.functional.interpolate(img.unsqueeze(0).unsqueeze(0), size=(size,size), mode='bilinear',antialias=True)\n",
    "  \n",
    "  imgs.append(img[0].numpy())\n",
    "\n",
    "  if i%500==0:\n",
    "    print(f'processing index {i}')\n",
    "\n",
    "img_data_x = np.array(imgs)\n",
    "img_data_y = np.array(labels)\n",
    "np.random.shuffle(img_data_x)\n",
    "print(f'collected data {img_data_x.shape}\\ncollected label {img_data_y.shape}')\n",
    "\n",
    "img_data_x = torch.from_numpy(img_data_x)\n",
    "\n",
    "img_data_x = 1-img_data_x/255.\n",
    "\n",
    "print(img_data_x.shape)\n",
    "print(img_data_x.max())\n",
    "print(img_data_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b485ee-9483-4fc5-b680-46b756674d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VAEDataset(data_train= img_data_x[:2000],\n",
    "                  data_val= img_data_x[2000:],\n",
    "                  train_batch_size= 64,\n",
    "                  val_batch_size= 64,\n",
    "                  patch_size= 64, \n",
    "                  num_workers= 4, \n",
    "                  pin_memory=1)\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71905b3-1135-4710-a434-68036d062e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ProgressBar\n",
    "\n",
    "class LitProgressBar(ProgressBar):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # don't forget this :)\n",
    "        self.enable = True\n",
    "\n",
    "    def disable(self):\n",
    "        self.enable = False\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        super().on_train_batch_end(trainer, pl_module, outputs, batch, batch_idx)  # don't forget this :)\n",
    "        # percent = (batch_idx / self.total_train_batches) * 100\n",
    "        # sys.stdout.flush()\n",
    "        # sys.stdout.write(f'{percent:.01f} percent complete \\r')\n",
    "        pass\n",
    "\n",
    "bar = LitProgressBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7b6c29-f474-421c-bb87-8e196b48f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "runner = Trainer(logger=logger,\n",
    "                 callbacks=[\n",
    "                     # LearningRateMonitor(),\n",
    "                     bar,\n",
    "                     ModelCheckpoint(save_top_k=3, \n",
    "                                     every_n_epochs = 3000,\n",
    "                                     dirpath =os.path.join(logger.log_dir , \"checkpoints\"), \n",
    "                                     monitor= \"val_loss\",\n",
    "                                     save_last= True),\n",
    "                 ],\n",
    "                 # strategy=DDPPlugin(find_unused_parameters=False),\n",
    "                 # strategy=\"ddp_notebook\", \n",
    "                 log_every_n_steps = 16,\n",
    "                 accelerator=\"gpu\", \n",
    "                 devices=1,\n",
    "                 **config['trainer_params'])\n",
    "\n",
    "\n",
    "Path(f\"{logger.log_dir}/Samples\").mkdir(exist_ok=True, parents=True)\n",
    "Path(f\"{logger.log_dir}/Reconstructions\").mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3966d7a8-7344-405a-a813-1015f13c9666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/jasper/miniforge3/envs/s2s2/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory logs/DFCVAE/version_9 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | DFCVAE | 147 M \n",
      "---------------------------------\n",
      "3.3 M     Trainable params\n",
      "143 M     Non-trainable params\n",
      "147 M     Total params\n",
      "588.099   Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10000` reached.\n"
     ]
    }
   ],
   "source": [
    "runner.fit(experiment, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0fdda-83e6-41f7-8dbf-778ff7b4acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
